{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Nominatim (from the Latin, 'by name') is a tool to search OSM data by name and address and to generate synthetic addresses of OSM points (reverse geocoding). This guide comes in four parts: API reference for users of Nominatim Administration Guide for those who want to install their own Nominatim server Customization Guide for those who want to adapt their own installation to their special requirements Developer's Guide for developers of the software","title":"Introduction"},{"location":"admin/Advanced-Installations/","text":"Advanced installations \uf0c1 This page contains instructions for setting up multiple countries in your Nominatim database. It is assumed that you have already successfully installed the Nominatim software itself, if not return to the installation page . Importing multiple regions (without updates) \uf0c1 To import multiple regions in your database you can simply give multiple OSM files to the import command: nominatim import -- osm - file file1 . pbf -- osm - file file2 . pbf If you already have imported a file and want to add another one, you can use the add-data function to import the additional data as follows: nominatim add-data --file <FILE> nominatim refresh --postcodes nominatim index -j <NUMBER OF THREADS> Please note that adding additional data is always significantly slower than the original import. Importing multiple regions (with updates) \uf0c1 If you want to import multiple regions and be able to keep them up-to-date with updates, then you can use the scripts provided in the utils directory. These scripts will set up an update directory in your project directory, which has the following structure: update \u251c\u2500\u2500 europe \u2502 \u251c\u2500\u2500 andorra \u2502 \u2502 \u2514\u2500\u2500 sequence.state \u2502 \u2514\u2500\u2500 monaco \u2502 \u2514\u2500\u2500 sequence.state \u2514\u2500\u2500 tmp \u2514\u2500\u2500 europe \u251c\u2500\u2500 andorra-latest.osm.pbf \u2514\u2500\u2500 monaco-latest.osm.pbf The sequence.state files contain the sequence ID for each region. They will be used by pyosmium to get updates. The tmp folder is used for import dump and can be deleted once the import is complete. Setting up multiple regions \uf0c1 Create a project directory as described for the simple import . If necessary, you can also add an .env configuration with customized options. In particular, you need to make sure that NOMINATIM_REPLICATION_UPDATE_INTERVAL and NOMINATIM_REPLICATION_RECHECK_INTERVAL are set according to the update interval of the extract server you use. Copy the scripts utils/import_multiple_regions.sh and utils/update_database.sh into the project directory. Now customize both files as per your requirements List of countries. e.g. COUNTRIES=\"europe/monaco europe/andorra\" URL to the service providing the extracts and updates. eg: BASEURL = \"https://download.geofabrik.de\" DOWNCOUNTRYPOSTFIX = \"-latest.osm.pbf\" Followup in the update script can be set according to your installation. E.g. for Photon, FOLLOWUP=\"curl http://localhost:2322/nominatim-update\" will handle the indexing. To start the initial import, change into the project directory and run bash import_multiple_regions.sh Updating the database \uf0c1 Change into the project directory and run the following command: bash update_database.sh This will get diffs from the replication server, import diffs and index the database. The default replication server in the script( Geofabrik ) provides daily updates. Using an external PostgreSQL database \uf0c1 You can install Nominatim using a database that runs on a different server when you have physical access to the file system on the other server. Nominatim uses a custom normalization library that needs to be made accessible to the PostgreSQL server. This section explains how to set up the normalization library. Note The external module is only needed when using the legacy tokenizer. If you have chosen the ICU tokenizer, then you can ignore this section and follow the standard import documentation. Option 1: Compiling the library on the database server \uf0c1 The most sure way to get a working library is to compile it on the database server. From the prerequisites you need at least cmake, gcc and the PostgreSQL server package. Clone or unpack the Nominatim source code, enter the source directory and create and enter a build directory. cd Nominatim mkdir build cd build Now configure cmake to only build the PostgreSQL module and build it: cmake -DBUILD_IMPORTER=off -DBUILD_API=off -DBUILD_TESTS=off -DBUILD_DOCS=off -DBUILD_OSM2PGSQL=off .. make When done, you find the normalization library in build/module/nominatim.so . Copy it to a place where it is readable and executable by the PostgreSQL server process. Option 2: Compiling the library on the import machine \uf0c1 You can also compile the normalization library on the machine from where you run the import. Important You can only do this when the database server and the import machine have the same architecture and run the same version of Linux. Otherwise there is no guarantee that the compiled library is compatible with the PostgreSQL server running on the database server. Make sure that the PostgreSQL server package is installed on the machine with the same version as on the database server . You do not need to install the PostgreSQL server itself. Download and compile Nominatim as per standard instructions. Once done, you find the normalization library in build/module/nominatim.so . Copy the file to the database server at a location where it is readable and executable by the PostgreSQL server process. Running the import \uf0c1 On the client side you now need to configure the import to point to the correct location of the library on the database server . Add the following line to your your .env file: NOMINATIM_DATABASE_MODULE_PATH=\"<directory on the database server where nominatim.so resides>\" Now change the NOMINATIM_DATABASE_DSN to point to your remote server and continue to follow the standard instructions for importing . Moving the database to another machine \uf0c1 For some configurations it may be useful to run the import on one machine, then move the database to another machine and run the Nominatim service from there. For example, you might want to use a large machine to be able to run the import quickly but only want a smaller machine for production because there is not so much load. Or you might want to do the import once and then replicate the database to many machines. The important thing to keep in mind when transferring the Nominatim installation is that you need to transfer the database and the project directory . Both parts are essential for your installation. The Nominatim database can be transferred using the pg_dump / pg_restore tool. Make sure to use the same version of PostgreSQL and PostGIS on source and target machine. Note Before creating a dump of your Nominatim database, consider running nominatim freeze first. Your database looses the ability to receive further data updates but the resulting database is only about a third of the size of a full database. Next install Nominatim on the target machine by following the standard installation instructions. Again, make sure to use the same version as the source machine. Create a project directory on your destination machine and set up the .env file to match the configuration on the source machine. Finally run nominatim refresh --website to make sure that the local installation of Nominatim will be used. If you are using the legacy tokenizer you might also have to switch to the PostgreSQL module that was compiled on your target machine. If you get errors that PostgreSQL cannot find or access nominatim.so then rerun nominatim refresh --functions on the target machine to update the the location of the module.","title":"Advanced Installations"},{"location":"admin/Advanced-Installations/#advanced-installations","text":"This page contains instructions for setting up multiple countries in your Nominatim database. It is assumed that you have already successfully installed the Nominatim software itself, if not return to the installation page .","title":"Advanced installations"},{"location":"admin/Advanced-Installations/#importing-multiple-regions-without-updates","text":"To import multiple regions in your database you can simply give multiple OSM files to the import command: nominatim import -- osm - file file1 . pbf -- osm - file file2 . pbf If you already have imported a file and want to add another one, you can use the add-data function to import the additional data as follows: nominatim add-data --file <FILE> nominatim refresh --postcodes nominatim index -j <NUMBER OF THREADS> Please note that adding additional data is always significantly slower than the original import.","title":"Importing multiple regions (without updates)"},{"location":"admin/Advanced-Installations/#importing-multiple-regions-with-updates","text":"If you want to import multiple regions and be able to keep them up-to-date with updates, then you can use the scripts provided in the utils directory. These scripts will set up an update directory in your project directory, which has the following structure: update \u251c\u2500\u2500 europe \u2502 \u251c\u2500\u2500 andorra \u2502 \u2502 \u2514\u2500\u2500 sequence.state \u2502 \u2514\u2500\u2500 monaco \u2502 \u2514\u2500\u2500 sequence.state \u2514\u2500\u2500 tmp \u2514\u2500\u2500 europe \u251c\u2500\u2500 andorra-latest.osm.pbf \u2514\u2500\u2500 monaco-latest.osm.pbf The sequence.state files contain the sequence ID for each region. They will be used by pyosmium to get updates. The tmp folder is used for import dump and can be deleted once the import is complete.","title":"Importing multiple regions (with updates)"},{"location":"admin/Advanced-Installations/#setting-up-multiple-regions","text":"Create a project directory as described for the simple import . If necessary, you can also add an .env configuration with customized options. In particular, you need to make sure that NOMINATIM_REPLICATION_UPDATE_INTERVAL and NOMINATIM_REPLICATION_RECHECK_INTERVAL are set according to the update interval of the extract server you use. Copy the scripts utils/import_multiple_regions.sh and utils/update_database.sh into the project directory. Now customize both files as per your requirements List of countries. e.g. COUNTRIES=\"europe/monaco europe/andorra\" URL to the service providing the extracts and updates. eg: BASEURL = \"https://download.geofabrik.de\" DOWNCOUNTRYPOSTFIX = \"-latest.osm.pbf\" Followup in the update script can be set according to your installation. E.g. for Photon, FOLLOWUP=\"curl http://localhost:2322/nominatim-update\" will handle the indexing. To start the initial import, change into the project directory and run bash import_multiple_regions.sh","title":"Setting up multiple regions"},{"location":"admin/Advanced-Installations/#updating-the-database","text":"Change into the project directory and run the following command: bash update_database.sh This will get diffs from the replication server, import diffs and index the database. The default replication server in the script( Geofabrik ) provides daily updates.","title":"Updating the database"},{"location":"admin/Advanced-Installations/#using-an-external-postgresql-database","text":"You can install Nominatim using a database that runs on a different server when you have physical access to the file system on the other server. Nominatim uses a custom normalization library that needs to be made accessible to the PostgreSQL server. This section explains how to set up the normalization library. Note The external module is only needed when using the legacy tokenizer. If you have chosen the ICU tokenizer, then you can ignore this section and follow the standard import documentation.","title":"Using an external PostgreSQL database"},{"location":"admin/Advanced-Installations/#option-1-compiling-the-library-on-the-database-server","text":"The most sure way to get a working library is to compile it on the database server. From the prerequisites you need at least cmake, gcc and the PostgreSQL server package. Clone or unpack the Nominatim source code, enter the source directory and create and enter a build directory. cd Nominatim mkdir build cd build Now configure cmake to only build the PostgreSQL module and build it: cmake -DBUILD_IMPORTER=off -DBUILD_API=off -DBUILD_TESTS=off -DBUILD_DOCS=off -DBUILD_OSM2PGSQL=off .. make When done, you find the normalization library in build/module/nominatim.so . Copy it to a place where it is readable and executable by the PostgreSQL server process.","title":"Option 1: Compiling the library on the database server"},{"location":"admin/Advanced-Installations/#option-2-compiling-the-library-on-the-import-machine","text":"You can also compile the normalization library on the machine from where you run the import. Important You can only do this when the database server and the import machine have the same architecture and run the same version of Linux. Otherwise there is no guarantee that the compiled library is compatible with the PostgreSQL server running on the database server. Make sure that the PostgreSQL server package is installed on the machine with the same version as on the database server . You do not need to install the PostgreSQL server itself. Download and compile Nominatim as per standard instructions. Once done, you find the normalization library in build/module/nominatim.so . Copy the file to the database server at a location where it is readable and executable by the PostgreSQL server process.","title":"Option 2: Compiling the library on the import machine"},{"location":"admin/Advanced-Installations/#running-the-import","text":"On the client side you now need to configure the import to point to the correct location of the library on the database server . Add the following line to your your .env file: NOMINATIM_DATABASE_MODULE_PATH=\"<directory on the database server where nominatim.so resides>\" Now change the NOMINATIM_DATABASE_DSN to point to your remote server and continue to follow the standard instructions for importing .","title":"Running the import"},{"location":"admin/Advanced-Installations/#moving-the-database-to-another-machine","text":"For some configurations it may be useful to run the import on one machine, then move the database to another machine and run the Nominatim service from there. For example, you might want to use a large machine to be able to run the import quickly but only want a smaller machine for production because there is not so much load. Or you might want to do the import once and then replicate the database to many machines. The important thing to keep in mind when transferring the Nominatim installation is that you need to transfer the database and the project directory . Both parts are essential for your installation. The Nominatim database can be transferred using the pg_dump / pg_restore tool. Make sure to use the same version of PostgreSQL and PostGIS on source and target machine. Note Before creating a dump of your Nominatim database, consider running nominatim freeze first. Your database looses the ability to receive further data updates but the resulting database is only about a third of the size of a full database. Next install Nominatim on the target machine by following the standard installation instructions. Again, make sure to use the same version as the source machine. Create a project directory on your destination machine and set up the .env file to match the configuration on the source machine. Finally run nominatim refresh --website to make sure that the local installation of Nominatim will be used. If you are using the legacy tokenizer you might also have to switch to the PostgreSQL module that was compiled on your target machine. If you get errors that PostgreSQL cannot find or access nominatim.so then rerun nominatim refresh --functions on the target machine to update the the location of the module.","title":"Moving the database to another machine"},{"location":"admin/Deployment/","text":"Deploying Nominatim \uf0c1 The Nominatim API is implemented as a PHP application. The website/ directory in the project directory contains the configured website. You can serve this in a production environment with any web server that is capable to run PHP scripts. This section gives a quick overview on how to configure Apache and Nginx to serve Nominatim. It is not meant as a full system administration guide on how to run a web service. Please refer to the documentation of Apache and Nginx for background information on configuring the services. Note Throughout this page, we assume that your Nominatim project directory is located in /srv/nominatim-project and that you have installed Nominatim using the default installation prefix /usr/local . If you have put it somewhere else, you need to adjust the commands and configuration accordingly. We further assume that your web server runs as user www-data . Older versions of CentOS may still use the user name apache . You also need to adapt the instructions in this case. Making the website directory accessible \uf0c1 You need to make sure that the website directory is accessible for the web server user. You can check that the permissions are correct by accessing on of the php files as the web server user: sudo -u www-data head -n 1 /srv/nominatim-project/website/search.php If this shows a permission error, then you need to adapt the permissions of each directory in the path so that it is executable for www-data . If you have SELinux enabled, further adjustments may be necessary to give the web server access. At a minimum the following SELinux labelling should be done for Nominatim: sudo semanage fcontext -a -t httpd_sys_content_t \"/usr/local/nominatim/lib/lib-php(/.*)?\" sudo semanage fcontext -a -t httpd_sys_content_t \"/srv/nominatim-project/website(/.*)?\" sudo semanage fcontext -a -t lib_t \"/srv/nominatim-project/module/nominatim.so\" sudo restorecon -R -v /usr/local/lib/nominatim sudo restorecon -R -v /srv/nominatim-project Nominatim with Apache \uf0c1 Installing the required packages \uf0c1 With Apache you can use the PHP module to run Nominatim. Under Ubuntu/Debian install them with: sudo apt install apache2 libapache2-mod-php Configuring Apache \uf0c1 Make sure your Apache configuration contains the required permissions for the directory and create an alias: <Directory \"/srv/nominatim-project/website\" > Options FollowSymLinks MultiViews AddType text/html .php DirectoryIndex search.php Require all granted </Directory> Alias /nominatim /srv/nominatim-project/website After making changes in the apache config you need to restart apache. The website should now be available on http://localhost/nominatim . Nominatim with Nginx \uf0c1 Installing the required packages \uf0c1 Nginx has no built-in PHP interpreter. You need to use php-fpm as a daemon for serving PHP cgi. On Ubuntu/Debian install nginx and php-fpm with: sudo apt install nginx php-fpm Configure php-fpm and Nginx \uf0c1 By default php-fpm listens on a network socket. If you want it to listen to a Unix socket instead, change the pool configuration ( /etc/php/<php version>/fpm/pool.d/www.conf ) as follows: ; Replace the tcp listener and add the unix socket listen = /var/run/php-fpm.sock ; Ensure that the daemon runs as the correct user listen.owner = www-data listen.group = www-data listen.mode = 0666 Tell nginx that php files are special and to fastcgi_pass to the php-fpm unix socket by adding the location definition to the default configuration. root /srv/nominatim-project/website ; index search.php ; location / { try_files $uri $uri/ @php ; } location @php { fastcgi_param SCRIPT_FILENAME \" $document_root$uri.php\" ; fastcgi_param PATH_TRANSLATED \" $document_root$uri.php\" ; fastcgi_param QUERY_STRING $args ; fastcgi_pass unix:/var/run/php-fpm.sock ; fastcgi_index index.php ; include fastcgi_params ; } location ~ [^/]\\.php(/|$) { fastcgi_split_path_info ^(.+?\\.php)(/.*) $ ; if (!-f $document_root$fastcgi_script_name ) { return 404 ; } fastcgi_pass unix:/var/run/php-fpm.sock ; fastcgi_index search.php ; include fastcgi.conf ; } Restart the nginx and php-fpm services and the website should now be available at http://localhost/ . Nominatim with other webservers \uf0c1 Users have created instructions for other webservers: Caddy","title":"Deploy"},{"location":"admin/Deployment/#deploying-nominatim","text":"The Nominatim API is implemented as a PHP application. The website/ directory in the project directory contains the configured website. You can serve this in a production environment with any web server that is capable to run PHP scripts. This section gives a quick overview on how to configure Apache and Nginx to serve Nominatim. It is not meant as a full system administration guide on how to run a web service. Please refer to the documentation of Apache and Nginx for background information on configuring the services. Note Throughout this page, we assume that your Nominatim project directory is located in /srv/nominatim-project and that you have installed Nominatim using the default installation prefix /usr/local . If you have put it somewhere else, you need to adjust the commands and configuration accordingly. We further assume that your web server runs as user www-data . Older versions of CentOS may still use the user name apache . You also need to adapt the instructions in this case.","title":"Deploying Nominatim"},{"location":"admin/Deployment/#making-the-website-directory-accessible","text":"You need to make sure that the website directory is accessible for the web server user. You can check that the permissions are correct by accessing on of the php files as the web server user: sudo -u www-data head -n 1 /srv/nominatim-project/website/search.php If this shows a permission error, then you need to adapt the permissions of each directory in the path so that it is executable for www-data . If you have SELinux enabled, further adjustments may be necessary to give the web server access. At a minimum the following SELinux labelling should be done for Nominatim: sudo semanage fcontext -a -t httpd_sys_content_t \"/usr/local/nominatim/lib/lib-php(/.*)?\" sudo semanage fcontext -a -t httpd_sys_content_t \"/srv/nominatim-project/website(/.*)?\" sudo semanage fcontext -a -t lib_t \"/srv/nominatim-project/module/nominatim.so\" sudo restorecon -R -v /usr/local/lib/nominatim sudo restorecon -R -v /srv/nominatim-project","title":"Making the website directory accessible"},{"location":"admin/Deployment/#nominatim-with-apache","text":"","title":"Nominatim with Apache"},{"location":"admin/Deployment/#installing-the-required-packages","text":"With Apache you can use the PHP module to run Nominatim. Under Ubuntu/Debian install them with: sudo apt install apache2 libapache2-mod-php","title":"Installing the required packages"},{"location":"admin/Deployment/#configuring-apache","text":"Make sure your Apache configuration contains the required permissions for the directory and create an alias: <Directory \"/srv/nominatim-project/website\" > Options FollowSymLinks MultiViews AddType text/html .php DirectoryIndex search.php Require all granted </Directory> Alias /nominatim /srv/nominatim-project/website After making changes in the apache config you need to restart apache. The website should now be available on http://localhost/nominatim .","title":"Configuring Apache"},{"location":"admin/Deployment/#nominatim-with-nginx","text":"","title":"Nominatim with Nginx"},{"location":"admin/Deployment/#installing-the-required-packages_1","text":"Nginx has no built-in PHP interpreter. You need to use php-fpm as a daemon for serving PHP cgi. On Ubuntu/Debian install nginx and php-fpm with: sudo apt install nginx php-fpm","title":"Installing the required packages"},{"location":"admin/Deployment/#configure-php-fpm-and-nginx","text":"By default php-fpm listens on a network socket. If you want it to listen to a Unix socket instead, change the pool configuration ( /etc/php/<php version>/fpm/pool.d/www.conf ) as follows: ; Replace the tcp listener and add the unix socket listen = /var/run/php-fpm.sock ; Ensure that the daemon runs as the correct user listen.owner = www-data listen.group = www-data listen.mode = 0666 Tell nginx that php files are special and to fastcgi_pass to the php-fpm unix socket by adding the location definition to the default configuration. root /srv/nominatim-project/website ; index search.php ; location / { try_files $uri $uri/ @php ; } location @php { fastcgi_param SCRIPT_FILENAME \" $document_root$uri.php\" ; fastcgi_param PATH_TRANSLATED \" $document_root$uri.php\" ; fastcgi_param QUERY_STRING $args ; fastcgi_pass unix:/var/run/php-fpm.sock ; fastcgi_index index.php ; include fastcgi_params ; } location ~ [^/]\\.php(/|$) { fastcgi_split_path_info ^(.+?\\.php)(/.*) $ ; if (!-f $document_root$fastcgi_script_name ) { return 404 ; } fastcgi_pass unix:/var/run/php-fpm.sock ; fastcgi_index search.php ; include fastcgi.conf ; } Restart the nginx and php-fpm services and the website should now be available at http://localhost/ .","title":"Configure php-fpm and Nginx"},{"location":"admin/Deployment/#nominatim-with-other-webservers","text":"Users have created instructions for other webservers: Caddy","title":"Nominatim with other webservers"},{"location":"admin/Faq/","text":"Troubleshooting Nominatim Installations \uf0c1 Installation Issues \uf0c1 Can a stopped/killed import process be resumed? \uf0c1 \"I accidentally killed the import process after it has been running for many hours. Can it be resumed?\" It is possible if the import already got to the indexing stage. Check the last line of output that was logged before the process was killed. If it looks like this: Done 844 in 13 @ 64.923080 per second - Rank 26 ETA (seconds): 7.886255 then you can resume with the following command: nominatim import --continue indexing If the reported rank is 26 or higher, you can also safely add --index-noanalyse . PostgreSQL crashed \"invalid page in block\" \uf0c1 Usually serious problem, can be a hardware issue, not all data written to disc for example. Check PostgreSQL log file and search PostgreSQL issues/mailing list for hints. If it happened during index creation you can try rerunning the step with nominatim import --continue indexing Otherwise it's best to start the full setup from the beginning. PHP \"open_basedir restriction in effect\" warnings \uf0c1 PHP Warning: file_get_contents(): open_basedir restriction in effect. You need to adjust the open_basedir setting in your PHP configuration ( php.ini file). By default this setting may look like this: open_basedir = /srv/http/:/home/:/tmp/:/usr/share/pear/ Either add reported directories to the list or disable this setting temporarily by adding \";\" at the beginning of the line. Don't forget to enable this setting again once you are done with the PHP command line operations. PHP timezeone warnings \uf0c1 The Apache log may contain lots of PHP warnings like this: PHP Warning: date_default_timezone_set() function. You should set the default time zone as instructed in the warning in your php.ini file. Find the entry about timezone and set it to something like this: ; Defines the default timezone used by the date functions ; https://php.net/date.timezone date.timezone = 'America/Denver' Or echo \"date.timezone = 'America/Denver'\" > /etc/php.d/timezone.ini nominatim.so version mismatch \uf0c1 When running the import you may get a version mismatch: COPY_END for place failed: ERROR: incompatible library \"/srv/Nominatim/nominatim/build/module/nominatim.so\": version mismatch pg_config seems to use bad includes sometimes when multiple versions of PostgreSQL are available in the system. Make sure you remove the server development libraries ( postgresql-server-dev-13 on Ubuntu) and recompile ( cmake .. && make ). I see the error \"ERROR: permission denied for language c\" \uf0c1 nominatim.so , written in C, is required to be installed on the database server. Some managed database (cloud) services like Amazon RDS do not allow this. There is currently no work-around other than installing a database on a non-managed machine. I see the error: \"function transliteration(text) does not exist\" \uf0c1 Reinstall the nominatim functions with nominatim refresh --functions and check for any errors, e.g. a missing nominatim.so file. I see the error: \"ERROR: mmap (remap) failed\" \uf0c1 This may be a simple out-of-memory error. Try reducing the memory used for --osm2pgsql-cache . Also make sure that overcommitting memory is allowed: cat /proc/sys/vm/overcommit_memory should print 0 or 1. If you are using a flatnode file, then it may also be that the underlying filesystem does not fully support 'mmap'. A notable candidate is virtualbox's vboxfs. nominatim UPDATE failed: ERROR: buffer 179261 is not owned by resource owner Portal \uf0c1 Several users reported this during the initial import of the database. It's something PostgreSQL internal Nominatim doesn't control. And PostgreSQL forums suggest it's threading related but definitely some kind of crash of a process. Users reported either rebooting the server, different hardware or just trying the import again worked. The website shows: \"Could not get word tokens\" \uf0c1 The server cannot access your database. Add &debug=1 to your URL to get the full error message. Website reports \"DB Error: insufficient permissions\" \uf0c1 The user the webserver, e.g. Apache, runs under needs to have access to the Nominatim database. You can find the user like this , for default Ubuntu operating system for example it's www-data . Repeat the createuser step of the installation instructions. Give the user permission to existing tables GRANT usage ON SCHEMA public TO \"www-data\"; GRANT SELECT ON ALL TABLES IN SCHEMA public TO \"www-data\"; Website reports \"Could not load library \"nominatim.so\" \uf0c1 Example error message SELECT make_standard_name ( '3039 E MEADOWLARK LN' ) [ nativecode = ERROR : could not load library \"/srv/nominatim/Nominatim-3.1.0/build/module/nominatim.so\" : / srv / nominatim / Nominatim - 3.1 . 0 / build / module / nominatim . so : cannot open shared object file : Permission denied CONTEXT : PL / pgSQL function make_standard_name ( text ) line 5 at assignment ] The PostgreSQL database, i.e. user postgres , needs to have access to that file. The permission need to be read & executable by everybody, but not writeable by everybody, e.g. -rwxr-xr-x 1 nominatim nominatim 297984 build/module/nominatim.so Try chmod a+r nominatim.so; chmod a+x nominatim.so . When you recently updated your operating system, updated PostgreSQL to a new version or moved files (e.g. the build directory) you should recreate nominatim.so . Try cd build rm -r module/ cmake $main_Nominatim_path && make Setup.php fails with \"DB Error: extension not found\" \uf0c1 Make sure you have the PostgreSQL extensions \"hstore\" and \"postgis\" installed. See the installation instructions for a full list of required packages. I forgot to delete the flatnodes file before starting an import. \uf0c1 That's fine. For each import the flatnodes file get overwritten. See https://help.openstreetmap.org/questions/52419/nominatim-flatnode-storage for more information. Running your own instance \uf0c1 Can I import negative OSM ids into Nominatim? \uf0c1 See this question of Stackoverflow .","title":"Troubleshooting"},{"location":"admin/Faq/#troubleshooting-nominatim-installations","text":"","title":"Troubleshooting Nominatim Installations"},{"location":"admin/Faq/#installation-issues","text":"","title":"Installation Issues"},{"location":"admin/Faq/#can-a-stoppedkilled-import-process-be-resumed","text":"\"I accidentally killed the import process after it has been running for many hours. Can it be resumed?\" It is possible if the import already got to the indexing stage. Check the last line of output that was logged before the process was killed. If it looks like this: Done 844 in 13 @ 64.923080 per second - Rank 26 ETA (seconds): 7.886255 then you can resume with the following command: nominatim import --continue indexing If the reported rank is 26 or higher, you can also safely add --index-noanalyse .","title":"Can a stopped/killed import process be resumed?"},{"location":"admin/Faq/#postgresql-crashed-invalid-page-in-block","text":"Usually serious problem, can be a hardware issue, not all data written to disc for example. Check PostgreSQL log file and search PostgreSQL issues/mailing list for hints. If it happened during index creation you can try rerunning the step with nominatim import --continue indexing Otherwise it's best to start the full setup from the beginning.","title":"PostgreSQL crashed \"invalid page in block\""},{"location":"admin/Faq/#php-open_basedir-restriction-in-effect-warnings","text":"PHP Warning: file_get_contents(): open_basedir restriction in effect. You need to adjust the open_basedir setting in your PHP configuration ( php.ini file). By default this setting may look like this: open_basedir = /srv/http/:/home/:/tmp/:/usr/share/pear/ Either add reported directories to the list or disable this setting temporarily by adding \";\" at the beginning of the line. Don't forget to enable this setting again once you are done with the PHP command line operations.","title":"PHP \"open_basedir restriction in effect\" warnings"},{"location":"admin/Faq/#php-timezeone-warnings","text":"The Apache log may contain lots of PHP warnings like this: PHP Warning: date_default_timezone_set() function. You should set the default time zone as instructed in the warning in your php.ini file. Find the entry about timezone and set it to something like this: ; Defines the default timezone used by the date functions ; https://php.net/date.timezone date.timezone = 'America/Denver' Or echo \"date.timezone = 'America/Denver'\" > /etc/php.d/timezone.ini","title":"PHP timezeone warnings"},{"location":"admin/Faq/#nominatimso-version-mismatch","text":"When running the import you may get a version mismatch: COPY_END for place failed: ERROR: incompatible library \"/srv/Nominatim/nominatim/build/module/nominatim.so\": version mismatch pg_config seems to use bad includes sometimes when multiple versions of PostgreSQL are available in the system. Make sure you remove the server development libraries ( postgresql-server-dev-13 on Ubuntu) and recompile ( cmake .. && make ).","title":"nominatim.so version mismatch"},{"location":"admin/Faq/#i-see-the-error-error-permission-denied-for-language-c","text":"nominatim.so , written in C, is required to be installed on the database server. Some managed database (cloud) services like Amazon RDS do not allow this. There is currently no work-around other than installing a database on a non-managed machine.","title":"I see the error \"ERROR: permission denied for language c\""},{"location":"admin/Faq/#i-see-the-error-function-transliterationtext-does-not-exist","text":"Reinstall the nominatim functions with nominatim refresh --functions and check for any errors, e.g. a missing nominatim.so file.","title":"I see the error: \"function transliteration(text) does not exist\""},{"location":"admin/Faq/#i-see-the-error-error-mmap-remap-failed","text":"This may be a simple out-of-memory error. Try reducing the memory used for --osm2pgsql-cache . Also make sure that overcommitting memory is allowed: cat /proc/sys/vm/overcommit_memory should print 0 or 1. If you are using a flatnode file, then it may also be that the underlying filesystem does not fully support 'mmap'. A notable candidate is virtualbox's vboxfs.","title":"I see the error: \"ERROR: mmap (remap) failed\""},{"location":"admin/Faq/#nominatim-update-failed-error-buffer-179261-is-not-owned-by-resource-owner-portal","text":"Several users reported this during the initial import of the database. It's something PostgreSQL internal Nominatim doesn't control. And PostgreSQL forums suggest it's threading related but definitely some kind of crash of a process. Users reported either rebooting the server, different hardware or just trying the import again worked.","title":"nominatim UPDATE failed: ERROR: buffer 179261 is not owned by resource owner Portal"},{"location":"admin/Faq/#the-website-shows-could-not-get-word-tokens","text":"The server cannot access your database. Add &debug=1 to your URL to get the full error message.","title":"The website shows: \"Could not get word tokens\""},{"location":"admin/Faq/#website-reports-db-error-insufficient-permissions","text":"The user the webserver, e.g. Apache, runs under needs to have access to the Nominatim database. You can find the user like this , for default Ubuntu operating system for example it's www-data . Repeat the createuser step of the installation instructions. Give the user permission to existing tables GRANT usage ON SCHEMA public TO \"www-data\"; GRANT SELECT ON ALL TABLES IN SCHEMA public TO \"www-data\";","title":"Website reports \"DB Error: insufficient permissions\""},{"location":"admin/Faq/#website-reports-could-not-load-library-nominatimso","text":"Example error message SELECT make_standard_name ( '3039 E MEADOWLARK LN' ) [ nativecode = ERROR : could not load library \"/srv/nominatim/Nominatim-3.1.0/build/module/nominatim.so\" : / srv / nominatim / Nominatim - 3.1 . 0 / build / module / nominatim . so : cannot open shared object file : Permission denied CONTEXT : PL / pgSQL function make_standard_name ( text ) line 5 at assignment ] The PostgreSQL database, i.e. user postgres , needs to have access to that file. The permission need to be read & executable by everybody, but not writeable by everybody, e.g. -rwxr-xr-x 1 nominatim nominatim 297984 build/module/nominatim.so Try chmod a+r nominatim.so; chmod a+x nominatim.so . When you recently updated your operating system, updated PostgreSQL to a new version or moved files (e.g. the build directory) you should recreate nominatim.so . Try cd build rm -r module/ cmake $main_Nominatim_path && make","title":"Website reports \"Could not load library \"nominatim.so\""},{"location":"admin/Faq/#setupphp-fails-with-db-error-extension-not-found","text":"Make sure you have the PostgreSQL extensions \"hstore\" and \"postgis\" installed. See the installation instructions for a full list of required packages.","title":"Setup.php fails with \"DB Error: extension not found\""},{"location":"admin/Faq/#i-forgot-to-delete-the-flatnodes-file-before-starting-an-import","text":"That's fine. For each import the flatnodes file get overwritten. See https://help.openstreetmap.org/questions/52419/nominatim-flatnode-storage for more information.","title":"I forgot to delete the flatnodes file before starting an import."},{"location":"admin/Faq/#running-your-own-instance","text":"","title":"Running your own instance"},{"location":"admin/Faq/#can-i-import-negative-osm-ids-into-nominatim","text":"See this question of Stackoverflow .","title":"Can I import negative OSM ids into Nominatim?"},{"location":"admin/Import/","text":"Importing the Database \uf0c1 The following instructions explain how to create a Nominatim database from an OSM planet file. It is assumed that you have already successfully installed the Nominatim software itself and the nominatim tool can be found in your PATH . If this is not the case, return to the installation page . Creating the project directory \uf0c1 Before you start the import, you should create a project directory for your new database installation. This directory receives all data that is related to a single Nominatim setup: configuration, extra data, etc. Create a project directory apart from the Nominatim software and change into the directory: mkdir ~/nominatim-planet cd ~/nominatim-planet In the following, we refer to the project directory as $PROJECT_DIR . To be able to copy&paste instructions, you can export the appropriate variable: export PROJECT_DIR =~/ nominatim - planet The Nominatim tool assumes per default that the current working directory is the project directory but you may explicitly state a different directory using the --project-dir parameter. The following instructions assume that you run all commands from the project directory. Migration Tip Nominatim used to be run directly from the build directory until version 3.6. Essentially, the build directory functioned as the project directory for the database installation. This setup still works and can be useful for development purposes. It is not recommended anymore for production setups. Create a project directory that is separate from the Nominatim software. Configuration setup in .env \uf0c1 The Nominatim server can be customized via an .env configuration file in the project directory. This is a file in dotenv format which looks the same as variable settings in a standard shell environment. You can also set the same configuration via environment variables. All settings have a NOMINATIM_ prefix to avoid conflicts with other environment variables. There are lots of configuration settings you can tweak. A full reference can be found in the chapter Configuration Settings . Most should have a sensible default. Flatnode files \uf0c1 If you plan to import a large dataset (e.g. Europe, North America, planet), you should also enable flatnode storage of node locations. With this setting enabled, node coordinates are stored in a simple file instead of the database. This will save you import time and disk storage. Add to your .env : NOMINATIM_FLATNODE_FILE=\"/path/to/flatnode.file\" Replace the second part with a suitable path on your system and make sure the directory exists. There should be at least 75GB of free space. Downloading additional data \uf0c1 Wikipedia/Wikidata rankings \uf0c1 Wikipedia can be used as an optional auxiliary data source to help indicate the importance of OSM features. Nominatim will work without this information but it will improve the quality of the results if this is installed. This data is available as a binary download. Put it into your project directory: cd $PROJECT_DIR wget https://www.nominatim.org/data/wikimedia-importance.sql.gz The file is about 400MB and adds around 4GB to the Nominatim database. Tip If you forgot to download the wikipedia rankings, you can also add importances after the import. Download the files, then run nominatim refresh --wiki-data --importance . Updating importances for a planet can take a couple of hours. External postcodes \uf0c1 Nominatim can use postcodes from an external source to improve searching with postcodes. We provide precomputed postcodes sets for the US (using TIGER data) and the UK (using the CodePoint OpenData set . This data can be optionally downloaded into the project directory: cd $PROJECT_DIR wget https://www.nominatim.org/data/gb_postcodes.csv.gz wget https://www.nominatim.org/data/us_postcodes.csv.gz You can also add your own custom postcode sources, see Customization of postcodes . Choosing the data to import \uf0c1 In its default setup Nominatim is configured to import the full OSM data set for the entire planet. Such a setup requires a powerful machine with at least 64GB of RAM and around 900GB of SSD hard disks. Depending on your use case there are various ways to reduce the amount of data imported. This section discusses these methods. They can also be combined. Using an extract \uf0c1 If you only need geocoding for a smaller region, then precomputed OSM extracts are a good way to reduce the database size and import time. Geofabrik offers extracts for most countries. They even have daily updates which can be used with the update process described in the next section . There are also other providers for extracts . Please be aware that some extracts are not cut exactly along the country boundaries. As a result some parts of the boundary may be missing which means that Nominatim cannot compute the areas for some administrative areas. Dropping Data Required for Dynamic Updates \uf0c1 About half of the data in Nominatim's database is not really used for serving the API. It is only there to allow the data to be updated from the latest changes from OSM. For many uses these dynamic updates are not really required. If you don't plan to apply updates, you can run the import with the --no-updates parameter. This will drop the dynamic part of the database as soon as it is not required anymore. You can also drop the dynamic part later using the following command: nominatim freeze Note that you still need to provide for sufficient disk space for the initial import. So this option is particularly interesting if you plan to transfer the database or reuse the space later. Warning The datastructure for updates are also required when adding additional data after the import, for example TIGER housenumber data . If you plan to use those, you must not use the --no-updates parameter. Do a normal import, add the external data and once you are done with everything run nominatim freeze . Reverse-only Imports \uf0c1 If you only want to use the Nominatim database for reverse lookups or if you plan to use the installation only for exports to a photon database, then you can set up a database without search indexes. Add --reverse-only to your setup command above. This saves about 5% of disk space. Filtering Imported Data \uf0c1 Nominatim normally sets up a full search database containing administrative boundaries, places, streets, addresses and POI data. There are also other import styles available which only read selected data: admin Only import administrative boundaries and places. street Like the admin style but also adds streets. address Import all data necessary to compute addresses down to house number level. full Default style that also includes points of interest. extratags Like the full style but also adds most of the OSM tags into the extratags column. The style can be changed with the configuration NOMINATIM_IMPORT_STYLE . To give you an idea of the impact of using the different styles, the table below gives rough estimates of the final database size after import of a 2020 planet and after using the --drop option. It also shows the time needed for the import on a machine with 64GB RAM, 4 CPUS and NVME disks. Note that the given sizes are just an estimate meant for comparison of style requirements. Your planet import is likely to be larger as the OSM data grows with time. style Import time DB size after drop admin 4h 215 GB 20 GB street 22h 440 GB 185 GB address 36h 545 GB 260 GB full 54h 640 GB 330 GB extratags 54h 650 GB 340 GB You can also customize the styles further. A description of the style format can be found in the customization guide. Initial import of the data \uf0c1 Important First try the import with a small extract, for example from Geofabrik . Download the data to import. Then issue the following command from the project directory to start the import: nominatim import --osm-file <data file> 2 > & 1 | tee setup.log The project directory is the one that you have set up at the beginning. See creating the project directory . Notes on full planet imports \uf0c1 Even on a perfectly configured machine the import of a full planet takes around 2 days. Once you see messages with Rank .. ETA appear, the indexing process has started. This part takes the most time. There are 30 ranks to process. Rank 26 and 30 are the most complex. They take each about a third of the total import time. If you have not reached rank 26 after two days of import, it is worth revisiting your system configuration as it may not be optimal for the import. Notes on memory usage \uf0c1 In the first step of the import Nominatim uses osm2pgsql to load the OSM data into the PostgreSQL database. This step is very demanding in terms of RAM usage. osm2pgsql and PostgreSQL are running in parallel at this point. PostgreSQL blocks at least the part of RAM that has been configured with the shared_buffers parameter during PostgreSQL tuning and needs some memory on top of that. osm2pgsql needs at least 2GB of RAM for its internal data structures, potentially more when it has to process very large relations. In addition it needs to maintain a cache for node locations. The size of this cache can be configured with the parameter --osm2pgsql-cache . When importing with a flatnode file, it is best to disable the node cache completely and leave the memory for the flatnode file. Nominatim will do this by default, so you do not need to configure anything in this case. For imports without a flatnode file, set --osm2pgsql-cache approximately to the size of the OSM pbf file you are importing. The size needs to be given in MB. Make sure you leave enough RAM for PostgreSQL and osm2pgsql as mentioned above. If the system starts swapping or you are getting out-of-memory errors, reduce the cache size or even consider using a flatnode file. Testing the installation \uf0c1 Run this script to verify that all required tables and indices got created successfully. nominatim admin --check-database Now you can try out your installation by running: nominatim serve This runs a small test server normally used for development. You can use it to verify that your installation is working. Go to http://localhost:8088/status.php and you should see the message OK . You can also run a search query, e.g. http://localhost:8088/search.php?q=Berlin . Note that search query is not supported for reverse-only imports. You can run a reverse query, e.g. http://localhost:8088/reverse.php?lat=27.1750090510034&lon=78.04209025 . To run Nominatim via webservers like Apache or nginx, please read the Deployment chapter . Adding search through category phrases \uf0c1 If you want to be able to search for places by their type through special phrases you also need to import these key phrases like this: nominatim special-phrases --import-from-wiki Note that this command downloads the phrases from the wiki link above. You need internet access for the step. You can also import special phrases from a csv file, for more information please see the Customization part .","title":"Import"},{"location":"admin/Import/#importing-the-database","text":"The following instructions explain how to create a Nominatim database from an OSM planet file. It is assumed that you have already successfully installed the Nominatim software itself and the nominatim tool can be found in your PATH . If this is not the case, return to the installation page .","title":"Importing the Database"},{"location":"admin/Import/#creating-the-project-directory","text":"Before you start the import, you should create a project directory for your new database installation. This directory receives all data that is related to a single Nominatim setup: configuration, extra data, etc. Create a project directory apart from the Nominatim software and change into the directory: mkdir ~/nominatim-planet cd ~/nominatim-planet In the following, we refer to the project directory as $PROJECT_DIR . To be able to copy&paste instructions, you can export the appropriate variable: export PROJECT_DIR =~/ nominatim - planet The Nominatim tool assumes per default that the current working directory is the project directory but you may explicitly state a different directory using the --project-dir parameter. The following instructions assume that you run all commands from the project directory. Migration Tip Nominatim used to be run directly from the build directory until version 3.6. Essentially, the build directory functioned as the project directory for the database installation. This setup still works and can be useful for development purposes. It is not recommended anymore for production setups. Create a project directory that is separate from the Nominatim software.","title":"Creating the project directory"},{"location":"admin/Import/#configuration-setup-in-env","text":"The Nominatim server can be customized via an .env configuration file in the project directory. This is a file in dotenv format which looks the same as variable settings in a standard shell environment. You can also set the same configuration via environment variables. All settings have a NOMINATIM_ prefix to avoid conflicts with other environment variables. There are lots of configuration settings you can tweak. A full reference can be found in the chapter Configuration Settings . Most should have a sensible default.","title":"Configuration setup in .env"},{"location":"admin/Import/#flatnode-files","text":"If you plan to import a large dataset (e.g. Europe, North America, planet), you should also enable flatnode storage of node locations. With this setting enabled, node coordinates are stored in a simple file instead of the database. This will save you import time and disk storage. Add to your .env : NOMINATIM_FLATNODE_FILE=\"/path/to/flatnode.file\" Replace the second part with a suitable path on your system and make sure the directory exists. There should be at least 75GB of free space.","title":"Flatnode files"},{"location":"admin/Import/#downloading-additional-data","text":"","title":"Downloading additional data"},{"location":"admin/Import/#wikipediawikidata-rankings","text":"Wikipedia can be used as an optional auxiliary data source to help indicate the importance of OSM features. Nominatim will work without this information but it will improve the quality of the results if this is installed. This data is available as a binary download. Put it into your project directory: cd $PROJECT_DIR wget https://www.nominatim.org/data/wikimedia-importance.sql.gz The file is about 400MB and adds around 4GB to the Nominatim database. Tip If you forgot to download the wikipedia rankings, you can also add importances after the import. Download the files, then run nominatim refresh --wiki-data --importance . Updating importances for a planet can take a couple of hours.","title":"Wikipedia/Wikidata rankings"},{"location":"admin/Import/#external-postcodes","text":"Nominatim can use postcodes from an external source to improve searching with postcodes. We provide precomputed postcodes sets for the US (using TIGER data) and the UK (using the CodePoint OpenData set . This data can be optionally downloaded into the project directory: cd $PROJECT_DIR wget https://www.nominatim.org/data/gb_postcodes.csv.gz wget https://www.nominatim.org/data/us_postcodes.csv.gz You can also add your own custom postcode sources, see Customization of postcodes .","title":"External postcodes"},{"location":"admin/Import/#choosing-the-data-to-import","text":"In its default setup Nominatim is configured to import the full OSM data set for the entire planet. Such a setup requires a powerful machine with at least 64GB of RAM and around 900GB of SSD hard disks. Depending on your use case there are various ways to reduce the amount of data imported. This section discusses these methods. They can also be combined.","title":"Choosing the data to import"},{"location":"admin/Import/#using-an-extract","text":"If you only need geocoding for a smaller region, then precomputed OSM extracts are a good way to reduce the database size and import time. Geofabrik offers extracts for most countries. They even have daily updates which can be used with the update process described in the next section . There are also other providers for extracts . Please be aware that some extracts are not cut exactly along the country boundaries. As a result some parts of the boundary may be missing which means that Nominatim cannot compute the areas for some administrative areas.","title":"Using an extract"},{"location":"admin/Import/#dropping-data-required-for-dynamic-updates","text":"About half of the data in Nominatim's database is not really used for serving the API. It is only there to allow the data to be updated from the latest changes from OSM. For many uses these dynamic updates are not really required. If you don't plan to apply updates, you can run the import with the --no-updates parameter. This will drop the dynamic part of the database as soon as it is not required anymore. You can also drop the dynamic part later using the following command: nominatim freeze Note that you still need to provide for sufficient disk space for the initial import. So this option is particularly interesting if you plan to transfer the database or reuse the space later. Warning The datastructure for updates are also required when adding additional data after the import, for example TIGER housenumber data . If you plan to use those, you must not use the --no-updates parameter. Do a normal import, add the external data and once you are done with everything run nominatim freeze .","title":"Dropping Data Required for Dynamic Updates"},{"location":"admin/Import/#reverse-only-imports","text":"If you only want to use the Nominatim database for reverse lookups or if you plan to use the installation only for exports to a photon database, then you can set up a database without search indexes. Add --reverse-only to your setup command above. This saves about 5% of disk space.","title":"Reverse-only Imports"},{"location":"admin/Import/#filtering-imported-data","text":"Nominatim normally sets up a full search database containing administrative boundaries, places, streets, addresses and POI data. There are also other import styles available which only read selected data: admin Only import administrative boundaries and places. street Like the admin style but also adds streets. address Import all data necessary to compute addresses down to house number level. full Default style that also includes points of interest. extratags Like the full style but also adds most of the OSM tags into the extratags column. The style can be changed with the configuration NOMINATIM_IMPORT_STYLE . To give you an idea of the impact of using the different styles, the table below gives rough estimates of the final database size after import of a 2020 planet and after using the --drop option. It also shows the time needed for the import on a machine with 64GB RAM, 4 CPUS and NVME disks. Note that the given sizes are just an estimate meant for comparison of style requirements. Your planet import is likely to be larger as the OSM data grows with time. style Import time DB size after drop admin 4h 215 GB 20 GB street 22h 440 GB 185 GB address 36h 545 GB 260 GB full 54h 640 GB 330 GB extratags 54h 650 GB 340 GB You can also customize the styles further. A description of the style format can be found in the customization guide.","title":"Filtering Imported Data"},{"location":"admin/Import/#initial-import-of-the-data","text":"Important First try the import with a small extract, for example from Geofabrik . Download the data to import. Then issue the following command from the project directory to start the import: nominatim import --osm-file <data file> 2 > & 1 | tee setup.log The project directory is the one that you have set up at the beginning. See creating the project directory .","title":"Initial import of the data"},{"location":"admin/Import/#notes-on-full-planet-imports","text":"Even on a perfectly configured machine the import of a full planet takes around 2 days. Once you see messages with Rank .. ETA appear, the indexing process has started. This part takes the most time. There are 30 ranks to process. Rank 26 and 30 are the most complex. They take each about a third of the total import time. If you have not reached rank 26 after two days of import, it is worth revisiting your system configuration as it may not be optimal for the import.","title":"Notes on full planet imports"},{"location":"admin/Import/#notes-on-memory-usage","text":"In the first step of the import Nominatim uses osm2pgsql to load the OSM data into the PostgreSQL database. This step is very demanding in terms of RAM usage. osm2pgsql and PostgreSQL are running in parallel at this point. PostgreSQL blocks at least the part of RAM that has been configured with the shared_buffers parameter during PostgreSQL tuning and needs some memory on top of that. osm2pgsql needs at least 2GB of RAM for its internal data structures, potentially more when it has to process very large relations. In addition it needs to maintain a cache for node locations. The size of this cache can be configured with the parameter --osm2pgsql-cache . When importing with a flatnode file, it is best to disable the node cache completely and leave the memory for the flatnode file. Nominatim will do this by default, so you do not need to configure anything in this case. For imports without a flatnode file, set --osm2pgsql-cache approximately to the size of the OSM pbf file you are importing. The size needs to be given in MB. Make sure you leave enough RAM for PostgreSQL and osm2pgsql as mentioned above. If the system starts swapping or you are getting out-of-memory errors, reduce the cache size or even consider using a flatnode file.","title":"Notes on memory usage"},{"location":"admin/Import/#testing-the-installation","text":"Run this script to verify that all required tables and indices got created successfully. nominatim admin --check-database Now you can try out your installation by running: nominatim serve This runs a small test server normally used for development. You can use it to verify that your installation is working. Go to http://localhost:8088/status.php and you should see the message OK . You can also run a search query, e.g. http://localhost:8088/search.php?q=Berlin . Note that search query is not supported for reverse-only imports. You can run a reverse query, e.g. http://localhost:8088/reverse.php?lat=27.1750090510034&lon=78.04209025 . To run Nominatim via webservers like Apache or nginx, please read the Deployment chapter .","title":"Testing the installation"},{"location":"admin/Import/#adding-search-through-category-phrases","text":"If you want to be able to search for places by their type through special phrases you also need to import these key phrases like this: nominatim special-phrases --import-from-wiki Note that this command downloads the phrases from the wiki link above. You need internet access for the step. You can also import special phrases from a csv file, for more information please see the Customization part .","title":"Adding search through category phrases"},{"location":"admin/Installation/","text":"Basic Installation \uf0c1 This page contains generic installation instructions for Nominatim and its prerequisites. There are also step-by-step instructions available for the following operating systems: Ubuntu 22.04 Ubuntu 20.04 Ubuntu 18.04 These OS-specific instructions can also be found in executable form in the vagrant/ directory. Users have created instructions for other frameworks. We haven't tested those and can't offer support. Docker Docker on Kubernetes Kubernetes with Helm Ansible Prerequisites \uf0c1 Software \uf0c1 Warning For larger installations you must have PostgreSQL 11+ and PostGIS 3+ otherwise import and queries will be slow to the point of being unusable. Query performance has marked improvements with PostgreSQL 13+ and PostGIS 3.2+. For compiling: cmake expat proj bzip2 zlib ICU Boost libraries , including system and filesystem PostgreSQL client libraries a recent C++ compiler (gcc 5+ or Clang 3.8+) For running Nominatim: PostgreSQL (9.6+ will work, 11+ strongly recommended) PostGIS (2.2+ will work, 3.0+ strongly recommended) Python 3 (3.6+) Psycopg2 (2.7+) Python Dotenv psutil Jinja2 PyICU PyYaml (5.1+) datrie PHP (7.0 or later) PHP-pgsql PHP-intl (bundled with PHP) PHP-cgi (for running queries from the command line) For running continuous updates: pyosmium For dependencies for running tests and building documentation, see the Development section . Hardware \uf0c1 A minimum of 2GB of RAM is required or installation will fail. For a full planet import 128GB of RAM or more are strongly recommended. Do not report out of memory problems if you have less than 64GB RAM. For a full planet install you will need at least 1TB of hard disk space. Take into account that the OSM database is growing fast. Fast disks are essential. Using NVME disks is recommended. Even on a well configured machine the import of a full planet takes around 2 days. On traditional spinning disks, 7-8 days are more realistic. Tuning the PostgreSQL database \uf0c1 You might want to tune your PostgreSQL installation so that the later steps make best use of your hardware. You should tune the following parameters in your postgresql.conf file. shared_buffers = 2GB maintenance_work_mem = (10GB) autovacuum_work_mem = 2GB work_mem = (50MB) effective_cache_size = (24GB) synchronous_commit = off max_wal_size = 1GB checkpoint_timeout = 10min checkpoint_completion_target = 0.9 The numbers in brackets behind some parameters seem to work fine for 64GB RAM machine. Adjust to your setup. A higher number for max_wal_size means that PostgreSQL needs to run checkpoints less often but it does require the additional space on your disk. Autovacuum must not be switched off because it ensures that the tables are frequently analysed. If your machine has very little memory, you might consider setting: autovacuum_max_workers = 1 and even reduce autovacuum_work_mem further. This will reduce the amount of memory that autovacuum takes away from the import process. For the initial import, you should also set: fsync = off full_page_writes = off Don't forget to re-enable them after the initial import or you risk database corruption. Downloading and building Nominatim \uf0c1 Downloading the latest release \uf0c1 You can download the latest release from nominatim.org . The release contains all necessary files. Just unpack it. Downloading the latest development version \uf0c1 If you want to install latest development version from github, make sure to also check out the osm2pgsql subproject: git clone --recursive https://github.com/openstreetmap/Nominatim.git The development version does not include the country grid. Download it separately: wget -O Nominatim/data/country_osm_grid.sql.gz https://www.nominatim.org/data/country_grid.sql.gz Building Nominatim \uf0c1 The code must be built in a separate directory. Create the directory and change into it. mkdir build cd build Nominatim uses cmake and make for building. Assuming that you have created the build at the same level as the Nominatim source directory run: cmake ../Nominatim make sudo make install Warning The default installation no longer compiles the PostgreSQL module that is needed for the legacy tokenizer from older Nominatim versions. If you are upgrading an older database or want to run the legacy tokenizer for some other reason, you need to enable the PostgreSQL module via cmake: cmake -DBUILD_MODULE=on ../Nominatim . To compile the module you need to have the server development headers for PostgreSQL installed. On Ubuntu/Debian run: sudo apt install postgresql-server-dev-<postgresql version> Nominatim installs itself into /usr/local per default. To choose a different installation directory add -DCMAKE_INSTALL_PREFIX=<install root> to the cmake command. Make sure that the bin directory is available in your path in that case, e.g. export PATH =< install root >/ bin : $ PATH Now continue with importing the database .","title":"Basic Installation"},{"location":"admin/Installation/#basic-installation","text":"This page contains generic installation instructions for Nominatim and its prerequisites. There are also step-by-step instructions available for the following operating systems: Ubuntu 22.04 Ubuntu 20.04 Ubuntu 18.04 These OS-specific instructions can also be found in executable form in the vagrant/ directory. Users have created instructions for other frameworks. We haven't tested those and can't offer support. Docker Docker on Kubernetes Kubernetes with Helm Ansible","title":"Basic Installation"},{"location":"admin/Installation/#prerequisites","text":"","title":"Prerequisites"},{"location":"admin/Installation/#software","text":"Warning For larger installations you must have PostgreSQL 11+ and PostGIS 3+ otherwise import and queries will be slow to the point of being unusable. Query performance has marked improvements with PostgreSQL 13+ and PostGIS 3.2+. For compiling: cmake expat proj bzip2 zlib ICU Boost libraries , including system and filesystem PostgreSQL client libraries a recent C++ compiler (gcc 5+ or Clang 3.8+) For running Nominatim: PostgreSQL (9.6+ will work, 11+ strongly recommended) PostGIS (2.2+ will work, 3.0+ strongly recommended) Python 3 (3.6+) Psycopg2 (2.7+) Python Dotenv psutil Jinja2 PyICU PyYaml (5.1+) datrie PHP (7.0 or later) PHP-pgsql PHP-intl (bundled with PHP) PHP-cgi (for running queries from the command line) For running continuous updates: pyosmium For dependencies for running tests and building documentation, see the Development section .","title":"Software"},{"location":"admin/Installation/#hardware","text":"A minimum of 2GB of RAM is required or installation will fail. For a full planet import 128GB of RAM or more are strongly recommended. Do not report out of memory problems if you have less than 64GB RAM. For a full planet install you will need at least 1TB of hard disk space. Take into account that the OSM database is growing fast. Fast disks are essential. Using NVME disks is recommended. Even on a well configured machine the import of a full planet takes around 2 days. On traditional spinning disks, 7-8 days are more realistic.","title":"Hardware"},{"location":"admin/Installation/#tuning-the-postgresql-database","text":"You might want to tune your PostgreSQL installation so that the later steps make best use of your hardware. You should tune the following parameters in your postgresql.conf file. shared_buffers = 2GB maintenance_work_mem = (10GB) autovacuum_work_mem = 2GB work_mem = (50MB) effective_cache_size = (24GB) synchronous_commit = off max_wal_size = 1GB checkpoint_timeout = 10min checkpoint_completion_target = 0.9 The numbers in brackets behind some parameters seem to work fine for 64GB RAM machine. Adjust to your setup. A higher number for max_wal_size means that PostgreSQL needs to run checkpoints less often but it does require the additional space on your disk. Autovacuum must not be switched off because it ensures that the tables are frequently analysed. If your machine has very little memory, you might consider setting: autovacuum_max_workers = 1 and even reduce autovacuum_work_mem further. This will reduce the amount of memory that autovacuum takes away from the import process. For the initial import, you should also set: fsync = off full_page_writes = off Don't forget to re-enable them after the initial import or you risk database corruption.","title":"Tuning the PostgreSQL database"},{"location":"admin/Installation/#downloading-and-building-nominatim","text":"","title":"Downloading and building Nominatim"},{"location":"admin/Installation/#downloading-the-latest-release","text":"You can download the latest release from nominatim.org . The release contains all necessary files. Just unpack it.","title":"Downloading the latest release"},{"location":"admin/Installation/#downloading-the-latest-development-version","text":"If you want to install latest development version from github, make sure to also check out the osm2pgsql subproject: git clone --recursive https://github.com/openstreetmap/Nominatim.git The development version does not include the country grid. Download it separately: wget -O Nominatim/data/country_osm_grid.sql.gz https://www.nominatim.org/data/country_grid.sql.gz","title":"Downloading the latest development version"},{"location":"admin/Installation/#building-nominatim","text":"The code must be built in a separate directory. Create the directory and change into it. mkdir build cd build Nominatim uses cmake and make for building. Assuming that you have created the build at the same level as the Nominatim source directory run: cmake ../Nominatim make sudo make install Warning The default installation no longer compiles the PostgreSQL module that is needed for the legacy tokenizer from older Nominatim versions. If you are upgrading an older database or want to run the legacy tokenizer for some other reason, you need to enable the PostgreSQL module via cmake: cmake -DBUILD_MODULE=on ../Nominatim . To compile the module you need to have the server development headers for PostgreSQL installed. On Ubuntu/Debian run: sudo apt install postgresql-server-dev-<postgresql version> Nominatim installs itself into /usr/local per default. To choose a different installation directory add -DCMAKE_INSTALL_PREFIX=<install root> to the cmake command. Make sure that the bin directory is available in your path in that case, e.g. export PATH =< install root >/ bin : $ PATH Now continue with importing the database .","title":"Building Nominatim"},{"location":"admin/Maintenance/","text":"This chapter describes the various operations the Nominatim database administrator may use to clean and maintain the database. None of these operations is mandatory but they may help improve the performance and accuracy of results. Updating postcodes \uf0c1 Command: nominatim refresh --postcodes Postcode centroids (aka 'calculated postcodes') are generated by looking at all postcodes of a country, grouping them and calculating the geometric centroid. There is currently no logic to deal with extreme outliers (typos or other mistakes in OSM data). There is also no check if a postcodes adheres to a country's format, e.g. if Swiss postcodes are 4 digits. When running regular updates, postcodes results can be improved by running this command on a regular basis. Note that only the postcode table and the postcode search terms are updated. The postcode that is assigned to each place is only updated when the place is updated. The command takes around 70min to run on the planet and needs ca. 40GB of temporary disk space. Updating word counts \uf0c1 Command: nominatim refresh --word-counts Nominatim keeps frequency statistics about all search terms it indexes. These statistics are currently used to optimise queries to the database. Thus better statistics mean better performance. Word counts are created once after import and are usually sufficient even when running regular updates. You might want to rerun the statistics computation when adding larger amounts of new data, for example, when adding an additional country via nominatim add-data . Forcing recomputation of places and areas \uf0c1 Command: nominatim refresh --data-object [NWR]<id> --data-area [NWR]<id> When running replication updates, Nominatim tries to recompute the search and address information for all places that are affected by a change. But it needs to restrict the total number of changes to make sure it can keep up with the minutely updates. Therefore it will refrain from propagating changes that affect a lot of objects. The administrator may force an update of places in the database. nominatim refresh --data-object invalidates a single OSM object. nominatim refresh --data-area invalidates an OSM object and all dependent objects. That are usually the places that inside its area or around the center of the object. Both commands expect the OSM object as an argument of the form OSM type + OSM id. The type must be N (node), W (way) or R (relation). After invalidating the object, indexing must be run again. If continuous update are running in the background, the objects will be recomputed together with the next round of updates. Otherwise you need to run nominatim index to finish the recomputation. Removing large deleted objects \uf0c1 Nominatim refuses to delete very large areas because often these deletions are accidental and are reverted within hours. Instead the deletions are logged in the import_polygon_delete table and left to the administrator to clean up. There is currently no command to do that. You can use the following SQL query to force a deletion on all objects that have been deleted more than a certain timespan ago (here: 1 month): SELECT place_force_delete ( p . place_id ) FROM import_polygon_delete d , placex p WHERE p . osm_type = d . osm_type and p . osm_id = d . osm_id and age ( p . indexed_date ) > '1 month' :: interval","title":"Maintenance"},{"location":"admin/Maintenance/#updating-postcodes","text":"Command: nominatim refresh --postcodes Postcode centroids (aka 'calculated postcodes') are generated by looking at all postcodes of a country, grouping them and calculating the geometric centroid. There is currently no logic to deal with extreme outliers (typos or other mistakes in OSM data). There is also no check if a postcodes adheres to a country's format, e.g. if Swiss postcodes are 4 digits. When running regular updates, postcodes results can be improved by running this command on a regular basis. Note that only the postcode table and the postcode search terms are updated. The postcode that is assigned to each place is only updated when the place is updated. The command takes around 70min to run on the planet and needs ca. 40GB of temporary disk space.","title":"Updating postcodes"},{"location":"admin/Maintenance/#updating-word-counts","text":"Command: nominatim refresh --word-counts Nominatim keeps frequency statistics about all search terms it indexes. These statistics are currently used to optimise queries to the database. Thus better statistics mean better performance. Word counts are created once after import and are usually sufficient even when running regular updates. You might want to rerun the statistics computation when adding larger amounts of new data, for example, when adding an additional country via nominatim add-data .","title":"Updating word counts"},{"location":"admin/Maintenance/#forcing-recomputation-of-places-and-areas","text":"Command: nominatim refresh --data-object [NWR]<id> --data-area [NWR]<id> When running replication updates, Nominatim tries to recompute the search and address information for all places that are affected by a change. But it needs to restrict the total number of changes to make sure it can keep up with the minutely updates. Therefore it will refrain from propagating changes that affect a lot of objects. The administrator may force an update of places in the database. nominatim refresh --data-object invalidates a single OSM object. nominatim refresh --data-area invalidates an OSM object and all dependent objects. That are usually the places that inside its area or around the center of the object. Both commands expect the OSM object as an argument of the form OSM type + OSM id. The type must be N (node), W (way) or R (relation). After invalidating the object, indexing must be run again. If continuous update are running in the background, the objects will be recomputed together with the next round of updates. Otherwise you need to run nominatim index to finish the recomputation.","title":"Forcing recomputation of places and areas"},{"location":"admin/Maintenance/#removing-large-deleted-objects","text":"Nominatim refuses to delete very large areas because often these deletions are accidental and are reverted within hours. Instead the deletions are logged in the import_polygon_delete table and left to the administrator to clean up. There is currently no command to do that. You can use the following SQL query to force a deletion on all objects that have been deleted more than a certain timespan ago (here: 1 month): SELECT place_force_delete ( p . place_id ) FROM import_polygon_delete d , placex p WHERE p . osm_type = d . osm_type and p . osm_id = d . osm_id and age ( p . indexed_date ) > '1 month' :: interval","title":"Removing large deleted objects"},{"location":"admin/Migration/","text":"Database Migrations \uf0c1 Since version 3.7.0 Nominatim offers automatic migrations. Please follow the following steps: stop any updates that are potentially running update Nominatim to the newer version go to your project directory and run nominatim admin --migrate (optionally) restart updates Below you find additional migrations and hints about other structural and breaking changes. Please read them before running the migration. Note If you are migrating from a version <3.6, then you still have to follow the manual migration steps up to 3.6. 4.0.0 -> 4.1.0 \uf0c1 ICU tokenizer is the new default \uf0c1 Nominatim now installs the ICU tokenizer by default. This only has an effect on newly installed databases. When updating older databases, it keeps its installed tokenizer. If you still run with the legacy tokenizer, make sure to compile Nominatim with the PostgreSQL module, see Installation . geocodejson output changed \uf0c1 The type field of the geocodejson output has changed. It now contains the address class of the object instead of the value of the OSM tag. If your client has used the type field, switch them to read osm_value instead. 3.7.0 -> 4.0.0 \uf0c1 NOMINATIM_PHRASE_CONFIG removed \uf0c1 Custom blacklist configurations for special phrases now need to be handed with the --config parameter to nominatim special-phrases . Alternatively you can put your custom configuration in the project directory in a file named phrase-settings.json . Version 3.8 also removes the automatic converter for the php format of the configuration in older versions. If you are updating from Nominatim < 3.7 and still work with a custom phrase-settings.php , you need to manually convert it into a json format. PHP utils removed \uf0c1 The old PHP utils have now been removed completely. You need to switch to the appropriate functions of the nominatim command line tool. See Introducing nominatim command line tool below. 3.6.0 -> 3.7.0 \uf0c1 New format and name of configuration file \uf0c1 The configuration for an import is now saved in a .env file in the project directory. This file follows the dotenv format. For more information, see the installation chapter . To migrate to the new system, create a new project directory, add the .env file and port your custom configuration from settings/local.php . Most settings are named similar and only have received a NOMINATIM_ prefix. Use the default settings in settings/env.defaults as a reference. New location for data files \uf0c1 External data files for Wikipedia importance, postcodes etc. are no longer expected to reside in the source tree by default. Instead they will be searched in the project directory. If you have an automated setup script you must either adapt the download location or explicitly set the location of the files to the old place in your .env . Introducing nominatim command line tool \uf0c1 The various php utilities have been replaced with a single nominatim command line tool. Make sure to adapt any scripts. There is no direct 1:1 matching between the old utilities and the commands of nominatim CLI. The following list gives you a list of nominatim sub-commands that contain functionality of each script: ./utils/setup.php: import , freeze , refresh ./utils/update.php: replication , add-data , index , refresh ./utils/specialphrases.php: special-phrases ./utils/check_import_finished.php: admin ./utils/warm.php: admin ./utils/export.php: export Try nominatim <command> --help for more information about each subcommand. ./utils/query.php no longer exists in its old form. nominatim search provides a replacement but returns different output. Switch to normalized house numbers \uf0c1 The housenumber column in the placex table uses now normalized version. The automatic migration step will convert the column but this may take a very long time. It is advisable to take the machine offline while doing that. 3.5.0 -> 3.6.0 \uf0c1 Change of layout of search_name_* tables \uf0c1 The table need a different index for nearest place lookup. Recreate the indexes using the following shell script: for table in ` psql -d nominatim -c \"SELECT tablename FROM pg_tables WHERE tablename LIKE 'search_name_%'\" -tA | grep -v search_name_blank ` ; do psql -d nominatim -c \"DROP INDEX idx_ ${ table } _centroid_place; CREATE INDEX idx_ ${ table } _centroid_place ON ${ table } USING gist (centroid) WHERE ((address_rank >= 2) AND (address_rank <= 25)); DROP INDEX idx_ ${ table } _centroid_street; CREATE INDEX idx_ ${ table } _centroid_street ON ${ table } USING gist (centroid) WHERE ((address_rank >= 26) AND (address_rank <= 27))\" ; done Removal of html output \uf0c1 The debugging UI is no longer directly provided with Nominatim. Instead we now provide a simple Javascript application. Please refer to Setting up the Nominatim UI for details on how to set up the UI. The icons served together with the API responses have been moved to the nominatim-ui project as well. If you want to keep the icon field in the response, you need to set CONST_MapIcon_URL to the URL of the /mapicon directory of nominatim-ui. Change order during indexing \uf0c1 When reindexing places during updates, there is now a different order used which needs a different database index. Create it with the following SQL command: CREATE INDEX idx_placex_pendingsector_rank_address ON placex USING BTREE ( rank_address , geometry_sector ) WHERE indexed_status > 0 ; You can then drop the old index with: DROP INDEX idx_placex_pendingsector ; Unused index \uf0c1 This index has been unused ever since the query using it was changed two years ago. Saves about 12GB on a planet installation. DROP INDEX idx_placex_geometry_reverse_lookupPoint ; Switching to dotenv \uf0c1 As part of the work changing the configuration format, the configuration for the website is now using a separate configuration file. To create the configuration file, run the following command after updating: ./utils/setup.php --setup-website Update SQL code \uf0c1 To update the SQL code to the leatest version run: ./utils/setup.php --create-functions --enable-diff-updates --create-partition-functions 3.4.0 -> 3.5.0 \uf0c1 New Wikipedia/Wikidata importance tables \uf0c1 The wikipedia_* tables have a new format that also includes references to Wikidata. You need to update the computation functions and the tables as follows: download the new Wikipedia tables as described in the import section reimport the tables: ./utils/setup.php --import-wikipedia-articles update the functions: ./utils/setup.php --create-functions --enable-diff-updates create a new lookup index: CREATE INDEX idx_placex_wikidata ON placex USING BTREE (( extratags -> 'wikidata' )) WHERE extratags ? 'wikidata' AND class = 'place' AND osm_type = 'N' AND rank_search < 26 ; compute importance: ./utils/update.php --recompute-importance The last step takes about 10 hours on the full planet. Remove one function (it will be recreated in the next step): DROP FUNCTION create_country ( hstore , character varying ); Finally, update all SQL functions: ./utils/setup.php --create-functions --enable-diff-updates --create-partition-functions 3.3.0 -> 3.4.0 \uf0c1 Reorganisation of location_area_country table \uf0c1 The table location_area_country has been optimized. You need to switch to the new format when you run updates. While updates are disabled, run the following SQL commands: CREATE TABLE location_area_country_new AS SELECT place_id , country_code , geometry FROM location_area_country ; DROP TABLE location_area_country ; ALTER TABLE location_area_country_new RENAME TO location_area_country ; CREATE INDEX idx_location_area_country_geometry ON location_area_country USING GIST ( geometry ); CREATE INDEX idx_location_area_country_place_id ON location_area_country USING BTREE ( place_id ); Finally, update all SQL functions: ./utils/setup.php --create-functions --enable-diff-updates --create-partition-functions 3.2.0 -> 3.3.0 \uf0c1 New database connection string (DSN) format \uf0c1 Previously database connection setting ( CONST_Database_DSN in settings/*.php ) had the format (simple) pgsql://@/nominatim (complex) pgsql://johndoe:secret@machine1.domain.com:1234/db1 The new format is (simple) pgsql:dbname=nominatim (complex) pgsql:dbname=db1;host=machine1.domain.com;port=1234;user=johndoe;password=secret Natural Earth country boundaries no longer needed as fallback \uf0c1 DROP TABLE country_naturalearthdata ; Finally, update all SQL functions: ./utils/setup.php --create-functions --enable-diff-updates --create-partition-functions Configurable Address Levels \uf0c1 The new configurable address levels require a new table. Create it with the following command: ./utils/update.php --update-address-levels 3.1.0 -> 3.2.0 \uf0c1 New reverse algorithm \uf0c1 The reverse algorithm has changed and requires new indexes. Run the following SQL statements to create the indexes: CREATE INDEX idx_placex_geometry_reverse_lookupPoint ON placex USING gist ( geometry ) WHERE ( name IS NOT null or housenumber IS NOT null or rank_address BETWEEN 26 AND 27 ) AND class NOT IN ( 'railway' , 'tunnel' , 'bridge' , 'man_made' ) AND rank_address >= 26 AND indexed_status = 0 AND linked_place_id IS null ; CREATE INDEX idx_placex_geometry_reverse_lookupPolygon ON placex USING gist ( geometry ) WHERE St_GeometryType ( geometry ) in ( 'ST_Polygon' , 'ST_MultiPolygon' ) AND rank_address between 4 and 25 AND type != 'postcode' AND name is not null AND indexed_status = 0 AND linked_place_id is null ; CREATE INDEX idx_placex_geometry_reverse_placeNode ON placex USING gist ( geometry ) WHERE osm_type = 'N' AND rank_search between 5 and 25 AND class = 'place' AND type != 'postcode' AND name is not null AND indexed_status = 0 AND linked_place_id is null ; You also need to grant the website user access to the country_osm_grid table: GRANT SELECT ON table country_osm_grid to \"www-user\" ; Replace the www-user with the user name of your website server if necessary. You can now drop the unused indexes: DROP INDEX idx_placex_reverse_geometry ; Finally, update all SQL functions: ./utils/setup.php --create-functions --enable-diff-updates --create-partition-functions 3.0.0 -> 3.1.0 \uf0c1 Postcode Table \uf0c1 A new separate table for artificially computed postcode centroids was introduced. Migration to the new format is possible but not recommended . Create postcode table and indexes, running the following SQL statements: CREATE TABLE location_postcode ( place_id BIGINT , parent_place_id BIGINT , rank_search SMALLINT , rank_address SMALLINT , indexed_status SMALLINT , indexed_date TIMESTAMP , country_code varchar ( 2 ), postcode TEXT , geometry GEOMETRY ( Geometry , 4326 )); CREATE INDEX idx_postcode_geometry ON location_postcode USING GIST ( geometry ); CREATE UNIQUE INDEX idx_postcode_id ON location_postcode USING BTREE ( place_id ); CREATE INDEX idx_postcode_postcode ON location_postcode USING BTREE ( postcode ); GRANT SELECT ON location_postcode TO \"www-data\" ; DROP TYPE IF EXISTS nearfeaturecentr CASCADE ; CREATE TYPE nearfeaturecentr AS ( place_id BIGINT , keywords int [], rank_address smallint , rank_search smallint , distance float , isguess boolean , postcode TEXT , centroid GEOMETRY ); Add postcode column to location_area tables with SQL statement: ALTER TABLE location_area ADD COLUMN postcode TEXT ; Then reimport the functions: ./utils/setup.php --create-functions --enable-diff-updates --create-partition-functions Create appropriate triggers with SQL: CREATE TRIGGER location_postcode_before_update BEFORE UPDATE ON location_postcode FOR EACH ROW EXECUTE PROCEDURE postcode_update (); Finally populate the postcode table (will take a while): ./utils/setup.php --calculate-postcodes --index --index-noanalyse This will create a working database. You may also delete the old artificial postcodes now. Note that this may be expensive and is not absolutely necessary. The following SQL statement will remove them: DELETE FROM place_addressline a USING placex p WHERE a . address_place_id = p . place_id and p . osm_type = 'P' ; ALTER TABLE placex DISABLE TRIGGER USER ; DELETE FROM placex WHERE osm_type = 'P' ; ALTER TABLE placex ENABLE TRIGGER USER ;","title":"Migration from older Versions"},{"location":"admin/Migration/#database-migrations","text":"Since version 3.7.0 Nominatim offers automatic migrations. Please follow the following steps: stop any updates that are potentially running update Nominatim to the newer version go to your project directory and run nominatim admin --migrate (optionally) restart updates Below you find additional migrations and hints about other structural and breaking changes. Please read them before running the migration. Note If you are migrating from a version <3.6, then you still have to follow the manual migration steps up to 3.6.","title":"Database Migrations"},{"location":"admin/Migration/#400-410","text":"","title":"4.0.0 -&gt; 4.1.0"},{"location":"admin/Migration/#icu-tokenizer-is-the-new-default","text":"Nominatim now installs the ICU tokenizer by default. This only has an effect on newly installed databases. When updating older databases, it keeps its installed tokenizer. If you still run with the legacy tokenizer, make sure to compile Nominatim with the PostgreSQL module, see Installation .","title":"ICU tokenizer is the new default"},{"location":"admin/Migration/#geocodejson-output-changed","text":"The type field of the geocodejson output has changed. It now contains the address class of the object instead of the value of the OSM tag. If your client has used the type field, switch them to read osm_value instead.","title":"geocodejson output changed"},{"location":"admin/Migration/#370-400","text":"","title":"3.7.0 -&gt; 4.0.0"},{"location":"admin/Migration/#nominatim_phrase_config-removed","text":"Custom blacklist configurations for special phrases now need to be handed with the --config parameter to nominatim special-phrases . Alternatively you can put your custom configuration in the project directory in a file named phrase-settings.json . Version 3.8 also removes the automatic converter for the php format of the configuration in older versions. If you are updating from Nominatim < 3.7 and still work with a custom phrase-settings.php , you need to manually convert it into a json format.","title":"NOMINATIM_PHRASE_CONFIG removed"},{"location":"admin/Migration/#php-utils-removed","text":"The old PHP utils have now been removed completely. You need to switch to the appropriate functions of the nominatim command line tool. See Introducing nominatim command line tool below.","title":"PHP utils removed"},{"location":"admin/Migration/#360-370","text":"","title":"3.6.0 -&gt; 3.7.0"},{"location":"admin/Migration/#new-format-and-name-of-configuration-file","text":"The configuration for an import is now saved in a .env file in the project directory. This file follows the dotenv format. For more information, see the installation chapter . To migrate to the new system, create a new project directory, add the .env file and port your custom configuration from settings/local.php . Most settings are named similar and only have received a NOMINATIM_ prefix. Use the default settings in settings/env.defaults as a reference.","title":"New format and name of configuration file"},{"location":"admin/Migration/#new-location-for-data-files","text":"External data files for Wikipedia importance, postcodes etc. are no longer expected to reside in the source tree by default. Instead they will be searched in the project directory. If you have an automated setup script you must either adapt the download location or explicitly set the location of the files to the old place in your .env .","title":"New location for data files"},{"location":"admin/Migration/#introducing-nominatim-command-line-tool","text":"The various php utilities have been replaced with a single nominatim command line tool. Make sure to adapt any scripts. There is no direct 1:1 matching between the old utilities and the commands of nominatim CLI. The following list gives you a list of nominatim sub-commands that contain functionality of each script: ./utils/setup.php: import , freeze , refresh ./utils/update.php: replication , add-data , index , refresh ./utils/specialphrases.php: special-phrases ./utils/check_import_finished.php: admin ./utils/warm.php: admin ./utils/export.php: export Try nominatim <command> --help for more information about each subcommand. ./utils/query.php no longer exists in its old form. nominatim search provides a replacement but returns different output.","title":"Introducing nominatim command line tool"},{"location":"admin/Migration/#switch-to-normalized-house-numbers","text":"The housenumber column in the placex table uses now normalized version. The automatic migration step will convert the column but this may take a very long time. It is advisable to take the machine offline while doing that.","title":"Switch to normalized house numbers"},{"location":"admin/Migration/#350-360","text":"","title":"3.5.0 -&gt; 3.6.0"},{"location":"admin/Migration/#change-of-layout-of-search_name_-tables","text":"The table need a different index for nearest place lookup. Recreate the indexes using the following shell script: for table in ` psql -d nominatim -c \"SELECT tablename FROM pg_tables WHERE tablename LIKE 'search_name_%'\" -tA | grep -v search_name_blank ` ; do psql -d nominatim -c \"DROP INDEX idx_ ${ table } _centroid_place; CREATE INDEX idx_ ${ table } _centroid_place ON ${ table } USING gist (centroid) WHERE ((address_rank >= 2) AND (address_rank <= 25)); DROP INDEX idx_ ${ table } _centroid_street; CREATE INDEX idx_ ${ table } _centroid_street ON ${ table } USING gist (centroid) WHERE ((address_rank >= 26) AND (address_rank <= 27))\" ; done","title":"Change of layout of search_name_* tables"},{"location":"admin/Migration/#removal-of-html-output","text":"The debugging UI is no longer directly provided with Nominatim. Instead we now provide a simple Javascript application. Please refer to Setting up the Nominatim UI for details on how to set up the UI. The icons served together with the API responses have been moved to the nominatim-ui project as well. If you want to keep the icon field in the response, you need to set CONST_MapIcon_URL to the URL of the /mapicon directory of nominatim-ui.","title":"Removal of html output"},{"location":"admin/Migration/#change-order-during-indexing","text":"When reindexing places during updates, there is now a different order used which needs a different database index. Create it with the following SQL command: CREATE INDEX idx_placex_pendingsector_rank_address ON placex USING BTREE ( rank_address , geometry_sector ) WHERE indexed_status > 0 ; You can then drop the old index with: DROP INDEX idx_placex_pendingsector ;","title":"Change order during indexing"},{"location":"admin/Migration/#unused-index","text":"This index has been unused ever since the query using it was changed two years ago. Saves about 12GB on a planet installation. DROP INDEX idx_placex_geometry_reverse_lookupPoint ;","title":"Unused index"},{"location":"admin/Migration/#switching-to-dotenv","text":"As part of the work changing the configuration format, the configuration for the website is now using a separate configuration file. To create the configuration file, run the following command after updating: ./utils/setup.php --setup-website","title":"Switching to dotenv"},{"location":"admin/Migration/#update-sql-code","text":"To update the SQL code to the leatest version run: ./utils/setup.php --create-functions --enable-diff-updates --create-partition-functions","title":"Update SQL code"},{"location":"admin/Migration/#340-350","text":"","title":"3.4.0 -&gt; 3.5.0"},{"location":"admin/Migration/#new-wikipediawikidata-importance-tables","text":"The wikipedia_* tables have a new format that also includes references to Wikidata. You need to update the computation functions and the tables as follows: download the new Wikipedia tables as described in the import section reimport the tables: ./utils/setup.php --import-wikipedia-articles update the functions: ./utils/setup.php --create-functions --enable-diff-updates create a new lookup index: CREATE INDEX idx_placex_wikidata ON placex USING BTREE (( extratags -> 'wikidata' )) WHERE extratags ? 'wikidata' AND class = 'place' AND osm_type = 'N' AND rank_search < 26 ; compute importance: ./utils/update.php --recompute-importance The last step takes about 10 hours on the full planet. Remove one function (it will be recreated in the next step): DROP FUNCTION create_country ( hstore , character varying ); Finally, update all SQL functions: ./utils/setup.php --create-functions --enable-diff-updates --create-partition-functions","title":"New Wikipedia/Wikidata importance tables"},{"location":"admin/Migration/#330-340","text":"","title":"3.3.0 -&gt; 3.4.0"},{"location":"admin/Migration/#reorganisation-of-location_area_country-table","text":"The table location_area_country has been optimized. You need to switch to the new format when you run updates. While updates are disabled, run the following SQL commands: CREATE TABLE location_area_country_new AS SELECT place_id , country_code , geometry FROM location_area_country ; DROP TABLE location_area_country ; ALTER TABLE location_area_country_new RENAME TO location_area_country ; CREATE INDEX idx_location_area_country_geometry ON location_area_country USING GIST ( geometry ); CREATE INDEX idx_location_area_country_place_id ON location_area_country USING BTREE ( place_id ); Finally, update all SQL functions: ./utils/setup.php --create-functions --enable-diff-updates --create-partition-functions","title":"Reorganisation of location_area_country table"},{"location":"admin/Migration/#320-330","text":"","title":"3.2.0 -&gt; 3.3.0"},{"location":"admin/Migration/#new-database-connection-string-dsn-format","text":"Previously database connection setting ( CONST_Database_DSN in settings/*.php ) had the format (simple) pgsql://@/nominatim (complex) pgsql://johndoe:secret@machine1.domain.com:1234/db1 The new format is (simple) pgsql:dbname=nominatim (complex) pgsql:dbname=db1;host=machine1.domain.com;port=1234;user=johndoe;password=secret","title":"New database connection string (DSN) format"},{"location":"admin/Migration/#natural-earth-country-boundaries-no-longer-needed-as-fallback","text":"DROP TABLE country_naturalearthdata ; Finally, update all SQL functions: ./utils/setup.php --create-functions --enable-diff-updates --create-partition-functions","title":"Natural Earth country boundaries no longer needed as fallback"},{"location":"admin/Migration/#configurable-address-levels","text":"The new configurable address levels require a new table. Create it with the following command: ./utils/update.php --update-address-levels","title":"Configurable Address Levels"},{"location":"admin/Migration/#310-320","text":"","title":"3.1.0 -&gt; 3.2.0"},{"location":"admin/Migration/#new-reverse-algorithm","text":"The reverse algorithm has changed and requires new indexes. Run the following SQL statements to create the indexes: CREATE INDEX idx_placex_geometry_reverse_lookupPoint ON placex USING gist ( geometry ) WHERE ( name IS NOT null or housenumber IS NOT null or rank_address BETWEEN 26 AND 27 ) AND class NOT IN ( 'railway' , 'tunnel' , 'bridge' , 'man_made' ) AND rank_address >= 26 AND indexed_status = 0 AND linked_place_id IS null ; CREATE INDEX idx_placex_geometry_reverse_lookupPolygon ON placex USING gist ( geometry ) WHERE St_GeometryType ( geometry ) in ( 'ST_Polygon' , 'ST_MultiPolygon' ) AND rank_address between 4 and 25 AND type != 'postcode' AND name is not null AND indexed_status = 0 AND linked_place_id is null ; CREATE INDEX idx_placex_geometry_reverse_placeNode ON placex USING gist ( geometry ) WHERE osm_type = 'N' AND rank_search between 5 and 25 AND class = 'place' AND type != 'postcode' AND name is not null AND indexed_status = 0 AND linked_place_id is null ; You also need to grant the website user access to the country_osm_grid table: GRANT SELECT ON table country_osm_grid to \"www-user\" ; Replace the www-user with the user name of your website server if necessary. You can now drop the unused indexes: DROP INDEX idx_placex_reverse_geometry ; Finally, update all SQL functions: ./utils/setup.php --create-functions --enable-diff-updates --create-partition-functions","title":"New reverse algorithm"},{"location":"admin/Migration/#300-310","text":"","title":"3.0.0 -&gt; 3.1.0"},{"location":"admin/Migration/#postcode-table","text":"A new separate table for artificially computed postcode centroids was introduced. Migration to the new format is possible but not recommended . Create postcode table and indexes, running the following SQL statements: CREATE TABLE location_postcode ( place_id BIGINT , parent_place_id BIGINT , rank_search SMALLINT , rank_address SMALLINT , indexed_status SMALLINT , indexed_date TIMESTAMP , country_code varchar ( 2 ), postcode TEXT , geometry GEOMETRY ( Geometry , 4326 )); CREATE INDEX idx_postcode_geometry ON location_postcode USING GIST ( geometry ); CREATE UNIQUE INDEX idx_postcode_id ON location_postcode USING BTREE ( place_id ); CREATE INDEX idx_postcode_postcode ON location_postcode USING BTREE ( postcode ); GRANT SELECT ON location_postcode TO \"www-data\" ; DROP TYPE IF EXISTS nearfeaturecentr CASCADE ; CREATE TYPE nearfeaturecentr AS ( place_id BIGINT , keywords int [], rank_address smallint , rank_search smallint , distance float , isguess boolean , postcode TEXT , centroid GEOMETRY ); Add postcode column to location_area tables with SQL statement: ALTER TABLE location_area ADD COLUMN postcode TEXT ; Then reimport the functions: ./utils/setup.php --create-functions --enable-diff-updates --create-partition-functions Create appropriate triggers with SQL: CREATE TRIGGER location_postcode_before_update BEFORE UPDATE ON location_postcode FOR EACH ROW EXECUTE PROCEDURE postcode_update (); Finally populate the postcode table (will take a while): ./utils/setup.php --calculate-postcodes --index --index-noanalyse This will create a working database. You may also delete the old artificial postcodes now. Note that this may be expensive and is not absolutely necessary. The following SQL statement will remove them: DELETE FROM place_addressline a USING placex p WHERE a . address_place_id = p . place_id and p . osm_type = 'P' ; ALTER TABLE placex DISABLE TRIGGER USER ; DELETE FROM placex WHERE osm_type = 'P' ; ALTER TABLE placex ENABLE TRIGGER USER ;","title":"Postcode Table"},{"location":"admin/Setup-Nominatim-UI/","text":"Setting up the Nominatim UI \uf0c1 Nominatim is a search API, it does not provide a website interface on its own. nominatim-ui offers a small website for testing your setup and inspecting the database content. This section provides a quick start how to use nominatim-ui with your installation. For more details, please also have a look at the README of nominatim-ui . Installing nominatim-ui \uf0c1 We provide regular releases of nominatim-ui that contain the packaged website. They do not need any special installation. Just download, configure and run it. Grab the latest release from nominatim-ui's Github release page and unpack it. You can use nominatim-ui-x.x.x.tar.gz or nominatim-ui-x.x.x.zip . Next you need to adapt the UI to your installation. Custom settings need to be put into dist/theme/config.theme.js . At a minimum you need to set Nominatim_API_Endpoint to point to your Nominatim installation: cd nominatim-ui echo \"Nominatim_Config.Nominatim_API_Endpoint='https://myserver.org/nominatim/';\" > dist/theme/config.theme.js For the full set of available settings, have a look at dist/config.defaults.js . Then you can just test it locally by spinning up a webserver in the dist directory. For example, with Python: cd nominatim-ui/dist python3 -m http.server 8765 The website is now available at http://localhost:8765 . Forwarding searches to nominatim-ui \uf0c1 Nominatim used to provide the search interface directly by itself when format=html was requested. For all endpoints except for /reverse and /lookup this even used to be the default. The following section describes how to set up Apache or nginx, so that your users are forwarded to nominatim-ui when they go to URL that formerly presented the UI. Setting up forwarding in Nginx \uf0c1 First of all make nominatim-ui available under /ui on your webserver: server { # Here is the Nominatim setup as described in the Installation section location /ui/ { alias <full path to the nominatim-ui directory>/dist/ ; index index.html ; } } Now we need to find out if a URL should be forwarded to the UI. Add the following map commands outside the server section: # Inspect the format parameter in the query arguments. We are interested # if it is set to html or something else or if it is missing completely. map $args $format { default default ; ~(^|&)format=html(&|$) html ; ~(^|&)format= other ; } # Determine from the URI and the format parameter above if forwarding is needed. map $uri/$format $forward_to_ui { default 1 ; # The default is to forward. ~^/ui 0 ; # If the URI point to the UI already, we are done. ~/other$ 0 ; # An explicit non-html format parameter. No forwarding. ~/reverse.*/default 0 ; # Reverse and lookup assume xml format when ~/lookup.*/default 0 ; # no format parameter is given. No forwarding. } The $forward_to_ui parameter can now be used to conditionally forward the calls: # When no endpoint is given , default to search . # Need to add a rewrite so that the rewrite rules below catch it correctly . rewrite ^/ $ / search ; location @php { # fastcgi stuff .. if ( $ forward_to_ui ) { rewrite ^ ( /[ ^/ ]* ) https : // yourserver . com / ui $ 1. html redirect ; } } location ~ [ ^/ ] \\ . php ( /| $ ) { # fastcgi stuff .. if ( $ forward_to_ui ) { rewrite (. * ). php https : // yourserver . com / ui $ 1. html redirect ; } } Warning Be aware that the rewrite commands are slightly different for URIs with and without the .php suffix. Reload nginx and the UI should be available. Setting up forwarding in Apache \uf0c1 First of all make nominatim-ui available in the ui/ subdirectory where Nominatim is installed. For example, given you have set up an alias under nominatim like this: Alias /nominatim /home/vagrant/build/website you need to insert the following rules for nominatim-ui before that alias: <Directory \"/home/vagrant/nominatim-ui/dist\" > DirectoryIndex search.html Require all granted </Directory> Alias /nominatim/ui /home/vagrant/nominatim-ui/dist Replace /home/vagrant/nominatim-ui with the directory where you have cloned nominatim-ui. Important The alias for nominatim-ui must come before the alias for the Nominatim website directory. To set up forwarding, the Apache rewrite module is needed. Enable it with: sudo a2enmod rewrite Then add rewrite rules to the Directory directive of the Nominatim website directory like this: <Directory \"/home/vagrant/build/website\" > Options FollowSymLinks MultiViews AddType text/html .php Require all granted RewriteEngine On # This must correspond to the URL where nominatim can be found. RewriteBase \"/nominatim/\" # If no endpoint is given, then use search. RewriteRule ^(/|$) \"search.php\" # If format-html is explicitly requested, forward to the UI. RewriteCond %{QUERY_STRING} \"format=html\" RewriteRule ^([^/]+)(.php)? ui/$1.html [R,END] # If no format parameter is there then forward anything # but /reverse and /lookup to the UI. RewriteCond %{QUERY_STRING} \"!format=\" RewriteCond %{REQUEST_URI} \"!/lookup\" RewriteCond %{REQUEST_URI} \"!/reverse\" RewriteRule ^([^/]+)(.php)? ui/$1.html [R,END] </Directory> Restart Apache and the UI should be available.","title":"Nominatim UI"},{"location":"admin/Setup-Nominatim-UI/#setting-up-the-nominatim-ui","text":"Nominatim is a search API, it does not provide a website interface on its own. nominatim-ui offers a small website for testing your setup and inspecting the database content. This section provides a quick start how to use nominatim-ui with your installation. For more details, please also have a look at the README of nominatim-ui .","title":"Setting up the Nominatim UI"},{"location":"admin/Setup-Nominatim-UI/#installing-nominatim-ui","text":"We provide regular releases of nominatim-ui that contain the packaged website. They do not need any special installation. Just download, configure and run it. Grab the latest release from nominatim-ui's Github release page and unpack it. You can use nominatim-ui-x.x.x.tar.gz or nominatim-ui-x.x.x.zip . Next you need to adapt the UI to your installation. Custom settings need to be put into dist/theme/config.theme.js . At a minimum you need to set Nominatim_API_Endpoint to point to your Nominatim installation: cd nominatim-ui echo \"Nominatim_Config.Nominatim_API_Endpoint='https://myserver.org/nominatim/';\" > dist/theme/config.theme.js For the full set of available settings, have a look at dist/config.defaults.js . Then you can just test it locally by spinning up a webserver in the dist directory. For example, with Python: cd nominatim-ui/dist python3 -m http.server 8765 The website is now available at http://localhost:8765 .","title":"Installing nominatim-ui"},{"location":"admin/Setup-Nominatim-UI/#forwarding-searches-to-nominatim-ui","text":"Nominatim used to provide the search interface directly by itself when format=html was requested. For all endpoints except for /reverse and /lookup this even used to be the default. The following section describes how to set up Apache or nginx, so that your users are forwarded to nominatim-ui when they go to URL that formerly presented the UI.","title":"Forwarding searches to nominatim-ui"},{"location":"admin/Setup-Nominatim-UI/#setting-up-forwarding-in-nginx","text":"First of all make nominatim-ui available under /ui on your webserver: server { # Here is the Nominatim setup as described in the Installation section location /ui/ { alias <full path to the nominatim-ui directory>/dist/ ; index index.html ; } } Now we need to find out if a URL should be forwarded to the UI. Add the following map commands outside the server section: # Inspect the format parameter in the query arguments. We are interested # if it is set to html or something else or if it is missing completely. map $args $format { default default ; ~(^|&)format=html(&|$) html ; ~(^|&)format= other ; } # Determine from the URI and the format parameter above if forwarding is needed. map $uri/$format $forward_to_ui { default 1 ; # The default is to forward. ~^/ui 0 ; # If the URI point to the UI already, we are done. ~/other$ 0 ; # An explicit non-html format parameter. No forwarding. ~/reverse.*/default 0 ; # Reverse and lookup assume xml format when ~/lookup.*/default 0 ; # no format parameter is given. No forwarding. } The $forward_to_ui parameter can now be used to conditionally forward the calls: # When no endpoint is given , default to search . # Need to add a rewrite so that the rewrite rules below catch it correctly . rewrite ^/ $ / search ; location @php { # fastcgi stuff .. if ( $ forward_to_ui ) { rewrite ^ ( /[ ^/ ]* ) https : // yourserver . com / ui $ 1. html redirect ; } } location ~ [ ^/ ] \\ . php ( /| $ ) { # fastcgi stuff .. if ( $ forward_to_ui ) { rewrite (. * ). php https : // yourserver . com / ui $ 1. html redirect ; } } Warning Be aware that the rewrite commands are slightly different for URIs with and without the .php suffix. Reload nginx and the UI should be available.","title":"Setting up forwarding in Nginx"},{"location":"admin/Setup-Nominatim-UI/#setting-up-forwarding-in-apache","text":"First of all make nominatim-ui available in the ui/ subdirectory where Nominatim is installed. For example, given you have set up an alias under nominatim like this: Alias /nominatim /home/vagrant/build/website you need to insert the following rules for nominatim-ui before that alias: <Directory \"/home/vagrant/nominatim-ui/dist\" > DirectoryIndex search.html Require all granted </Directory> Alias /nominatim/ui /home/vagrant/nominatim-ui/dist Replace /home/vagrant/nominatim-ui with the directory where you have cloned nominatim-ui. Important The alias for nominatim-ui must come before the alias for the Nominatim website directory. To set up forwarding, the Apache rewrite module is needed. Enable it with: sudo a2enmod rewrite Then add rewrite rules to the Directory directive of the Nominatim website directory like this: <Directory \"/home/vagrant/build/website\" > Options FollowSymLinks MultiViews AddType text/html .php Require all granted RewriteEngine On # This must correspond to the URL where nominatim can be found. RewriteBase \"/nominatim/\" # If no endpoint is given, then use search. RewriteRule ^(/|$) \"search.php\" # If format-html is explicitly requested, forward to the UI. RewriteCond %{QUERY_STRING} \"format=html\" RewriteRule ^([^/]+)(.php)? ui/$1.html [R,END] # If no format parameter is there then forward anything # but /reverse and /lookup to the UI. RewriteCond %{QUERY_STRING} \"!format=\" RewriteCond %{REQUEST_URI} \"!/lookup\" RewriteCond %{REQUEST_URI} \"!/reverse\" RewriteRule ^([^/]+)(.php)? ui/$1.html [R,END] </Directory> Restart Apache and the UI should be available.","title":"Setting up forwarding in Apache"},{"location":"admin/Update/","text":"Updating the Database \uf0c1 There are many different ways to update your Nominatim database. The following section describes how to keep it up-to-date using an online replication service for OpenStreetMap data For a list of other methods to add or update data see the output of nominatim add-data --help . Important If you have configured a flatnode file for the import, then you need to keep this flatnode file around for updates. Installing the newest version of Pyosmium \uf0c1 The replication process uses Pyosmium to download update data from the server. It is recommended to install Pyosmium via pip. Run (as the same user who will later run the updates): pip3 install --user osmium Setting up the update process \uf0c1 Next the update process needs to be initialised. By default Nominatim is configured to update using the global minutely diffs. If you want a different update source you will need to add some settings to .env . For example, to use the daily country extracts diffs for Ireland from Geofabrik add the following: # base URL of the replication service NOMINATIM_REPLICATION_URL = \"https://download.geofabrik.de/europe/ireland-and-northern-ireland-updates\" # How often upstream publishes diffs (in seconds) NOMINATIM_REPLICATION_UPDATE_INTERVAL = 86400 # How long to sleep if no update found yet (in seconds) NOMINATIM_REPLICATION_RECHECK_INTERVAL = 900 To set up the update process now run the following command: nominatim replication --init It outputs the date where updates will start. Recheck that this date is what you expect. The replication --init command needs to be rerun whenever the replication service is changed. Updating Nominatim \uf0c1 Nominatim supports different modes how to retrieve the update data from the server. Which one you want to use depends on your exact setup and how often you want to retrieve updates. These instructions are for using a single source of updates. If you have imported multiple country extracts and want to keep them up-to-date, Advanced installations section contains instructions to set up and update multiple country extracts. Continuous updates \uf0c1 This is the easiest mode. Simply run the replication command without any parameters: nominatim replication The update application keeps running forever and retrieves and applies new updates from the server as they are published. You can run this command as a simple systemd service. Create a service description like that in /etc/systemd/system/nominatim-updates.service : [Unit] Description = Continuous updates of Nominatim [Service] WorkingDirectory = /srv/nominatim ExecStart = nominatim replication StandardOutput = append:/var/log/nominatim-updates.log StandardError = append:/var/log/nominatim-updates.error.log User = nominatim Group = nominatim Type = simple [Install] WantedBy = multi-user.target Replace the WorkingDirectory with your project directory. Also adapt user and group names as required. Now activate the service and start the updates: sudo systemctl daemon - reload sudo systemctl enable nominatim - updates sudo systemctl start nominatim - updates One-time mode \uf0c1 When the --once parameter is given, then Nominatim will download exactly one batch of updates and then exit. This one-time mode still respects the NOMINATIM_REPLICATION_UPDATE_INTERVAL that you have set. If according to the update interval no new data has been published yet, it will go to sleep until the next expected update and only then attempt to download the next batch. The one-time mode is particularly useful if you want to run updates continuously but need to schedule other work in between updates. For example, the main service at osm.org uses it, to regularly recompute postcodes -- a process that must not be run while updates are in progress. Its update script looks like this: #!/bin/bash # Switch to your project directory. cd /srv/nominatim while true ; do nominatim replication --once if [ -f \"/srv/nominatim/schedule-maintenance\" ] ; then rm /srv/nominatim/schedule-maintenance nominatim refresh --postcodes fi done A cron job then creates the file /srv/nominatim/schedule-maintenance once per night. One-time mode with systemd \uf0c1 You can run the one-time mode with a systemd timer & service. Create a timer description like /etc/systemd/system/nominatim-updates.timer : [Unit] Description = Timer to start updates of Nominatim [Timer] OnActiveSec = 2 OnUnitActiveSec = 1min Unit = nominatim-updates.service [Install] WantedBy = multi-user.target And then a similar service definition: /etc/systemd/system/nominatim-updates.service : [Unit] Description = Single updates of Nominatim [Service] WorkingDirectory = /srv/nominatim ExecStart = nominatim replication --once StandardOutput = append:/var/log/nominatim-updates.log StandardError = append:/var/log/nominatim-updates.error.log User = nominatim Group = nominatim Type = simple [Install] WantedBy = multi-user.target Replace the WorkingDirectory with your project directory. Also adapt user and group names as required. OnUnitActiveSec defines how often the individual update command is run. Now activate the service and start the updates: sudo systemctl daemon - reload sudo systemctl enable nominatim - updates . timer sudo systemctl start nominatim - updates . timer You can stop future data updates, while allowing any current, in-progress update steps to finish, by running sudo systemctl stop nominatim-updates.timer and waiting until nominatim-updates.service isn't running ( sudo systemctl is-active nominatim-updates.service ). Current output from the update can be seen like above ( systemctl status nominatim-updates.service ). Catch-up mode \uf0c1 With the --catch-up parameter, Nominatim will immediately try to download all changes from the server until the database is up-to-date. The catch-up mode still respects the parameter NOMINATIM_REPLICATION_MAX_DIFF . It downloads and applies the changes in appropriate batches until all is done. The catch-up mode is foremost useful to bring the database up to speed after the initial import. Give that the service usually is not in production at this point, you can temporarily be a bit more generous with the batch size and number of threads you use for the updates by running catch-up like this: cd /srv/nominatim NOMINATIM_REPLICATION_MAX_DIFF=5000 nominatim replication --catch-up --threads 15 The catch-up mode is also useful when you want to apply updates at a lower frequency than what the source publishes. You can set up a cron job to run replication catch-up at whatever interval you desire. Hint When running scheduled updates with catch-up, it is a good idea to choose a replication source with an update frequency that is an order of magnitude lower. For example, if you want to update once a day, use an hourly updated source. This makes sure that you don't miss an entire day of updates when the source is unexpectedly late to publish its update. If you want to use the source with the same update frequency (e.g. a daily updated source with daily updates), use the continuous update mode. It ensures to re-request the newest update until it is published.","title":"Update"},{"location":"admin/Update/#updating-the-database","text":"There are many different ways to update your Nominatim database. The following section describes how to keep it up-to-date using an online replication service for OpenStreetMap data For a list of other methods to add or update data see the output of nominatim add-data --help . Important If you have configured a flatnode file for the import, then you need to keep this flatnode file around for updates.","title":"Updating the Database"},{"location":"admin/Update/#installing-the-newest-version-of-pyosmium","text":"The replication process uses Pyosmium to download update data from the server. It is recommended to install Pyosmium via pip. Run (as the same user who will later run the updates): pip3 install --user osmium","title":"Installing the newest version of Pyosmium"},{"location":"admin/Update/#setting-up-the-update-process","text":"Next the update process needs to be initialised. By default Nominatim is configured to update using the global minutely diffs. If you want a different update source you will need to add some settings to .env . For example, to use the daily country extracts diffs for Ireland from Geofabrik add the following: # base URL of the replication service NOMINATIM_REPLICATION_URL = \"https://download.geofabrik.de/europe/ireland-and-northern-ireland-updates\" # How often upstream publishes diffs (in seconds) NOMINATIM_REPLICATION_UPDATE_INTERVAL = 86400 # How long to sleep if no update found yet (in seconds) NOMINATIM_REPLICATION_RECHECK_INTERVAL = 900 To set up the update process now run the following command: nominatim replication --init It outputs the date where updates will start. Recheck that this date is what you expect. The replication --init command needs to be rerun whenever the replication service is changed.","title":"Setting up the update process"},{"location":"admin/Update/#updating-nominatim","text":"Nominatim supports different modes how to retrieve the update data from the server. Which one you want to use depends on your exact setup and how often you want to retrieve updates. These instructions are for using a single source of updates. If you have imported multiple country extracts and want to keep them up-to-date, Advanced installations section contains instructions to set up and update multiple country extracts.","title":"Updating Nominatim"},{"location":"admin/Update/#continuous-updates","text":"This is the easiest mode. Simply run the replication command without any parameters: nominatim replication The update application keeps running forever and retrieves and applies new updates from the server as they are published. You can run this command as a simple systemd service. Create a service description like that in /etc/systemd/system/nominatim-updates.service : [Unit] Description = Continuous updates of Nominatim [Service] WorkingDirectory = /srv/nominatim ExecStart = nominatim replication StandardOutput = append:/var/log/nominatim-updates.log StandardError = append:/var/log/nominatim-updates.error.log User = nominatim Group = nominatim Type = simple [Install] WantedBy = multi-user.target Replace the WorkingDirectory with your project directory. Also adapt user and group names as required. Now activate the service and start the updates: sudo systemctl daemon - reload sudo systemctl enable nominatim - updates sudo systemctl start nominatim - updates","title":"Continuous updates"},{"location":"admin/Update/#one-time-mode","text":"When the --once parameter is given, then Nominatim will download exactly one batch of updates and then exit. This one-time mode still respects the NOMINATIM_REPLICATION_UPDATE_INTERVAL that you have set. If according to the update interval no new data has been published yet, it will go to sleep until the next expected update and only then attempt to download the next batch. The one-time mode is particularly useful if you want to run updates continuously but need to schedule other work in between updates. For example, the main service at osm.org uses it, to regularly recompute postcodes -- a process that must not be run while updates are in progress. Its update script looks like this: #!/bin/bash # Switch to your project directory. cd /srv/nominatim while true ; do nominatim replication --once if [ -f \"/srv/nominatim/schedule-maintenance\" ] ; then rm /srv/nominatim/schedule-maintenance nominatim refresh --postcodes fi done A cron job then creates the file /srv/nominatim/schedule-maintenance once per night.","title":"One-time mode"},{"location":"admin/Update/#one-time-mode-with-systemd","text":"You can run the one-time mode with a systemd timer & service. Create a timer description like /etc/systemd/system/nominatim-updates.timer : [Unit] Description = Timer to start updates of Nominatim [Timer] OnActiveSec = 2 OnUnitActiveSec = 1min Unit = nominatim-updates.service [Install] WantedBy = multi-user.target And then a similar service definition: /etc/systemd/system/nominatim-updates.service : [Unit] Description = Single updates of Nominatim [Service] WorkingDirectory = /srv/nominatim ExecStart = nominatim replication --once StandardOutput = append:/var/log/nominatim-updates.log StandardError = append:/var/log/nominatim-updates.error.log User = nominatim Group = nominatim Type = simple [Install] WantedBy = multi-user.target Replace the WorkingDirectory with your project directory. Also adapt user and group names as required. OnUnitActiveSec defines how often the individual update command is run. Now activate the service and start the updates: sudo systemctl daemon - reload sudo systemctl enable nominatim - updates . timer sudo systemctl start nominatim - updates . timer You can stop future data updates, while allowing any current, in-progress update steps to finish, by running sudo systemctl stop nominatim-updates.timer and waiting until nominatim-updates.service isn't running ( sudo systemctl is-active nominatim-updates.service ). Current output from the update can be seen like above ( systemctl status nominatim-updates.service ).","title":"One-time mode with systemd"},{"location":"admin/Update/#catch-up-mode","text":"With the --catch-up parameter, Nominatim will immediately try to download all changes from the server until the database is up-to-date. The catch-up mode still respects the parameter NOMINATIM_REPLICATION_MAX_DIFF . It downloads and applies the changes in appropriate batches until all is done. The catch-up mode is foremost useful to bring the database up to speed after the initial import. Give that the service usually is not in production at this point, you can temporarily be a bit more generous with the batch size and number of threads you use for the updates by running catch-up like this: cd /srv/nominatim NOMINATIM_REPLICATION_MAX_DIFF=5000 nominatim replication --catch-up --threads 15 The catch-up mode is also useful when you want to apply updates at a lower frequency than what the source publishes. You can set up a cron job to run replication catch-up at whatever interval you desire. Hint When running scheduled updates with catch-up, it is a good idea to choose a replication source with an update frequency that is an order of magnitude lower. For example, if you want to update once a day, use an hourly updated source. This makes sure that you don't miss an entire day of updates when the source is unexpectedly late to publish its update. If you want to use the source with the same update frequency (e.g. a daily updated source with daily updates), use the continuous update mode. It ensures to re-request the newest update until it is published.","title":"Catch-up mode"},{"location":"api/Details/","text":"Place details \uf0c1 Show all details about a single place saved in the database. Warning The details page exists for debugging only. You may not use it in scripts or to automatically query details about a result. See Nominatim Usage Policy . Parameters \uf0c1 The details API supports the following two request formats: https://nominatim.openstreetmap.org/details?osmtype=[N|W|R] & osmid= <value> & class= <value> osmtype and osmid are required parameters. The type is one of node (N), way (W) or relation (R). The id must be a number. The class parameter is optional and allows to distinguish between entries, when the corresponding OSM object has more than one main tag. For example, when a place is tagged with tourism=hotel and amenity=restaurant , there will be two place entries in Nominatim, one for a restaurant, one for a hotel. You need to specify class=tourism or class=amentity to get exactly the one you want. If there are multiple places in the database but the class parameter is left out, then one of the places will be chosen at random and displayed. https://nominatim.openstreetmap.org/details?place_id= <value> Place IDs are assigned sequentially during Nominatim data import. The ID for a place is different between Nominatim installation (servers) and changes when data gets reimported. Therefore it cannot be used as a permanent id and shouldn't be used in bug reports. Additional optional parameters are explained below. Output format \uf0c1 json_callback=<string> Wrap JSON output in a callback function (JSONP) i.e. <string>(<json>) . pretty=[0|1] Add indentation to make it more human-readable. (Default: 0) Output details \uf0c1 addressdetails=[0|1] Include a breakdown of the address into elements. (Default: 0) keywords=[0|1] Include a list of name keywords and address keywords (word ids). (Default: 0) linkedplaces=[0|1] Include a details of places that are linked with this one. Places get linked together when they are different forms of the same physical object. Nominatim links two kinds of objects together: place nodes get linked with the corresponding administrative boundaries. Waterway relations get linked together with their members. (Default: 1) hierarchy=[0|1] Include details of places lower in the address hierarchy. (Default: 0) group_hierarchy=[0|1] For JSON output will group the places by type. (Default: 0) polygon_geojson=[0|1] Include geometry of result. (Default: 0) Language of results \uf0c1 accept-language=<browser language string> Preferred language order for showing result, overrides the value specified in the \"Accept-Language\" HTTP header. Either use a standard RFC2616 accept-language string or a simple comma-separated list of language codes. Examples \uf0c1 JSON \uf0c1 https://nominatim.openstreetmap.org/details.php?osmtype=W&osmid=38210407&format=json { \"place_id\" : 85993608 , \"parent_place_id\" : 72765313 , \"osm_type\" : \"W\" , \"osm_id\" : 38210407 , \"category\" : \"place\" , \"type\" : \"square\" , \"admin_level\" : \"15\" , \"localname\" : \"Pariser Platz\" , \"names\" : { \"name\" : \"Pariser Platz\" , \"name:be\" : \"\u041f\u0430\u0440\u044b\u0436\u0441\u043a\u0430\u044f \u043f\u043b\u043e\u0448\u0447\u0430\" , \"name:de\" : \"Pariser Platz\" , \"name:es\" : \"Plaza de Par\u00eds\" , \"name:he\" : \"\u05e4\u05d0\u05e8\u05d9\u05d6\u05e8 \u05e4\u05dc\u05d0\u05e5\" , \"name:ko\" : \"\ud30c\ub9ac\uc800 \uad11\uc7a5\" , \"name:la\" : \"Forum Parisinum\" , \"name:ru\" : \"\u041f\u0430\u0440\u0438\u0436\u0441\u043a\u0430\u044f \u043f\u043b\u043e\u0449\u0430\u0434\u044c\" , \"name:uk\" : \"\u041f\u0430\u0440\u0438\u0437\u044c\u043a\u0430 \u043f\u043b\u043e\u0449\u0430\" , \"name:zh\" : \"\u5df4\u9ece\u5ee3\u5834\" }, \"addresstags\" : { \"postcode\" : \"10117\" }, \"housenumber\" : null , \"calculated_postcode\" : \"10117\" , \"country_code\" : \"de\" , \"indexed_date\" : \"2018-08-18T17:02:45+00:00\" , \"importance\" : 0.339401620591472 , \"calculated_importance\" : 0.339401620591472 , \"extratags\" : { \"wikidata\" : \"Q156716\" , \"wikipedia\" : \"de:Pariser Platz\" }, \"calculated_wikipedia\" : \"de:Pariser_Platz\" , \"rank_address\" : 30 , \"rank_search\" : 30 , \"isarea\" : true , \"centroid\" : { \"type\" : \"Point\" , \"coordinates\" : [ 13.3786822618517 , 52.5163654 ] }, \"geometry\" : { \"type\" : \"Point\" , \"coordinates\" : [ 13.3786822618517 , 52.5163654 ] } }","title":"Details"},{"location":"api/Details/#place-details","text":"Show all details about a single place saved in the database. Warning The details page exists for debugging only. You may not use it in scripts or to automatically query details about a result. See Nominatim Usage Policy .","title":"Place details"},{"location":"api/Details/#parameters","text":"The details API supports the following two request formats: https://nominatim.openstreetmap.org/details?osmtype=[N|W|R] & osmid= <value> & class= <value> osmtype and osmid are required parameters. The type is one of node (N), way (W) or relation (R). The id must be a number. The class parameter is optional and allows to distinguish between entries, when the corresponding OSM object has more than one main tag. For example, when a place is tagged with tourism=hotel and amenity=restaurant , there will be two place entries in Nominatim, one for a restaurant, one for a hotel. You need to specify class=tourism or class=amentity to get exactly the one you want. If there are multiple places in the database but the class parameter is left out, then one of the places will be chosen at random and displayed. https://nominatim.openstreetmap.org/details?place_id= <value> Place IDs are assigned sequentially during Nominatim data import. The ID for a place is different between Nominatim installation (servers) and changes when data gets reimported. Therefore it cannot be used as a permanent id and shouldn't be used in bug reports. Additional optional parameters are explained below.","title":"Parameters"},{"location":"api/Details/#output-format","text":"json_callback=<string> Wrap JSON output in a callback function (JSONP) i.e. <string>(<json>) . pretty=[0|1] Add indentation to make it more human-readable. (Default: 0)","title":"Output format"},{"location":"api/Details/#output-details","text":"addressdetails=[0|1] Include a breakdown of the address into elements. (Default: 0) keywords=[0|1] Include a list of name keywords and address keywords (word ids). (Default: 0) linkedplaces=[0|1] Include a details of places that are linked with this one. Places get linked together when they are different forms of the same physical object. Nominatim links two kinds of objects together: place nodes get linked with the corresponding administrative boundaries. Waterway relations get linked together with their members. (Default: 1) hierarchy=[0|1] Include details of places lower in the address hierarchy. (Default: 0) group_hierarchy=[0|1] For JSON output will group the places by type. (Default: 0) polygon_geojson=[0|1] Include geometry of result. (Default: 0)","title":"Output details"},{"location":"api/Details/#language-of-results","text":"accept-language=<browser language string> Preferred language order for showing result, overrides the value specified in the \"Accept-Language\" HTTP header. Either use a standard RFC2616 accept-language string or a simple comma-separated list of language codes.","title":"Language of results"},{"location":"api/Details/#examples","text":"","title":"Examples"},{"location":"api/Details/#json","text":"https://nominatim.openstreetmap.org/details.php?osmtype=W&osmid=38210407&format=json { \"place_id\" : 85993608 , \"parent_place_id\" : 72765313 , \"osm_type\" : \"W\" , \"osm_id\" : 38210407 , \"category\" : \"place\" , \"type\" : \"square\" , \"admin_level\" : \"15\" , \"localname\" : \"Pariser Platz\" , \"names\" : { \"name\" : \"Pariser Platz\" , \"name:be\" : \"\u041f\u0430\u0440\u044b\u0436\u0441\u043a\u0430\u044f \u043f\u043b\u043e\u0448\u0447\u0430\" , \"name:de\" : \"Pariser Platz\" , \"name:es\" : \"Plaza de Par\u00eds\" , \"name:he\" : \"\u05e4\u05d0\u05e8\u05d9\u05d6\u05e8 \u05e4\u05dc\u05d0\u05e5\" , \"name:ko\" : \"\ud30c\ub9ac\uc800 \uad11\uc7a5\" , \"name:la\" : \"Forum Parisinum\" , \"name:ru\" : \"\u041f\u0430\u0440\u0438\u0436\u0441\u043a\u0430\u044f \u043f\u043b\u043e\u0449\u0430\u0434\u044c\" , \"name:uk\" : \"\u041f\u0430\u0440\u0438\u0437\u044c\u043a\u0430 \u043f\u043b\u043e\u0449\u0430\" , \"name:zh\" : \"\u5df4\u9ece\u5ee3\u5834\" }, \"addresstags\" : { \"postcode\" : \"10117\" }, \"housenumber\" : null , \"calculated_postcode\" : \"10117\" , \"country_code\" : \"de\" , \"indexed_date\" : \"2018-08-18T17:02:45+00:00\" , \"importance\" : 0.339401620591472 , \"calculated_importance\" : 0.339401620591472 , \"extratags\" : { \"wikidata\" : \"Q156716\" , \"wikipedia\" : \"de:Pariser Platz\" }, \"calculated_wikipedia\" : \"de:Pariser_Platz\" , \"rank_address\" : 30 , \"rank_search\" : 30 , \"isarea\" : true , \"centroid\" : { \"type\" : \"Point\" , \"coordinates\" : [ 13.3786822618517 , 52.5163654 ] }, \"geometry\" : { \"type\" : \"Point\" , \"coordinates\" : [ 13.3786822618517 , 52.5163654 ] } }","title":"JSON"},{"location":"api/Faq/","text":"Frequently Asked Questions \uf0c1 API Results \uf0c1 1. The address of my search results contains far-away places that don't belong there. \uf0c1 Nominatim computes the address from two sources in the OpenStreetMap data: from administrative boundaries and from place nodes. Boundaries are the more useful source. They precisely describe an area. So it is very clear for Nominatim if a point belongs to an area or not. Place nodes are more complicated. These are only points without any precise extent. So Nominatim has to take a guess and assume that an address belongs to the closest place node it can find. In an ideal world, Nominatim would not need the place nodes but there are many places on earth where there are no precise boundaries available for all parts that make up an address. This is in particular true for the more local address parts, like villages and suburbs. Therefore it is not possible to completely dismiss place nodes. And sometimes they sneak in where they don't belong. As a OpenStreetMap mapper, you can improve the situation in two ways: if you see a place node for which already an administrative area exists, then you should link the two by adding the node with a 'label' role to the boundary relation. If there is no administrative area, you can add the approximate extent of the place and tag it place= as well. 2. When doing reverse search, the address details have parts that don't contain the point I was looking up. \uf0c1 There is a common misconception how the reverse API call works in Nominatim. Reverse does not give you the address of the point you asked for. Reverse returns the closest object to the point you asked for and then returns the address of that object. Now, if you are close to a border, then the closest object may be across that border. When Nominatim then returns the address, it contains the county/state/country across the border. 3. I get different counties/states/countries when I change the zoom parameter in the reverse query. How is that possible? \uf0c1 This is basically the same problem as in the previous answer. The zoom level influences at which search rank Nominatim starts looking for the closest object. So the closest house number maybe on one side of the border while the closest street is on the other. As the address details contain the address of the closest object found, you might sometimes get one result, sometimes the other for the closest point. 4. Can you return the continent? \uf0c1 Nominatim assigns each map feature one country. Those outside any administrative boundaries are assigned a special no-country. Continents or other super-national administrations (e.g. European Union, NATO, Custom unions) are not supported, see also Administrative Boundary . 5. Can you return the timezone? \uf0c1 See this separate OpenStreetMap-based project Timezone Boundary Builder . 6. I want to download a list of streets/restaurants of a city/region \uf0c1 The Overpass API is more suited for these kinds of queries. That said if you installed your own Nominatim instance you can use the nominatim export PHP script as basis to return such lists.","title":"FAQ"},{"location":"api/Faq/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"api/Faq/#api-results","text":"","title":"API Results"},{"location":"api/Faq/#1-the-address-of-my-search-results-contains-far-away-places-that-dont-belong-there","text":"Nominatim computes the address from two sources in the OpenStreetMap data: from administrative boundaries and from place nodes. Boundaries are the more useful source. They precisely describe an area. So it is very clear for Nominatim if a point belongs to an area or not. Place nodes are more complicated. These are only points without any precise extent. So Nominatim has to take a guess and assume that an address belongs to the closest place node it can find. In an ideal world, Nominatim would not need the place nodes but there are many places on earth where there are no precise boundaries available for all parts that make up an address. This is in particular true for the more local address parts, like villages and suburbs. Therefore it is not possible to completely dismiss place nodes. And sometimes they sneak in where they don't belong. As a OpenStreetMap mapper, you can improve the situation in two ways: if you see a place node for which already an administrative area exists, then you should link the two by adding the node with a 'label' role to the boundary relation. If there is no administrative area, you can add the approximate extent of the place and tag it place= as well.","title":"1. The address of my search results contains far-away places that don't belong there."},{"location":"api/Faq/#2-when-doing-reverse-search-the-address-details-have-parts-that-dont-contain-the-point-i-was-looking-up","text":"There is a common misconception how the reverse API call works in Nominatim. Reverse does not give you the address of the point you asked for. Reverse returns the closest object to the point you asked for and then returns the address of that object. Now, if you are close to a border, then the closest object may be across that border. When Nominatim then returns the address, it contains the county/state/country across the border.","title":"2. When doing reverse search, the address details have parts that don't contain the point I was looking up."},{"location":"api/Faq/#3-i-get-different-countiesstatescountries-when-i-change-the-zoom-parameter-in-the-reverse-query-how-is-that-possible","text":"This is basically the same problem as in the previous answer. The zoom level influences at which search rank Nominatim starts looking for the closest object. So the closest house number maybe on one side of the border while the closest street is on the other. As the address details contain the address of the closest object found, you might sometimes get one result, sometimes the other for the closest point.","title":"3. I get different counties/states/countries when I change the zoom parameter in the reverse query. How is that possible?"},{"location":"api/Faq/#4-can-you-return-the-continent","text":"Nominatim assigns each map feature one country. Those outside any administrative boundaries are assigned a special no-country. Continents or other super-national administrations (e.g. European Union, NATO, Custom unions) are not supported, see also Administrative Boundary .","title":"4. Can you return the continent?"},{"location":"api/Faq/#5-can-you-return-the-timezone","text":"See this separate OpenStreetMap-based project Timezone Boundary Builder .","title":"5. Can you return the timezone?"},{"location":"api/Faq/#6-i-want-to-download-a-list-of-streetsrestaurants-of-a-cityregion","text":"The Overpass API is more suited for these kinds of queries. That said if you installed your own Nominatim instance you can use the nominatim export PHP script as basis to return such lists.","title":"6. I want to download a list of streets/restaurants of a city/region"},{"location":"api/Lookup/","text":"Address lookup \uf0c1 The lookup API allows to query the address and other details of one or multiple OSM objects like node, way or relation. Parameters \uf0c1 The lookup API has the following format: https://nominatim.openstreetmap.org/lookup?osm_ids=[N|W|R]<value>,\u2026,\u2026,&<params> osm_ids is mandatory and must contain a comma-separated list of OSM ids each prefixed with its type, one of node(N), way(W) or relation(R). Up to 50 ids can be queried at the same time. Additional optional parameters are explained below. Output format \uf0c1 format=[xml|json|jsonv2|geojson|geocodejson] See Place Output Formats for details on each format. (Default: xml) json_callback=<string> Wrap JSON output in a callback function (JSONP) i.e. <string>(<json>) . Only has an effect for JSON output formats. Output details \uf0c1 addressdetails=[0|1] Include a breakdown of the address into elements. (Default: 0) extratags=[0|1] Include additional information in the result if available, e.g. wikipedia link, opening hours. (Default: 0) namedetails=[0|1] Include a list of alternative names in the results. These may include language variants, references, operator and brand. (Default: 0) Language of results \uf0c1 accept-language=<browser language string> Preferred language order for showing search results, overrides the value specified in the \"Accept-Language\" HTTP header. Either use a standard RFC2616 accept-language string or a simple comma-separated list of language codes. Polygon output \uf0c1 polygon_geojson=1 polygon_kml=1 polygon_svg=1 polygon_text=1 Output geometry of results as a GeoJSON, KML, SVG or WKT. Only one of these options can be used at a time. (Default: 0) polygon_threshold=0.0 Return a simplified version of the output geometry. The parameter is the tolerance in degrees with which the geometry may differ from the original geometry. Topology is preserved in the result. (Default: 0.0) Other \uf0c1 email=<valid email address> If you are making large numbers of request please include an appropriate email address to identify your requests. See Nominatim's Usage Policy for more details. debug=[0|1] Output assorted developer debug information. Data on internals of Nominatim's \"Search Loop\" logic, and SQL queries. The output is (rough) HTML format. This overrides the specified machine readable format. (Default: 0) Examples \uf0c1 XML \uf0c1 https://nominatim.openstreetmap.org/lookup?osm_ids=R146656,W104393803,N240109189 <lookupresults timestamp= \"Mon, 28 Mar 22 14:38:54 +0000\" attribution= \"Data &#xA9; OpenStreetMap contributors, ODbL 1.0. http://www.openstreetmap.org/copyright\" querystring= \"R146656,W50637691,N240109189\" more_url= \"\" > <place place_id= \"282236157\" osm_type= \"relation\" osm_id= \"146656\" place_rank= \"16\" address_rank= \"16\" boundingbox= \"53.3401044,53.5445923,-2.3199185,-2.1468288\" lat= \"53.44246175\" lon= \"-2.2324547359718547\" display_name= \"Manchester, Greater Manchester, North West England, England, United Kingdom\" class= \"boundary\" type= \"administrative\" importance= \"0.35\" > <city> Manchester </city> <county> Greater Manchester </county> <state_district> North West England </state_district> <state> England </state> <country> United Kingdom </country> <country_code> gb </country_code> </place> <place place_id= \"115462561\" osm_type= \"way\" osm_id= \"50637691\" place_rank= \"30\" address_rank= \"30\" boundingbox= \"52.3994612,52.3996426,13.0479574,13.0481754\" lat= \"52.399550700000006\" lon= \"13.048066846939687\" display_name= \"Brandenburger Tor, Brandenburger Stra&#xDF;e, Historische Innenstadt, Innenstadt, Potsdam, Brandenburg, 14467, Germany\" class= \"tourism\" type= \"attraction\" importance= \"0.29402874005524\" > <tourism> Brandenburger Tor </tourism> <road> Brandenburger Stra &#xDF; e </road> <suburb> Historische Innenstadt </suburb> <city> Potsdam </city> <state> Brandenburg </state> <postcode> 14467 </postcode> <country> Germany </country> <country_code> de </country_code> </place> <place place_id= \"567505\" osm_type= \"node\" osm_id= \"240109189\" place_rank= \"15\" address_rank= \"16\" boundingbox= \"52.3586925,52.6786925,13.2396024,13.5596024\" lat= \"52.5186925\" lon= \"13.3996024\" display_name= \"Berlin, 10178, Germany\" class= \"place\" type= \"city\" importance= \"0.78753902824914\" > <city> Berlin </city> <state> Berlin </state> <postcode> 10178 </postcode> <country> Germany </country> <country_code> de </country_code> </place> </lookupresults> JSON with extratags \uf0c1 https://nominatim.openstreetmap.org/lookup?osm_ids=W50637691&format=json&extratags=1 [ { \"place_id\" : 115462561 , \"licence\" : \"Data \u00a9 OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\" , \"osm_type\" : \"way\" , \"osm_id\" : 50637691 , \"boundingbox\" : [ \"52.3994612\" , \"52.3996426\" , \"13.0479574\" , \"13.0481754\" ], \"lat\" : \"52.399550700000006\" , \"lon\" : \"13.048066846939687\" , \"display_name\" : \"Brandenburger Tor, Brandenburger Stra\u00dfe, Historische Innenstadt, Innenstadt, Potsdam, Brandenburg, 14467, Germany\" , \"class\" : \"tourism\" , \"type\" : \"attraction\" , \"importance\" : 0.2940287400552381 , \"address\" : { \"tourism\" : \"Brandenburger Tor\" , \"road\" : \"Brandenburger Stra\u00dfe\" , \"suburb\" : \"Historische Innenstadt\" , \"city\" : \"Potsdam\" , \"state\" : \"Brandenburg\" , \"postcode\" : \"14467\" , \"country\" : \"Germany\" , \"country_code\" : \"de\" }, \"extratags\" : { \"image\" : \"http://commons.wikimedia.org/wiki/File:Potsdam_brandenburger_tor.jpg\" , \"heritage\" : \"4\" , \"wikidata\" : \"Q695045\" , \"architect\" : \"Carl von Gontard;Georg Christian Unger\" , \"wikipedia\" : \"de:Brandenburger Tor (Potsdam)\" , \"wheelchair\" : \"yes\" , \"description\" : \"Kleines Brandenburger Tor in Potsdam\" , \"heritage:website\" : \"http://www.bldam-brandenburg.de/images/stories/PDF/DML%202012/04-p-internet-13.pdf\" , \"heritage:operator\" : \"bldam\" , \"architect:wikidata\" : \"Q68768;Q95223\" , \"year_of_construction\" : \"1771\" } } ]","title":"Address Lookup"},{"location":"api/Lookup/#address-lookup","text":"The lookup API allows to query the address and other details of one or multiple OSM objects like node, way or relation.","title":"Address lookup"},{"location":"api/Lookup/#parameters","text":"The lookup API has the following format: https://nominatim.openstreetmap.org/lookup?osm_ids=[N|W|R]<value>,\u2026,\u2026,&<params> osm_ids is mandatory and must contain a comma-separated list of OSM ids each prefixed with its type, one of node(N), way(W) or relation(R). Up to 50 ids can be queried at the same time. Additional optional parameters are explained below.","title":"Parameters"},{"location":"api/Lookup/#output-format","text":"format=[xml|json|jsonv2|geojson|geocodejson] See Place Output Formats for details on each format. (Default: xml) json_callback=<string> Wrap JSON output in a callback function (JSONP) i.e. <string>(<json>) . Only has an effect for JSON output formats.","title":"Output format"},{"location":"api/Lookup/#output-details","text":"addressdetails=[0|1] Include a breakdown of the address into elements. (Default: 0) extratags=[0|1] Include additional information in the result if available, e.g. wikipedia link, opening hours. (Default: 0) namedetails=[0|1] Include a list of alternative names in the results. These may include language variants, references, operator and brand. (Default: 0)","title":"Output details"},{"location":"api/Lookup/#language-of-results","text":"accept-language=<browser language string> Preferred language order for showing search results, overrides the value specified in the \"Accept-Language\" HTTP header. Either use a standard RFC2616 accept-language string or a simple comma-separated list of language codes.","title":"Language of results"},{"location":"api/Lookup/#polygon-output","text":"polygon_geojson=1 polygon_kml=1 polygon_svg=1 polygon_text=1 Output geometry of results as a GeoJSON, KML, SVG or WKT. Only one of these options can be used at a time. (Default: 0) polygon_threshold=0.0 Return a simplified version of the output geometry. The parameter is the tolerance in degrees with which the geometry may differ from the original geometry. Topology is preserved in the result. (Default: 0.0)","title":"Polygon output"},{"location":"api/Lookup/#other","text":"email=<valid email address> If you are making large numbers of request please include an appropriate email address to identify your requests. See Nominatim's Usage Policy for more details. debug=[0|1] Output assorted developer debug information. Data on internals of Nominatim's \"Search Loop\" logic, and SQL queries. The output is (rough) HTML format. This overrides the specified machine readable format. (Default: 0)","title":"Other"},{"location":"api/Lookup/#examples","text":"","title":"Examples"},{"location":"api/Lookup/#xml","text":"https://nominatim.openstreetmap.org/lookup?osm_ids=R146656,W104393803,N240109189 <lookupresults timestamp= \"Mon, 28 Mar 22 14:38:54 +0000\" attribution= \"Data &#xA9; OpenStreetMap contributors, ODbL 1.0. http://www.openstreetmap.org/copyright\" querystring= \"R146656,W50637691,N240109189\" more_url= \"\" > <place place_id= \"282236157\" osm_type= \"relation\" osm_id= \"146656\" place_rank= \"16\" address_rank= \"16\" boundingbox= \"53.3401044,53.5445923,-2.3199185,-2.1468288\" lat= \"53.44246175\" lon= \"-2.2324547359718547\" display_name= \"Manchester, Greater Manchester, North West England, England, United Kingdom\" class= \"boundary\" type= \"administrative\" importance= \"0.35\" > <city> Manchester </city> <county> Greater Manchester </county> <state_district> North West England </state_district> <state> England </state> <country> United Kingdom </country> <country_code> gb </country_code> </place> <place place_id= \"115462561\" osm_type= \"way\" osm_id= \"50637691\" place_rank= \"30\" address_rank= \"30\" boundingbox= \"52.3994612,52.3996426,13.0479574,13.0481754\" lat= \"52.399550700000006\" lon= \"13.048066846939687\" display_name= \"Brandenburger Tor, Brandenburger Stra&#xDF;e, Historische Innenstadt, Innenstadt, Potsdam, Brandenburg, 14467, Germany\" class= \"tourism\" type= \"attraction\" importance= \"0.29402874005524\" > <tourism> Brandenburger Tor </tourism> <road> Brandenburger Stra &#xDF; e </road> <suburb> Historische Innenstadt </suburb> <city> Potsdam </city> <state> Brandenburg </state> <postcode> 14467 </postcode> <country> Germany </country> <country_code> de </country_code> </place> <place place_id= \"567505\" osm_type= \"node\" osm_id= \"240109189\" place_rank= \"15\" address_rank= \"16\" boundingbox= \"52.3586925,52.6786925,13.2396024,13.5596024\" lat= \"52.5186925\" lon= \"13.3996024\" display_name= \"Berlin, 10178, Germany\" class= \"place\" type= \"city\" importance= \"0.78753902824914\" > <city> Berlin </city> <state> Berlin </state> <postcode> 10178 </postcode> <country> Germany </country> <country_code> de </country_code> </place> </lookupresults>","title":"XML"},{"location":"api/Lookup/#json-with-extratags","text":"https://nominatim.openstreetmap.org/lookup?osm_ids=W50637691&format=json&extratags=1 [ { \"place_id\" : 115462561 , \"licence\" : \"Data \u00a9 OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\" , \"osm_type\" : \"way\" , \"osm_id\" : 50637691 , \"boundingbox\" : [ \"52.3994612\" , \"52.3996426\" , \"13.0479574\" , \"13.0481754\" ], \"lat\" : \"52.399550700000006\" , \"lon\" : \"13.048066846939687\" , \"display_name\" : \"Brandenburger Tor, Brandenburger Stra\u00dfe, Historische Innenstadt, Innenstadt, Potsdam, Brandenburg, 14467, Germany\" , \"class\" : \"tourism\" , \"type\" : \"attraction\" , \"importance\" : 0.2940287400552381 , \"address\" : { \"tourism\" : \"Brandenburger Tor\" , \"road\" : \"Brandenburger Stra\u00dfe\" , \"suburb\" : \"Historische Innenstadt\" , \"city\" : \"Potsdam\" , \"state\" : \"Brandenburg\" , \"postcode\" : \"14467\" , \"country\" : \"Germany\" , \"country_code\" : \"de\" }, \"extratags\" : { \"image\" : \"http://commons.wikimedia.org/wiki/File:Potsdam_brandenburger_tor.jpg\" , \"heritage\" : \"4\" , \"wikidata\" : \"Q695045\" , \"architect\" : \"Carl von Gontard;Georg Christian Unger\" , \"wikipedia\" : \"de:Brandenburger Tor (Potsdam)\" , \"wheelchair\" : \"yes\" , \"description\" : \"Kleines Brandenburger Tor in Potsdam\" , \"heritage:website\" : \"http://www.bldam-brandenburg.de/images/stories/PDF/DML%202012/04-p-internet-13.pdf\" , \"heritage:operator\" : \"bldam\" , \"architect:wikidata\" : \"Q68768;Q95223\" , \"year_of_construction\" : \"1771\" } } ]","title":"JSON with extratags"},{"location":"api/Output/","text":"Place Output \uf0c1 The /reverse , /search and /lookup API calls produce very similar output which is explained in this section. There is one section for each format. The format correspond to what was selected via the format parameter. JSON \uf0c1 The JSON format returns an array of places (for search and lookup) or a single place (for reverse) of the following format: { \"place_id\": \"100149\", \"licence\": \"Data \u00a9 OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\", \"osm_type\": \"node\", \"osm_id\": \"107775\", \"boundingbox\": [\"51.3473219\", \"51.6673219\", \"-0.2876474\", \"0.0323526\"], \"lat\": \"51.5073219\", \"lon\": \"-0.1276474\", \"display_name\": \"London, Greater London, England, SW1A 2DU, United Kingdom\", \"class\": \"place\", \"type\": \"city\", \"importance\": 0.9654895765402, \"icon\": \"https://nominatim.openstreetmap.org/images/mapicons/poi_place_city.p.20.png\", \"address\": { \"city\": \"London\", \"state_district\": \"Greater London\", \"state\": \"England\", \"ISO3166-2-lvl4\": \"GB-ENG\", \"postcode\": \"SW1A 2DU\", \"country\": \"United Kingdom\", \"country_code\": \"gb\" }, \"extratags\": { \"capital\": \"yes\", \"website\": \"http://www.london.gov.uk\", \"wikidata\": \"Q84\", \"wikipedia\": \"en:London\", \"population\": \"8416535\" } } The possible fields are: place_id - reference to the Nominatim internal database ID ( see notes ) osm_type , osm_id - reference to the OSM object ( see notes ) boundingbox - area of corner coordinates ( see notes ) lat , lon - latitude and longitude of the centroid of the object display_name - full comma-separated address class , type - key and value of the main OSM tag importance - computed importance rank icon - link to class icon (if available) address - dictionary of address details (only with addressdetails=1 , see notes ) extratags - dictionary with additional useful tags like website or maxspeed (only with extratags=1 ) namedetails - dictionary with full list of available names including ref etc. geojson , svg , geotext , geokml - full geometry (only with the appropriate polygon_* parameter) JSONv2 \uf0c1 This is the same as the JSON format with two changes: class renamed to category additional field place_rank with the search rank of the object GeoJSON \uf0c1 This format follows the RFC7946 . Every feature includes a bounding box ( bbox ). The properties object has the following fields: place_id - reference to the Nominatim internal database ID ( see notes ) osm_type , osm_id - reference to the OSM object ( see notes ) category , type - key and value of the main OSM tag display_name - full comma-separated address place_rank - class search rank importance - computed importance rank icon - link to class icon (if available) address - dictionary of address details (only with addressdetails=1 , see notes ) extratags - dictionary with additional useful tags like website or maxspeed (only with extratags=1 ) namedetails - dictionary with full list of available names including ref etc. Use polygon_geojson to output the full geometry of the object instead of the centroid. GeocodeJSON \uf0c1 The GeocodeJSON format follows the GeocodeJSON spec 0.1.0 . The following feature attributes are implemented: osm_type , osm_id - reference to the OSM object (unofficial extension, see notes ) type - the 'address level' of the object ('house', 'street', district , city , county , state , country , locality ) osm_key - key of the main tag of the OSM object (e.g. boundary, highway, amenity) osm_value - value of the main tag of the OSM object (e.g. residential, restaurant) label - full comma-separated address name - localised name of the place housenumber , street , locality , district , postcode , city , county , state , country - provided when it can be determined from the address admin - list of localised names of administrative boundaries (only with addressdetails=1 ) Use polygon_geojson to output the full geometry of the object instead of the centroid. XML \uf0c1 The XML response returns one or more place objects in slightly different formats depending on the API call. Reverse \uf0c1 <reversegeocode timestamp= \"Sat, 11 Aug 18 11:53:21 +0000\" attribution= \"Data \u00a9 OpenStreetMap contributors, ODbL 1.0. https://www.openstreetmap.org/copyright\" querystring= \"lat=48.400381&lon=11.745876&zoom=5&format=xml\" > <result place_id= \"179509537\" osm_type= \"relation\" osm_id= \"2145268\" ref= \"BY\" place_rank= \"15\" address_rank= \"15\" lat= \"48.9467562\" lon= \"11.4038717\" boundingbox= \"47.2701114,50.5647142,8.9763497,13.8396373\" > Bavaria, Germany </result> <addressparts> <state> Bavaria </state> <ISO3166-2-lvl4> DE-BY </ISO3166-2-lvl4> <country> Germany </country> <country_code> de </country_code> </addressparts> <extratags> <tag key= \"place\" value= \"state\" /> <tag key= \"wikidata\" value= \"Q980\" /> <tag key= \"wikipedia\" value= \"de:Bayern\" /> <tag key= \"population\" value= \"12520000\" /> <tag key= \"name:prefix\" value= \"Freistaat\" /> </extratags> </reversegeocode> The attributes of the outer reversegeocode element return generic information about the query, including the time when the response was sent (in UTC), attribution to OSM and the original querystring. The place information can be found in the result element. The attributes of that element contain: place_id - reference to the Nominatim internal database ID ( see notes ) osm_type , osm_id - reference to the OSM object ( see notes ) ref - content of ref tag if it exists lat , lon - latitude and longitude of the centroid of the object boundingbox - comma-separated list of corner coordinates ( see notes ) The full address of the result can be found in the content of the result element as a comma-separated list. Additional information requested with addressdetails=1 , extratags=1 and namedetails=1 can be found in extra elements. Search and Lookup \uf0c1 <searchresults timestamp=\"Sat, 11 Aug 18 11:55:35 +0000\" attribution=\"Data \u00a9 OpenStreetMap contributors, ODbL 1.0. https://www.openstreetmap.org/copyright\" querystring=\"london\" polygon=\"false\" exclude_place_ids=\"100149\" more_url=\"https://nominatim.openstreetmap.org/search.php?q=london&addressdetails=1&extratags=1&exclude_place_ids=100149&format=xml&accept-language=en-US%2Cen%3Bq%3D0.7%2Cde%3Bq%3D0.3\"> <place place_id=\"100149\" osm_type=\"node\" osm_id=\"107775\" place_rank=\"15\" address_rank=\"15\" boundingbox=\"51.3473219,51.6673219,-0.2876474,0.0323526\" lat=\"51.5073219\" lon=\"-0.1276474\" display_name=\"London, Greater London, England, SW1A 2DU, United Kingdom\" class=\"place\" type=\"city\" importance=\"0.9654895765402\" icon=\"https://nominatim.openstreetmap.org/images/mapicons/poi_place_city.p.20.png\"> <extratags> <tag key=\"capital\" value=\"yes\"/> <tag key=\"website\" value=\"http://www.london.gov.uk\"/> <tag key=\"wikidata\" value=\"Q84\"/> <tag key=\"wikipedia\" value=\"en:London\"/> <tag key=\"population\" value=\"8416535\"/> </extratags> <city>London</city> <state_district>Greater London</state_district> <state>England</state> <ISO3166-2-lvl4>GB-ENG</ISO3166-2-lvl4> <postcode>SW1A 2DU</postcode> <country>United Kingdom</country> <country_code>gb</country_code> </place> </searchresults> The attributes of the outer searchresults or lookupresults element return generic information about the query: timestamp - UTC time when the response was sent attribution - OSM licensing information querystring - original query polygon - true when extra geometry information was requested exclude_place_ids - IDs of places that should be ignored in a follow-up request more_url - search call that will yield additional results for the query just sent The place information can be found in the place elements, of which there may be more than one. The attributes of that element contain: place_id - reference to the Nominatim internal database ID ( see notes ) osm_type , osm_id - reference to the OSM object ( see notes ) ref - content of ref tag if it exists lat , lon - latitude and longitude of the centroid of the object boundingbox - comma-separated list of corner coordinates ( see notes ) place_rank - class search rank address_rank - place address rank display_name - full comma-separated address class , type - key and value of the main OSM tag importance - computed importance rank icon - link to class icon (if available) When addressdetails=1 is requested, the localised address parts appear as subelements with the type of the address part. Additional information requested with extratags=1 and namedetails=1 can be found in extra elements as sub-element of extratags and namedetails respectively. Notes on field values \uf0c1 place_id is not a persistent id \uf0c1 The place_id is an internal identifier that is assigned data is imported into a Nominatim database. The same OSM object will have a different value on another server. It may even change its ID on the same server when it is removed and reimported while updating the database with fresh OSM data. It is thus not useful to treat it as permanent for later use. The combination osm_type + osm_id is slightly better but remember in OpenStreetMap mappers can delete, split, recreate places (and those get a new osm_id ), there is no link between those old and new ids. Places can also change their meaning without changing their osm_id , e.g. when a restaurant is retagged as supermarket. For a more in-depth discussion see Permanent ID . If you need an ID that is consistent over multiple installations of Nominatim, then you should use the combination of osm_type + osm_id + class . OSM reference \uf0c1 Nominatim may sometimes return special objects that do not correspond directly to an object in OpenStreetMap. These are: Postcodes . Nominatim returns an postcode point created from all mapped postcodes of the same name. The class and type of these object is place=postcdode . No osm_type and osm_id are included in the result. Housenumber interpolations . Nominatim returns a single interpolated housenumber from the interpolation way. The class and type are place=house and osm_type and osm_id correspond to the interpolation way in OSM. TIGER housenumber. Nominatim returns a single interpolated housenumber from the TIGER data. The class and type are place=house and osm_type and osm_id correspond to the street mentioned in the result. Please note that the osm_type and osm_id returned may be changed in the future. You should not expect to only find node , way and relation for the type. boundingbox \uf0c1 Comma separated list of min latitude, max latitude, min longitude, max longitude. The whole planet would be -90,90,-180,180 . Can be used to pan and center the map on the result, for example with leafletjs mapping library map.fitBounds([[bbox[0],bbox[2]],[bbox[1],bbox[3]]], {padding: [20, 20], maxzoom: 16}); Bounds crossing the antimeridian have a min latitude -180 and max latitude 180, essentially covering the entire planet (see issue 184 ). addressdetails \uf0c1 Address details in the xml and json formats return a list of names together with a designation label. Per default the following labels may appear: continent country, country_code region, state, state_district, county, ISO3166-2-lvl municipality, city, town, village city_district, district, borough, suburb, subdivision hamlet, croft, isolated_dwelling neighbourhood, allotments, quarter city_block, residential, farm, farmyard, industrial, commercial, retail road house_number, house_name emergency, historic, military, natural, landuse, place, railway, man_made, aerialway, boundary, amenity, aeroway, club, craft, leisure, office, mountain_pass, shop, tourism, bridge, tunnel, waterway postcode They roughly correspond to the classification of the OpenStreetMap data according to either the place tag or the main key of the object.","title":"Place Output Formats"},{"location":"api/Output/#place-output","text":"The /reverse , /search and /lookup API calls produce very similar output which is explained in this section. There is one section for each format. The format correspond to what was selected via the format parameter.","title":"Place Output"},{"location":"api/Output/#json","text":"The JSON format returns an array of places (for search and lookup) or a single place (for reverse) of the following format: { \"place_id\": \"100149\", \"licence\": \"Data \u00a9 OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\", \"osm_type\": \"node\", \"osm_id\": \"107775\", \"boundingbox\": [\"51.3473219\", \"51.6673219\", \"-0.2876474\", \"0.0323526\"], \"lat\": \"51.5073219\", \"lon\": \"-0.1276474\", \"display_name\": \"London, Greater London, England, SW1A 2DU, United Kingdom\", \"class\": \"place\", \"type\": \"city\", \"importance\": 0.9654895765402, \"icon\": \"https://nominatim.openstreetmap.org/images/mapicons/poi_place_city.p.20.png\", \"address\": { \"city\": \"London\", \"state_district\": \"Greater London\", \"state\": \"England\", \"ISO3166-2-lvl4\": \"GB-ENG\", \"postcode\": \"SW1A 2DU\", \"country\": \"United Kingdom\", \"country_code\": \"gb\" }, \"extratags\": { \"capital\": \"yes\", \"website\": \"http://www.london.gov.uk\", \"wikidata\": \"Q84\", \"wikipedia\": \"en:London\", \"population\": \"8416535\" } } The possible fields are: place_id - reference to the Nominatim internal database ID ( see notes ) osm_type , osm_id - reference to the OSM object ( see notes ) boundingbox - area of corner coordinates ( see notes ) lat , lon - latitude and longitude of the centroid of the object display_name - full comma-separated address class , type - key and value of the main OSM tag importance - computed importance rank icon - link to class icon (if available) address - dictionary of address details (only with addressdetails=1 , see notes ) extratags - dictionary with additional useful tags like website or maxspeed (only with extratags=1 ) namedetails - dictionary with full list of available names including ref etc. geojson , svg , geotext , geokml - full geometry (only with the appropriate polygon_* parameter)","title":"JSON"},{"location":"api/Output/#jsonv2","text":"This is the same as the JSON format with two changes: class renamed to category additional field place_rank with the search rank of the object","title":"JSONv2"},{"location":"api/Output/#geojson","text":"This format follows the RFC7946 . Every feature includes a bounding box ( bbox ). The properties object has the following fields: place_id - reference to the Nominatim internal database ID ( see notes ) osm_type , osm_id - reference to the OSM object ( see notes ) category , type - key and value of the main OSM tag display_name - full comma-separated address place_rank - class search rank importance - computed importance rank icon - link to class icon (if available) address - dictionary of address details (only with addressdetails=1 , see notes ) extratags - dictionary with additional useful tags like website or maxspeed (only with extratags=1 ) namedetails - dictionary with full list of available names including ref etc. Use polygon_geojson to output the full geometry of the object instead of the centroid.","title":"GeoJSON"},{"location":"api/Output/#geocodejson","text":"The GeocodeJSON format follows the GeocodeJSON spec 0.1.0 . The following feature attributes are implemented: osm_type , osm_id - reference to the OSM object (unofficial extension, see notes ) type - the 'address level' of the object ('house', 'street', district , city , county , state , country , locality ) osm_key - key of the main tag of the OSM object (e.g. boundary, highway, amenity) osm_value - value of the main tag of the OSM object (e.g. residential, restaurant) label - full comma-separated address name - localised name of the place housenumber , street , locality , district , postcode , city , county , state , country - provided when it can be determined from the address admin - list of localised names of administrative boundaries (only with addressdetails=1 ) Use polygon_geojson to output the full geometry of the object instead of the centroid.","title":"GeocodeJSON"},{"location":"api/Output/#xml","text":"The XML response returns one or more place objects in slightly different formats depending on the API call.","title":"XML"},{"location":"api/Output/#reverse","text":"<reversegeocode timestamp= \"Sat, 11 Aug 18 11:53:21 +0000\" attribution= \"Data \u00a9 OpenStreetMap contributors, ODbL 1.0. https://www.openstreetmap.org/copyright\" querystring= \"lat=48.400381&lon=11.745876&zoom=5&format=xml\" > <result place_id= \"179509537\" osm_type= \"relation\" osm_id= \"2145268\" ref= \"BY\" place_rank= \"15\" address_rank= \"15\" lat= \"48.9467562\" lon= \"11.4038717\" boundingbox= \"47.2701114,50.5647142,8.9763497,13.8396373\" > Bavaria, Germany </result> <addressparts> <state> Bavaria </state> <ISO3166-2-lvl4> DE-BY </ISO3166-2-lvl4> <country> Germany </country> <country_code> de </country_code> </addressparts> <extratags> <tag key= \"place\" value= \"state\" /> <tag key= \"wikidata\" value= \"Q980\" /> <tag key= \"wikipedia\" value= \"de:Bayern\" /> <tag key= \"population\" value= \"12520000\" /> <tag key= \"name:prefix\" value= \"Freistaat\" /> </extratags> </reversegeocode> The attributes of the outer reversegeocode element return generic information about the query, including the time when the response was sent (in UTC), attribution to OSM and the original querystring. The place information can be found in the result element. The attributes of that element contain: place_id - reference to the Nominatim internal database ID ( see notes ) osm_type , osm_id - reference to the OSM object ( see notes ) ref - content of ref tag if it exists lat , lon - latitude and longitude of the centroid of the object boundingbox - comma-separated list of corner coordinates ( see notes ) The full address of the result can be found in the content of the result element as a comma-separated list. Additional information requested with addressdetails=1 , extratags=1 and namedetails=1 can be found in extra elements.","title":"Reverse"},{"location":"api/Output/#search-and-lookup","text":"<searchresults timestamp=\"Sat, 11 Aug 18 11:55:35 +0000\" attribution=\"Data \u00a9 OpenStreetMap contributors, ODbL 1.0. https://www.openstreetmap.org/copyright\" querystring=\"london\" polygon=\"false\" exclude_place_ids=\"100149\" more_url=\"https://nominatim.openstreetmap.org/search.php?q=london&addressdetails=1&extratags=1&exclude_place_ids=100149&format=xml&accept-language=en-US%2Cen%3Bq%3D0.7%2Cde%3Bq%3D0.3\"> <place place_id=\"100149\" osm_type=\"node\" osm_id=\"107775\" place_rank=\"15\" address_rank=\"15\" boundingbox=\"51.3473219,51.6673219,-0.2876474,0.0323526\" lat=\"51.5073219\" lon=\"-0.1276474\" display_name=\"London, Greater London, England, SW1A 2DU, United Kingdom\" class=\"place\" type=\"city\" importance=\"0.9654895765402\" icon=\"https://nominatim.openstreetmap.org/images/mapicons/poi_place_city.p.20.png\"> <extratags> <tag key=\"capital\" value=\"yes\"/> <tag key=\"website\" value=\"http://www.london.gov.uk\"/> <tag key=\"wikidata\" value=\"Q84\"/> <tag key=\"wikipedia\" value=\"en:London\"/> <tag key=\"population\" value=\"8416535\"/> </extratags> <city>London</city> <state_district>Greater London</state_district> <state>England</state> <ISO3166-2-lvl4>GB-ENG</ISO3166-2-lvl4> <postcode>SW1A 2DU</postcode> <country>United Kingdom</country> <country_code>gb</country_code> </place> </searchresults> The attributes of the outer searchresults or lookupresults element return generic information about the query: timestamp - UTC time when the response was sent attribution - OSM licensing information querystring - original query polygon - true when extra geometry information was requested exclude_place_ids - IDs of places that should be ignored in a follow-up request more_url - search call that will yield additional results for the query just sent The place information can be found in the place elements, of which there may be more than one. The attributes of that element contain: place_id - reference to the Nominatim internal database ID ( see notes ) osm_type , osm_id - reference to the OSM object ( see notes ) ref - content of ref tag if it exists lat , lon - latitude and longitude of the centroid of the object boundingbox - comma-separated list of corner coordinates ( see notes ) place_rank - class search rank address_rank - place address rank display_name - full comma-separated address class , type - key and value of the main OSM tag importance - computed importance rank icon - link to class icon (if available) When addressdetails=1 is requested, the localised address parts appear as subelements with the type of the address part. Additional information requested with extratags=1 and namedetails=1 can be found in extra elements as sub-element of extratags and namedetails respectively.","title":"Search and Lookup"},{"location":"api/Output/#notes-on-field-values","text":"","title":"Notes on field values"},{"location":"api/Output/#place_id-is-not-a-persistent-id","text":"The place_id is an internal identifier that is assigned data is imported into a Nominatim database. The same OSM object will have a different value on another server. It may even change its ID on the same server when it is removed and reimported while updating the database with fresh OSM data. It is thus not useful to treat it as permanent for later use. The combination osm_type + osm_id is slightly better but remember in OpenStreetMap mappers can delete, split, recreate places (and those get a new osm_id ), there is no link between those old and new ids. Places can also change their meaning without changing their osm_id , e.g. when a restaurant is retagged as supermarket. For a more in-depth discussion see Permanent ID . If you need an ID that is consistent over multiple installations of Nominatim, then you should use the combination of osm_type + osm_id + class .","title":"place_id is not a persistent id"},{"location":"api/Output/#osm-reference","text":"Nominatim may sometimes return special objects that do not correspond directly to an object in OpenStreetMap. These are: Postcodes . Nominatim returns an postcode point created from all mapped postcodes of the same name. The class and type of these object is place=postcdode . No osm_type and osm_id are included in the result. Housenumber interpolations . Nominatim returns a single interpolated housenumber from the interpolation way. The class and type are place=house and osm_type and osm_id correspond to the interpolation way in OSM. TIGER housenumber. Nominatim returns a single interpolated housenumber from the TIGER data. The class and type are place=house and osm_type and osm_id correspond to the street mentioned in the result. Please note that the osm_type and osm_id returned may be changed in the future. You should not expect to only find node , way and relation for the type.","title":"OSM reference"},{"location":"api/Output/#boundingbox","text":"Comma separated list of min latitude, max latitude, min longitude, max longitude. The whole planet would be -90,90,-180,180 . Can be used to pan and center the map on the result, for example with leafletjs mapping library map.fitBounds([[bbox[0],bbox[2]],[bbox[1],bbox[3]]], {padding: [20, 20], maxzoom: 16}); Bounds crossing the antimeridian have a min latitude -180 and max latitude 180, essentially covering the entire planet (see issue 184 ).","title":"boundingbox"},{"location":"api/Output/#addressdetails","text":"Address details in the xml and json formats return a list of names together with a designation label. Per default the following labels may appear: continent country, country_code region, state, state_district, county, ISO3166-2-lvl municipality, city, town, village city_district, district, borough, suburb, subdivision hamlet, croft, isolated_dwelling neighbourhood, allotments, quarter city_block, residential, farm, farmyard, industrial, commercial, retail road house_number, house_name emergency, historic, military, natural, landuse, place, railway, man_made, aerialway, boundary, amenity, aeroway, club, craft, leisure, office, mountain_pass, shop, tourism, bridge, tunnel, waterway postcode They roughly correspond to the classification of the OpenStreetMap data according to either the place tag or the main key of the object.","title":"addressdetails"},{"location":"api/Overview/","text":"Nominatim API \uf0c1 Nominatim indexes named (or numbered) features within the OpenStreetMap (OSM) dataset and a subset of other unnamed features (pubs, hotels, churches, etc). Its API has the following endpoints for querying the data: /search - search OSM objects by name or type /reverse - search OSM object by their location /lookup - look up address details for OSM objects by their ID /status - query the status of the server /deletable - list objects that have been deleted in OSM but are held back in Nominatim in case the deletion was accidental /polygons - list of broken polygons detected by Nominatim /details - show internal details for an object (for debugging only)","title":"Overview"},{"location":"api/Overview/#nominatim-api","text":"Nominatim indexes named (or numbered) features within the OpenStreetMap (OSM) dataset and a subset of other unnamed features (pubs, hotels, churches, etc). Its API has the following endpoints for querying the data: /search - search OSM objects by name or type /reverse - search OSM object by their location /lookup - look up address details for OSM objects by their ID /status - query the status of the server /deletable - list objects that have been deleted in OSM but are held back in Nominatim in case the deletion was accidental /polygons - list of broken polygons detected by Nominatim /details - show internal details for an object (for debugging only)","title":"Nominatim API"},{"location":"api/Reverse/","text":"Reverse Geocoding \uf0c1 Reverse geocoding generates an address from a latitude and longitude. How it works \uf0c1 The reverse geocoding API does not exactly compute the address for the coordinate it receives. It works by finding the closest suitable OSM object and returning its address information. This may occasionally lead to unexpected results. First of all, Nominatim only includes OSM objects in its index that are suitable for searching. Small, unnamed paths for example are missing from the database and can therefore not be used for reverse geocoding either. The other issue to be aware of is that the closest OSM object may not always have a similar enough address to the coordinate you were requesting. For example, in dense city areas it may belong to a completely different street. Parameters \uf0c1 The main format of the reverse API is https://nominatim.openstreetmap.org/reverse?lat=<value>&lon=<value>&<params> where lat and lon are latitude and longitude of a coordinate in WGS84 projection. The API returns exactly one result or an error when the coordinate is in an area with no OSM data coverage. Additional parameters are accepted as listed below. Deprecation warning The reverse API used to allow address lookup for a single OSM object by its OSM id. This use is now deprecated. Use the Address Lookup API instead. Output format \uf0c1 format=[xml|json|jsonv2|geojson|geocodejson] See Place Output Formats for details on each format. (Default: xml) json_callback=<string> Wrap JSON output in a callback function ( JSONP ) i.e. <string>(<json>) . Only has an effect for JSON output formats. Output details \uf0c1 addressdetails=[0|1] Include a breakdown of the address into elements. (Default: 1) extratags=[0|1] Include additional information in the result if available, e.g. wikipedia link, opening hours. (Default: 0) namedetails=[0|1] Include a list of alternative names in the results. These may include language variants, references, operator and brand. (Default: 0) Language of results \uf0c1 accept-language=<browser language string> Preferred language order for showing search results, overrides the value specified in the \"Accept-Language\" HTTP header. Either use a standard RFC2616 accept-language string or a simple comma-separated list of language codes. Result limitation \uf0c1 zoom=[0-18] Level of detail required for the address. Default: 18. This is a number that corresponds roughly to the zoom level used in XYZ tile sources in frameworks like Leaflet.js, Openlayers etc. In terms of address details the zoom levels are as follows: zoom address detail 3 country 5 state 8 county 10 city 14 suburb 16 major streets 17 major and minor streets 18 building Polygon output \uf0c1 polygon_geojson=1 polygon_kml=1 polygon_svg=1 polygon_text=1 Output geometry of results as a GeoJSON, KML, SVG or WKT. Only one of these options can be used at a time. (Default: 0) polygon_threshold=0.0 Return a simplified version of the output geometry. The parameter is the tolerance in degrees with which the geometry may differ from the original geometry. Topology is preserved in the result. (Default: 0.0) Other \uf0c1 email=<valid email address> If you are making a large number of requests, please include an appropriate email address to identify your requests. See Nominatim's Usage Policy for more details. debug=[0|1] Output assorted developer debug information. Data on internals of Nominatim's \"Search Loop\" logic, and SQL queries. The output is (rough) HTML format. This overrides the specified machine readable format. (Default: 0) Examples \uf0c1 https://nominatim.openstreetmap.org/reverse?format=xml&lat=52.5487429714954&lon=-1.81602098644987&zoom=18&addressdetails=1 <reversegeocode timestamp= \"Fri, 06 Nov 09 16:33:54 +0000\" querystring= \"...\" > <result place_id= \"1620612\" osm_type= \"node\" osm_id= \"452010817\" > 135, Pilkington Avenue, Wylde Green, City of Birmingham, West Midlands (county), B72, United Kingdom </result> <addressparts> <house_number> 135 </house_number> <road> Pilkington Avenue </road> <village> Wylde Green </village> <town> Sutton Coldfield </town> <city> City of Birmingham </city> <county> West Midlands (county) </county> <postcode> B72 </postcode> <country> United Kingdom </country> <country_code> gb </country_code> </addressparts> </reversegeocode> Example with format=jsonv2 \uf0c1 https://nominatim.openstreetmap.org/reverse?format=jsonv2&lat=-34.44076&lon=-58.70521 { \"place_id\" : \"134140761\" , \"licence\" : \"Data \u00a9 OpenStreetMap contributors, ODbL 1.0. https:\\/\\/www.openstreetmap.org\\/copyright\" , \"osm_type\" : \"way\" , \"osm_id\" : \"280940520\" , \"lat\" : \"-34.4391708\" , \"lon\" : \"-58.7064573\" , \"place_rank\" : \"26\" , \"category\" : \"highway\" , \"type\" : \"motorway\" , \"importance\" : \"0.1\" , \"addresstype\" : \"road\" , \"display_name\" : \"Autopista Pedro Eugenio Aramburu, El Tri\u00e1ngulo, Partido de Malvinas Argentinas, Buenos Aires, 1.619, Argentina\" , \"name\" : \"Autopista Pedro Eugenio Aramburu\" , \"address\" :{ \"road\" : \"Autopista Pedro Eugenio Aramburu\" , \"village\" : \"El Tri\u00e1ngulo\" , \"state_district\" : \"Partido de Malvinas Argentinas\" , \"state\" : \"Buenos Aires\" , \"postcode\" : \"1.619\" , \"country\" : \"Argentina\" , \"country_code\" : \"ar\" }, \"boundingbox\" :[ \"-34.44159\" , \"-34.4370994\" , \"-58.7086067\" , \"-58.7044712\" ] } Example with format=geojson \uf0c1 https://nominatim.openstreetmap.org/reverse?format=geojson&lat=44.50155&lon=11.33989 { \"type\" : \"FeatureCollection\" , \"licence\" : \"Data \u00a9 OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\" , \"features\" : [ { \"type\" : \"Feature\" , \"properties\" : { \"place_id\" : \"18512203\" , \"osm_type\" : \"node\" , \"osm_id\" : \"1704756187\" , \"place_rank\" : \"30\" , \"category\" : \"place\" , \"type\" : \"house\" , \"importance\" : \"0\" , \"addresstype\" : \"place\" , \"name\" : null , \"display_name\" : \"71, Via Guglielmo Marconi, Saragozza-Porto, Bologna, BO, Emilia-Romagna, 40122, Italy\" , \"address\" : { \"house_number\" : \"71\" , \"road\" : \"Via Guglielmo Marconi\" , \"suburb\" : \"Saragozza-Porto\" , \"city\" : \"Bologna\" , \"county\" : \"BO\" , \"state\" : \"Emilia-Romagna\" , \"postcode\" : \"40122\" , \"country\" : \"Italy\" , \"country_code\" : \"it\" } }, \"bbox\" : [ 11.3397676 , 44.5014307 , 11.3399676 , 44.5016307 ], \"geometry\" : { \"type\" : \"Point\" , \"coordinates\" : [ 11.3398676 , 44.5015307 ] } } ] } Example with format=geocodejson \uf0c1 https://nominatim.openstreetmap.org/reverse?format=geocodejson&lat=60.2299&lon=11.1663 { \"type\" : \"FeatureCollection\" , \"geocoding\" : { \"version\" : \"0.1.0\" , \"attribution\" : \"Data \u00a9 OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\" , \"licence\" : \"ODbL\" , \"query\" : \"60.229917843587,11.16630979382\" }, \"features\" : { \"type\" : \"Feature\" , \"properties\" : { \"geocoding\" : { \"place_id\" : \"42700574\" , \"osm_type\" : \"node\" , \"osm_id\" : \"3110596255\" , \"type\" : \"house\" , \"accuracy\" : 0 , \"label\" : \"1, L\u00f8venbergvegen, Mogreina, Ullensaker, Akershus, 2054, Norway\" , \"name\" : null , \"housenumber\" : \"1\" , \"street\" : \"L\u00f8venbergvegen\" , \"postcode\" : \"2054\" , \"county\" : \"Akershus\" , \"country\" : \"Norway\" , \"admin\" : { \"level7\" : \"Ullensaker\" , \"level4\" : \"Akershus\" , \"level2\" : \"Norway\" } } }, \"geometry\" : { \"type\" : \"Point\" , \"coordinates\" : [ 11.1658572 , 60.2301296 ] } } }","title":"Reverse"},{"location":"api/Reverse/#reverse-geocoding","text":"Reverse geocoding generates an address from a latitude and longitude.","title":"Reverse Geocoding"},{"location":"api/Reverse/#how-it-works","text":"The reverse geocoding API does not exactly compute the address for the coordinate it receives. It works by finding the closest suitable OSM object and returning its address information. This may occasionally lead to unexpected results. First of all, Nominatim only includes OSM objects in its index that are suitable for searching. Small, unnamed paths for example are missing from the database and can therefore not be used for reverse geocoding either. The other issue to be aware of is that the closest OSM object may not always have a similar enough address to the coordinate you were requesting. For example, in dense city areas it may belong to a completely different street.","title":"How it works"},{"location":"api/Reverse/#parameters","text":"The main format of the reverse API is https://nominatim.openstreetmap.org/reverse?lat=<value>&lon=<value>&<params> where lat and lon are latitude and longitude of a coordinate in WGS84 projection. The API returns exactly one result or an error when the coordinate is in an area with no OSM data coverage. Additional parameters are accepted as listed below. Deprecation warning The reverse API used to allow address lookup for a single OSM object by its OSM id. This use is now deprecated. Use the Address Lookup API instead.","title":"Parameters"},{"location":"api/Reverse/#output-format","text":"format=[xml|json|jsonv2|geojson|geocodejson] See Place Output Formats for details on each format. (Default: xml) json_callback=<string> Wrap JSON output in a callback function ( JSONP ) i.e. <string>(<json>) . Only has an effect for JSON output formats.","title":"Output format"},{"location":"api/Reverse/#output-details","text":"addressdetails=[0|1] Include a breakdown of the address into elements. (Default: 1) extratags=[0|1] Include additional information in the result if available, e.g. wikipedia link, opening hours. (Default: 0) namedetails=[0|1] Include a list of alternative names in the results. These may include language variants, references, operator and brand. (Default: 0)","title":"Output details"},{"location":"api/Reverse/#language-of-results","text":"accept-language=<browser language string> Preferred language order for showing search results, overrides the value specified in the \"Accept-Language\" HTTP header. Either use a standard RFC2616 accept-language string or a simple comma-separated list of language codes.","title":"Language of results"},{"location":"api/Reverse/#result-limitation","text":"zoom=[0-18] Level of detail required for the address. Default: 18. This is a number that corresponds roughly to the zoom level used in XYZ tile sources in frameworks like Leaflet.js, Openlayers etc. In terms of address details the zoom levels are as follows: zoom address detail 3 country 5 state 8 county 10 city 14 suburb 16 major streets 17 major and minor streets 18 building","title":"Result limitation"},{"location":"api/Reverse/#polygon-output","text":"polygon_geojson=1 polygon_kml=1 polygon_svg=1 polygon_text=1 Output geometry of results as a GeoJSON, KML, SVG or WKT. Only one of these options can be used at a time. (Default: 0) polygon_threshold=0.0 Return a simplified version of the output geometry. The parameter is the tolerance in degrees with which the geometry may differ from the original geometry. Topology is preserved in the result. (Default: 0.0)","title":"Polygon output"},{"location":"api/Reverse/#other","text":"email=<valid email address> If you are making a large number of requests, please include an appropriate email address to identify your requests. See Nominatim's Usage Policy for more details. debug=[0|1] Output assorted developer debug information. Data on internals of Nominatim's \"Search Loop\" logic, and SQL queries. The output is (rough) HTML format. This overrides the specified machine readable format. (Default: 0)","title":"Other"},{"location":"api/Reverse/#examples","text":"https://nominatim.openstreetmap.org/reverse?format=xml&lat=52.5487429714954&lon=-1.81602098644987&zoom=18&addressdetails=1 <reversegeocode timestamp= \"Fri, 06 Nov 09 16:33:54 +0000\" querystring= \"...\" > <result place_id= \"1620612\" osm_type= \"node\" osm_id= \"452010817\" > 135, Pilkington Avenue, Wylde Green, City of Birmingham, West Midlands (county), B72, United Kingdom </result> <addressparts> <house_number> 135 </house_number> <road> Pilkington Avenue </road> <village> Wylde Green </village> <town> Sutton Coldfield </town> <city> City of Birmingham </city> <county> West Midlands (county) </county> <postcode> B72 </postcode> <country> United Kingdom </country> <country_code> gb </country_code> </addressparts> </reversegeocode>","title":"Examples"},{"location":"api/Reverse/#example-with-formatjsonv2","text":"https://nominatim.openstreetmap.org/reverse?format=jsonv2&lat=-34.44076&lon=-58.70521 { \"place_id\" : \"134140761\" , \"licence\" : \"Data \u00a9 OpenStreetMap contributors, ODbL 1.0. https:\\/\\/www.openstreetmap.org\\/copyright\" , \"osm_type\" : \"way\" , \"osm_id\" : \"280940520\" , \"lat\" : \"-34.4391708\" , \"lon\" : \"-58.7064573\" , \"place_rank\" : \"26\" , \"category\" : \"highway\" , \"type\" : \"motorway\" , \"importance\" : \"0.1\" , \"addresstype\" : \"road\" , \"display_name\" : \"Autopista Pedro Eugenio Aramburu, El Tri\u00e1ngulo, Partido de Malvinas Argentinas, Buenos Aires, 1.619, Argentina\" , \"name\" : \"Autopista Pedro Eugenio Aramburu\" , \"address\" :{ \"road\" : \"Autopista Pedro Eugenio Aramburu\" , \"village\" : \"El Tri\u00e1ngulo\" , \"state_district\" : \"Partido de Malvinas Argentinas\" , \"state\" : \"Buenos Aires\" , \"postcode\" : \"1.619\" , \"country\" : \"Argentina\" , \"country_code\" : \"ar\" }, \"boundingbox\" :[ \"-34.44159\" , \"-34.4370994\" , \"-58.7086067\" , \"-58.7044712\" ] }","title":"Example with format=jsonv2"},{"location":"api/Reverse/#example-with-formatgeojson","text":"https://nominatim.openstreetmap.org/reverse?format=geojson&lat=44.50155&lon=11.33989 { \"type\" : \"FeatureCollection\" , \"licence\" : \"Data \u00a9 OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\" , \"features\" : [ { \"type\" : \"Feature\" , \"properties\" : { \"place_id\" : \"18512203\" , \"osm_type\" : \"node\" , \"osm_id\" : \"1704756187\" , \"place_rank\" : \"30\" , \"category\" : \"place\" , \"type\" : \"house\" , \"importance\" : \"0\" , \"addresstype\" : \"place\" , \"name\" : null , \"display_name\" : \"71, Via Guglielmo Marconi, Saragozza-Porto, Bologna, BO, Emilia-Romagna, 40122, Italy\" , \"address\" : { \"house_number\" : \"71\" , \"road\" : \"Via Guglielmo Marconi\" , \"suburb\" : \"Saragozza-Porto\" , \"city\" : \"Bologna\" , \"county\" : \"BO\" , \"state\" : \"Emilia-Romagna\" , \"postcode\" : \"40122\" , \"country\" : \"Italy\" , \"country_code\" : \"it\" } }, \"bbox\" : [ 11.3397676 , 44.5014307 , 11.3399676 , 44.5016307 ], \"geometry\" : { \"type\" : \"Point\" , \"coordinates\" : [ 11.3398676 , 44.5015307 ] } } ] }","title":"Example with format=geojson"},{"location":"api/Reverse/#example-with-formatgeocodejson","text":"https://nominatim.openstreetmap.org/reverse?format=geocodejson&lat=60.2299&lon=11.1663 { \"type\" : \"FeatureCollection\" , \"geocoding\" : { \"version\" : \"0.1.0\" , \"attribution\" : \"Data \u00a9 OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\" , \"licence\" : \"ODbL\" , \"query\" : \"60.229917843587,11.16630979382\" }, \"features\" : { \"type\" : \"Feature\" , \"properties\" : { \"geocoding\" : { \"place_id\" : \"42700574\" , \"osm_type\" : \"node\" , \"osm_id\" : \"3110596255\" , \"type\" : \"house\" , \"accuracy\" : 0 , \"label\" : \"1, L\u00f8venbergvegen, Mogreina, Ullensaker, Akershus, 2054, Norway\" , \"name\" : null , \"housenumber\" : \"1\" , \"street\" : \"L\u00f8venbergvegen\" , \"postcode\" : \"2054\" , \"county\" : \"Akershus\" , \"country\" : \"Norway\" , \"admin\" : { \"level7\" : \"Ullensaker\" , \"level4\" : \"Akershus\" , \"level2\" : \"Norway\" } } }, \"geometry\" : { \"type\" : \"Point\" , \"coordinates\" : [ 11.1658572 , 60.2301296 ] } } }","title":"Example with format=geocodejson"},{"location":"api/Search/","text":"Search queries \uf0c1 The search API allows you to look up a location from a textual description or address. Nominatim supports structured and free-form search queries. The search query may also contain special phrases which are translated into specific OpenStreetMap (OSM) tags (e.g. Pub => amenity=pub ). This can be used to narrow down the kind of objects to be returned. Warning Special phrases are not suitable to query all objects of a certain type in an area. Nominatim will always just return a collection of the best matches. To download OSM data by object type, use the Overpass API . Parameters \uf0c1 The search API has the following format: https://nominatim.openstreetmap.org/search?<params> The search term may be specified with two different sets of parameters: q=<query> Free-form query string to search for. Free-form queries are processed first left-to-right and then right-to-left if that fails. So you may search for pilkington avenue, birmingham as well as for birmingham, pilkington avenue . Commas are optional, but improve performance by reducing the complexity of the search. street=<housenumber> <streetname> city=<city> county=<county> state=<state> country=<country> postalcode=<postalcode> Alternative query string format split into several parameters for structured requests. Structured requests are faster but are less robust against alternative OSM tagging schemas. Do not combine with q=<query> parameter . Both query forms accept the additional parameters listed below. Output format \uf0c1 format=[xml|json|jsonv2|geojson|geocodejson] See Place Output Formats for details on each format. (Default: jsonv2) Note The Nominatim service at https://nominatim.openstreetmap.org has a different default behaviour for historical reasons. When the format parameter is omitted, the request will be forwarded to the Web UI. json_callback=<string> Wrap JSON output in a callback function ( JSONP ) i.e. <string>(<json>) . Only has an effect for JSON output formats. Output details \uf0c1 addressdetails=[0|1] Include a breakdown of the address into elements. (Default: 0) extratags=[0|1] Include additional information in the result if available, e.g. wikipedia link, opening hours. (Default: 0) namedetails=[0|1] Include a list of alternative names in the results. These may include language variants, references, operator and brand. (Default: 0) Language of results \uf0c1 accept-language=<browser language string> Preferred language order for showing search results, overrides the value specified in the \"Accept-Language\" HTTP header . Either use a standard RFC2616 accept-language string or a simple comma-separated list of language codes. Result limitation \uf0c1 countrycodes=<countrycode>[,<countrycode>][,<countrycode>]... Limit search results to one or more countries. <countrycode> must be the ISO 3166-1alpha2 code, e.g. gb for the United Kingdom, de for Germany. Each place in Nominatim is assigned to one country code based on OSM country boundaries. In rare cases a place may not be in any country at all, for example, in international waters. exclude_place_ids=<place_id,[place_id],[place_id] If you do not want certain OSM objects to appear in the search result, give a comma separated list of the place_id s you want to skip. This can be used to retrieve additional search results. For example, if a previous query only returned a few results, then including those here would cause the search to return other, less accurate, matches (if possible). limit=<integer> Limit the number of returned results. (Default: 10, Maximum: 50) viewbox=<x1>,<y1>,<x2>,<y2> The preferred area to find search results. Any two corner points of the box are accepted as long as they span a real box. x is longitude, y is latitude. bounded=[0|1] When a viewbox is given, restrict the result to items contained within that viewbox (see above). When viewbox and bounded=1 are given, an amenity only search is allowed. Give the special keyword for the amenity in square brackets, e.g. [pub] and a selection of objects of this type is returned. There is no guarantee that the result is complete. (Default: 0) Polygon output \uf0c1 polygon_geojson=1 polygon_kml=1 polygon_svg=1 polygon_text=1 Output geometry of results as a GeoJSON, KML, SVG or WKT. Only one of these options can be used at a time. (Default: 0) polygon_threshold=0.0 Return a simplified version of the output geometry. The parameter is the tolerance in degrees with which the geometry may differ from the original geometry. Topology is preserved in the result. (Default: 0.0) Other \uf0c1 email=<valid email address> If you are making large numbers of request please include an appropriate email address to identify your requests. See Nominatim's Usage Policy for more details. dedupe=[0|1] Sometimes you have several objects in OSM identifying the same place or object in reality. The simplest case is a street being split into many different OSM ways due to different characteristics. Nominatim will attempt to detect such duplicates and only return one match unless this parameter is set to 0. (Default: 1) debug=[0|1] Output assorted developer debug information. Data on internals of Nominatim's \"Search Loop\" logic, and SQL queries. The output is (rough) HTML format. This overrides the specified machine readable format. (Default: 0) Examples \uf0c1 XML with kml polygon \uf0c1 https://nominatim.openstreetmap.org/search?q=135+pilkington+avenue,+birmingham&format=xml&polygon_geojson=1&addressdetails=1 <searchresults timestamp= \"Sat, 07 Nov 09 14:42:10 +0000\" querystring= \"135 pilkington, avenue birmingham\" polygon= \"true\" > <place place_id= \"1620612\" osm_type= \"node\" osm_id= \"452010817\" boundingbox= \"52.548641204834,52.5488433837891,-1.81612110137939,-1.81592094898224\" lat= \"52.5487429714954\" lon= \"-1.81602098644987\" display_name= \"135, Pilkington Avenue, Wylde Green, City of Birmingham, West Midlands (county), B72, United Kingdom\" class= \"place\" type= \"house\" > <geokml> <Polygon> <outerBoundaryIs> <LinearRing> <coordinates> -1.816513,52.548756599999997 -1.816434,52.548747300000002 -1.816429,52.5487629 -1.8163717,52.548756099999999 -1.8163464,52.548834599999999 -1.8164599,52.548848100000001 -1.8164685,52.5488213 -1.8164913,52.548824000000003 -1.816513,52.548756599999997 </coordinates> </LinearRing> </outerBoundaryIs> </Polygon> </geokml> <house_number> 135 </house_number> <road> Pilkington Avenue </road> <village> Wylde Green </village> <town> Sutton Coldfield </town> <city> City of Birmingham </city> <county> West Midlands (county) </county> <postcode> B72 </postcode> <country> United Kingdom </country> <country_code> gb </country_code> </place> </searchresults> JSON with SVG polygon \uf0c1 https://nominatim.openstreetmap.org/search/Unter%20den%20Linden%201%20Berlin?format=json&addressdetails=1&limit=1&polygon_svg=1 { \"address\" : { \"city\" : \"Berlin\" , \"city_district\" : \"Mitte\" , \"construction\" : \"Unter den Linden\" , \"continent\" : \"European Union\" , \"country\" : \"Deutschland\" , \"country_code\" : \"de\" , \"house_number\" : \"1\" , \"neighbourhood\" : \"Scheunenviertel\" , \"postcode\" : \"10117\" , \"public_building\" : \"Kommandantenhaus\" , \"state\" : \"Berlin\" , \"suburb\" : \"Mitte\" }, \"boundingbox\" : [ \"52.5170783996582\" , \"52.5173187255859\" , \"13.3975105285645\" , \"13.3981599807739\" ], \"class\" : \"amenity\" , \"display_name\" : \"Kommandantenhaus, 1, Unter den Linden, Scheunenviertel, Mitte, Berlin, 10117, Deutschland, European Union\" , \"importance\" : 0.73606775332943 , \"lat\" : \"52.51719785\" , \"licence\" : \"Data \\u00a9 OpenStreetMap contributors, ODbL 1.0. https://www.openstreetmap.org/copyright\" , \"lon\" : \"13.3978352028938\" , \"osm_id\" : \"15976890\" , \"osm_type\" : \"way\" , \"place_id\" : \"30848715\" , \"svg\" : \"M 13.397511 -52.517283599999999 L 13.397829400000001 -52.517299800000004 13.398131599999999 -52.517315099999998 13.398159400000001 -52.517112099999999 13.3975388 -52.517080700000001 Z\" , \"type\" : \"public_building\" } JSON with address details \uf0c1 https://nominatim.openstreetmap.org/?addressdetails=1&q=bakery+in+berlin+wedding&format=json&limit=1 { \"address\" : { \"bakery\" : \"B\\u00e4cker Kamps\" , \"city_district\" : \"Mitte\" , \"continent\" : \"European Union\" , \"country\" : \"Deutschland\" , \"country_code\" : \"de\" , \"footway\" : \"Bahnsteig U6\" , \"neighbourhood\" : \"Sprengelkiez\" , \"postcode\" : \"13353\" , \"state\" : \"Berlin\" , \"suburb\" : \"Wedding\" }, \"boundingbox\" : [ \"52.5460929870605\" , \"52.5460968017578\" , \"13.3591794967651\" , \"13.3591804504395\" ], \"class\" : \"shop\" , \"display_name\" : \"B\\u00e4cker Kamps, Bahnsteig U6, Sprengelkiez, Wedding, Mitte, Berlin, 13353, Deutschland, European Union\" , \"icon\" : \"https://nominatim.openstreetmap.org/images/mapicons/shopping_bakery.p.20.png\" , \"importance\" : 0.201 , \"lat\" : \"52.5460941\" , \"licence\" : \"Data \\u00a9 OpenStreetMap contributors, ODbL 1.0. https://www.openstreetmap.org/copyright\" , \"lon\" : \"13.35918\" , \"osm_id\" : \"317179427\" , \"osm_type\" : \"node\" , \"place_id\" : \"1453068\" , \"type\" : \"bakery\" } GeoJSON \uf0c1 https://nominatim.openstreetmap.org/search?q=17+Strada+Pictor+Alexandru+Romano%2C+Bukarest&format=geojson { \"type\" : \"FeatureCollection\" , \"licence\" : \"Data \u00a9 OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\" , \"features\" : [ { \"type\" : \"Feature\" , \"properties\" : { \"place_id\" : \"35811445\" , \"osm_type\" : \"node\" , \"osm_id\" : \"2846295644\" , \"display_name\" : \"17, Strada Pictor Alexandru Romano, Bukarest, Bucharest, Sector 2, Bucharest, 023964, Romania\" , \"place_rank\" : \"30\" , \"category\" : \"place\" , \"type\" : \"house\" , \"importance\" : 0.62025 }, \"bbox\" : [ 26.1156689 , 44.4354754 , 26.1157689 , 44.4355754 ], \"geometry\" : { \"type\" : \"Point\" , \"coordinates\" : [ 26.1157189 , 44.4355254 ] } } ] } GeocodeJSON \uf0c1 https://nominatim.openstreetmap.org/search?q=%CE%91%CE%B3%CE%AF%CE%B1+%CE%A4%CF%81%CE%B9%CE%AC%CE%B4%CE%B1%2C+%CE%91%CE%B4%CF%89%CE%BD%CE%B9%CE%B4%CE%BF%CF%82%2C+Athens%2C+Greece&format=geocodejson { \"type\" : \"FeatureCollection\" , \"geocoding\" : { \"version\" : \"0.1.0\" , \"attribution\" : \"Data \u00a9 OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\" , \"licence\" : \"ODbL\" , \"query\" : \"\u0391\u03b3\u03af\u03b1 \u03a4\u03c1\u03b9\u03ac\u03b4\u03b1, \u0391\u03b4\u03c9\u03bd\u03b9\u03b4\u03bf\u03c2, Athens, Greece\" }, \"features\" : [ { \"type\" : \"Feature\" , \"properties\" : { \"geocoding\" : { \"type\" : \"place_of_worship\" , \"label\" : \"\u0391\u03b3\u03af\u03b1 \u03a4\u03c1\u03b9\u03ac\u03b4\u03b1, \u0391\u03b4\u03c9\u03bd\u03b9\u03b4\u03bf\u03c2, \u0386\u03b3\u03b9\u03bf\u03c2 \u039d\u03b9\u03ba\u03cc\u03bb\u03b1\u03bf\u03c2, 5\u00ba \u0394\u03b7\u03bc\u03bf\u03c4\u03b9\u03ba\u03cc \u0394\u03b9\u03b1\u03bc\u03ad\u03c1\u03b9\u03c3\u03bc\u03b1 \u0391\u03b8\u03b7\u03bd\u03ce\u03bd, Athens, Municipality of Athens, Regional Unit of Central Athens, Region of Attica, Attica, 11472, Greece\" , \"name\" : \"\u0391\u03b3\u03af\u03b1 \u03a4\u03c1\u03b9\u03ac\u03b4\u03b1\" , \"admin\" : null } }, \"geometry\" : { \"type\" : \"Point\" , \"coordinates\" : [ 23.72949633941 , 38.0051697 ] } } ] }","title":"Search"},{"location":"api/Search/#search-queries","text":"The search API allows you to look up a location from a textual description or address. Nominatim supports structured and free-form search queries. The search query may also contain special phrases which are translated into specific OpenStreetMap (OSM) tags (e.g. Pub => amenity=pub ). This can be used to narrow down the kind of objects to be returned. Warning Special phrases are not suitable to query all objects of a certain type in an area. Nominatim will always just return a collection of the best matches. To download OSM data by object type, use the Overpass API .","title":"Search queries"},{"location":"api/Search/#parameters","text":"The search API has the following format: https://nominatim.openstreetmap.org/search?<params> The search term may be specified with two different sets of parameters: q=<query> Free-form query string to search for. Free-form queries are processed first left-to-right and then right-to-left if that fails. So you may search for pilkington avenue, birmingham as well as for birmingham, pilkington avenue . Commas are optional, but improve performance by reducing the complexity of the search. street=<housenumber> <streetname> city=<city> county=<county> state=<state> country=<country> postalcode=<postalcode> Alternative query string format split into several parameters for structured requests. Structured requests are faster but are less robust against alternative OSM tagging schemas. Do not combine with q=<query> parameter . Both query forms accept the additional parameters listed below.","title":"Parameters"},{"location":"api/Search/#output-format","text":"format=[xml|json|jsonv2|geojson|geocodejson] See Place Output Formats for details on each format. (Default: jsonv2) Note The Nominatim service at https://nominatim.openstreetmap.org has a different default behaviour for historical reasons. When the format parameter is omitted, the request will be forwarded to the Web UI. json_callback=<string> Wrap JSON output in a callback function ( JSONP ) i.e. <string>(<json>) . Only has an effect for JSON output formats.","title":"Output format"},{"location":"api/Search/#output-details","text":"addressdetails=[0|1] Include a breakdown of the address into elements. (Default: 0) extratags=[0|1] Include additional information in the result if available, e.g. wikipedia link, opening hours. (Default: 0) namedetails=[0|1] Include a list of alternative names in the results. These may include language variants, references, operator and brand. (Default: 0)","title":"Output details"},{"location":"api/Search/#language-of-results","text":"accept-language=<browser language string> Preferred language order for showing search results, overrides the value specified in the \"Accept-Language\" HTTP header . Either use a standard RFC2616 accept-language string or a simple comma-separated list of language codes.","title":"Language of results"},{"location":"api/Search/#result-limitation","text":"countrycodes=<countrycode>[,<countrycode>][,<countrycode>]... Limit search results to one or more countries. <countrycode> must be the ISO 3166-1alpha2 code, e.g. gb for the United Kingdom, de for Germany. Each place in Nominatim is assigned to one country code based on OSM country boundaries. In rare cases a place may not be in any country at all, for example, in international waters. exclude_place_ids=<place_id,[place_id],[place_id] If you do not want certain OSM objects to appear in the search result, give a comma separated list of the place_id s you want to skip. This can be used to retrieve additional search results. For example, if a previous query only returned a few results, then including those here would cause the search to return other, less accurate, matches (if possible). limit=<integer> Limit the number of returned results. (Default: 10, Maximum: 50) viewbox=<x1>,<y1>,<x2>,<y2> The preferred area to find search results. Any two corner points of the box are accepted as long as they span a real box. x is longitude, y is latitude. bounded=[0|1] When a viewbox is given, restrict the result to items contained within that viewbox (see above). When viewbox and bounded=1 are given, an amenity only search is allowed. Give the special keyword for the amenity in square brackets, e.g. [pub] and a selection of objects of this type is returned. There is no guarantee that the result is complete. (Default: 0)","title":"Result limitation"},{"location":"api/Search/#polygon-output","text":"polygon_geojson=1 polygon_kml=1 polygon_svg=1 polygon_text=1 Output geometry of results as a GeoJSON, KML, SVG or WKT. Only one of these options can be used at a time. (Default: 0) polygon_threshold=0.0 Return a simplified version of the output geometry. The parameter is the tolerance in degrees with which the geometry may differ from the original geometry. Topology is preserved in the result. (Default: 0.0)","title":"Polygon output"},{"location":"api/Search/#other","text":"email=<valid email address> If you are making large numbers of request please include an appropriate email address to identify your requests. See Nominatim's Usage Policy for more details. dedupe=[0|1] Sometimes you have several objects in OSM identifying the same place or object in reality. The simplest case is a street being split into many different OSM ways due to different characteristics. Nominatim will attempt to detect such duplicates and only return one match unless this parameter is set to 0. (Default: 1) debug=[0|1] Output assorted developer debug information. Data on internals of Nominatim's \"Search Loop\" logic, and SQL queries. The output is (rough) HTML format. This overrides the specified machine readable format. (Default: 0)","title":"Other"},{"location":"api/Search/#examples","text":"","title":"Examples"},{"location":"api/Search/#xml-with-kml-polygon","text":"https://nominatim.openstreetmap.org/search?q=135+pilkington+avenue,+birmingham&format=xml&polygon_geojson=1&addressdetails=1 <searchresults timestamp= \"Sat, 07 Nov 09 14:42:10 +0000\" querystring= \"135 pilkington, avenue birmingham\" polygon= \"true\" > <place place_id= \"1620612\" osm_type= \"node\" osm_id= \"452010817\" boundingbox= \"52.548641204834,52.5488433837891,-1.81612110137939,-1.81592094898224\" lat= \"52.5487429714954\" lon= \"-1.81602098644987\" display_name= \"135, Pilkington Avenue, Wylde Green, City of Birmingham, West Midlands (county), B72, United Kingdom\" class= \"place\" type= \"house\" > <geokml> <Polygon> <outerBoundaryIs> <LinearRing> <coordinates> -1.816513,52.548756599999997 -1.816434,52.548747300000002 -1.816429,52.5487629 -1.8163717,52.548756099999999 -1.8163464,52.548834599999999 -1.8164599,52.548848100000001 -1.8164685,52.5488213 -1.8164913,52.548824000000003 -1.816513,52.548756599999997 </coordinates> </LinearRing> </outerBoundaryIs> </Polygon> </geokml> <house_number> 135 </house_number> <road> Pilkington Avenue </road> <village> Wylde Green </village> <town> Sutton Coldfield </town> <city> City of Birmingham </city> <county> West Midlands (county) </county> <postcode> B72 </postcode> <country> United Kingdom </country> <country_code> gb </country_code> </place> </searchresults>","title":"XML with kml polygon"},{"location":"api/Search/#json-with-svg-polygon","text":"https://nominatim.openstreetmap.org/search/Unter%20den%20Linden%201%20Berlin?format=json&addressdetails=1&limit=1&polygon_svg=1 { \"address\" : { \"city\" : \"Berlin\" , \"city_district\" : \"Mitte\" , \"construction\" : \"Unter den Linden\" , \"continent\" : \"European Union\" , \"country\" : \"Deutschland\" , \"country_code\" : \"de\" , \"house_number\" : \"1\" , \"neighbourhood\" : \"Scheunenviertel\" , \"postcode\" : \"10117\" , \"public_building\" : \"Kommandantenhaus\" , \"state\" : \"Berlin\" , \"suburb\" : \"Mitte\" }, \"boundingbox\" : [ \"52.5170783996582\" , \"52.5173187255859\" , \"13.3975105285645\" , \"13.3981599807739\" ], \"class\" : \"amenity\" , \"display_name\" : \"Kommandantenhaus, 1, Unter den Linden, Scheunenviertel, Mitte, Berlin, 10117, Deutschland, European Union\" , \"importance\" : 0.73606775332943 , \"lat\" : \"52.51719785\" , \"licence\" : \"Data \\u00a9 OpenStreetMap contributors, ODbL 1.0. https://www.openstreetmap.org/copyright\" , \"lon\" : \"13.3978352028938\" , \"osm_id\" : \"15976890\" , \"osm_type\" : \"way\" , \"place_id\" : \"30848715\" , \"svg\" : \"M 13.397511 -52.517283599999999 L 13.397829400000001 -52.517299800000004 13.398131599999999 -52.517315099999998 13.398159400000001 -52.517112099999999 13.3975388 -52.517080700000001 Z\" , \"type\" : \"public_building\" }","title":"JSON with SVG polygon"},{"location":"api/Search/#json-with-address-details","text":"https://nominatim.openstreetmap.org/?addressdetails=1&q=bakery+in+berlin+wedding&format=json&limit=1 { \"address\" : { \"bakery\" : \"B\\u00e4cker Kamps\" , \"city_district\" : \"Mitte\" , \"continent\" : \"European Union\" , \"country\" : \"Deutschland\" , \"country_code\" : \"de\" , \"footway\" : \"Bahnsteig U6\" , \"neighbourhood\" : \"Sprengelkiez\" , \"postcode\" : \"13353\" , \"state\" : \"Berlin\" , \"suburb\" : \"Wedding\" }, \"boundingbox\" : [ \"52.5460929870605\" , \"52.5460968017578\" , \"13.3591794967651\" , \"13.3591804504395\" ], \"class\" : \"shop\" , \"display_name\" : \"B\\u00e4cker Kamps, Bahnsteig U6, Sprengelkiez, Wedding, Mitte, Berlin, 13353, Deutschland, European Union\" , \"icon\" : \"https://nominatim.openstreetmap.org/images/mapicons/shopping_bakery.p.20.png\" , \"importance\" : 0.201 , \"lat\" : \"52.5460941\" , \"licence\" : \"Data \\u00a9 OpenStreetMap contributors, ODbL 1.0. https://www.openstreetmap.org/copyright\" , \"lon\" : \"13.35918\" , \"osm_id\" : \"317179427\" , \"osm_type\" : \"node\" , \"place_id\" : \"1453068\" , \"type\" : \"bakery\" }","title":"JSON with address details"},{"location":"api/Search/#geojson","text":"https://nominatim.openstreetmap.org/search?q=17+Strada+Pictor+Alexandru+Romano%2C+Bukarest&format=geojson { \"type\" : \"FeatureCollection\" , \"licence\" : \"Data \u00a9 OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\" , \"features\" : [ { \"type\" : \"Feature\" , \"properties\" : { \"place_id\" : \"35811445\" , \"osm_type\" : \"node\" , \"osm_id\" : \"2846295644\" , \"display_name\" : \"17, Strada Pictor Alexandru Romano, Bukarest, Bucharest, Sector 2, Bucharest, 023964, Romania\" , \"place_rank\" : \"30\" , \"category\" : \"place\" , \"type\" : \"house\" , \"importance\" : 0.62025 }, \"bbox\" : [ 26.1156689 , 44.4354754 , 26.1157689 , 44.4355754 ], \"geometry\" : { \"type\" : \"Point\" , \"coordinates\" : [ 26.1157189 , 44.4355254 ] } } ] }","title":"GeoJSON"},{"location":"api/Search/#geocodejson","text":"https://nominatim.openstreetmap.org/search?q=%CE%91%CE%B3%CE%AF%CE%B1+%CE%A4%CF%81%CE%B9%CE%AC%CE%B4%CE%B1%2C+%CE%91%CE%B4%CF%89%CE%BD%CE%B9%CE%B4%CE%BF%CF%82%2C+Athens%2C+Greece&format=geocodejson { \"type\" : \"FeatureCollection\" , \"geocoding\" : { \"version\" : \"0.1.0\" , \"attribution\" : \"Data \u00a9 OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\" , \"licence\" : \"ODbL\" , \"query\" : \"\u0391\u03b3\u03af\u03b1 \u03a4\u03c1\u03b9\u03ac\u03b4\u03b1, \u0391\u03b4\u03c9\u03bd\u03b9\u03b4\u03bf\u03c2, Athens, Greece\" }, \"features\" : [ { \"type\" : \"Feature\" , \"properties\" : { \"geocoding\" : { \"type\" : \"place_of_worship\" , \"label\" : \"\u0391\u03b3\u03af\u03b1 \u03a4\u03c1\u03b9\u03ac\u03b4\u03b1, \u0391\u03b4\u03c9\u03bd\u03b9\u03b4\u03bf\u03c2, \u0386\u03b3\u03b9\u03bf\u03c2 \u039d\u03b9\u03ba\u03cc\u03bb\u03b1\u03bf\u03c2, 5\u00ba \u0394\u03b7\u03bc\u03bf\u03c4\u03b9\u03ba\u03cc \u0394\u03b9\u03b1\u03bc\u03ad\u03c1\u03b9\u03c3\u03bc\u03b1 \u0391\u03b8\u03b7\u03bd\u03ce\u03bd, Athens, Municipality of Athens, Regional Unit of Central Athens, Region of Attica, Attica, 11472, Greece\" , \"name\" : \"\u0391\u03b3\u03af\u03b1 \u03a4\u03c1\u03b9\u03ac\u03b4\u03b1\" , \"admin\" : null } }, \"geometry\" : { \"type\" : \"Point\" , \"coordinates\" : [ 23.72949633941 , 38.0051697 ] } } ] }","title":"GeocodeJSON"},{"location":"api/Status/","text":"Status \uf0c1 Useful for checking if the service and database is running. The JSON output also shows when the database was last updated. Parameters \uf0c1 format=[text|json] (defaults to 'text') Output \uf0c1 Text format \uf0c1 https://nominatim.openstreetmap.org/status.php will return HTTP status code 200 and print OK . On error it will return HTTP status code 500 and print a message, e.g. ERROR: Database connection failed . JSON format \uf0c1 https://nominatim.openstreetmap.org/status.php?format=json will return HTTP code 200 and a structure { \"status\" : 0 , \"message\" : \"OK\" , \"data_updated\" : \"2020-05-04T14:47:00+00:00\" , \"software_version\" : \"3.6.0-0\" , \"database_version\" : \"3.6.0-0\" } The software_version field contains the version of Nominatim used to serve the API. The database_version field contains the version of the data format in the database. On error will also return HTTP status code 200 and a structure with error code and message, e.g. { \"status\" : 700 , \"message\" : \"Database connection failed\" } Possible status codes are message notes 700 \"No database\" connection failed 701 \"Module failed\" database could not load nominatim.so 702 \"Module call failed\" nominatim.so loaded but calling a function failed 703 \"Query failed\" test query against a database table failed 704 \"No value\" test query worked but returned no results","title":"Status"},{"location":"api/Status/#status","text":"Useful for checking if the service and database is running. The JSON output also shows when the database was last updated.","title":"Status"},{"location":"api/Status/#parameters","text":"format=[text|json] (defaults to 'text')","title":"Parameters"},{"location":"api/Status/#output","text":"","title":"Output"},{"location":"api/Status/#text-format","text":"https://nominatim.openstreetmap.org/status.php will return HTTP status code 200 and print OK . On error it will return HTTP status code 500 and print a message, e.g. ERROR: Database connection failed .","title":"Text format"},{"location":"api/Status/#json-format","text":"https://nominatim.openstreetmap.org/status.php?format=json will return HTTP code 200 and a structure { \"status\" : 0 , \"message\" : \"OK\" , \"data_updated\" : \"2020-05-04T14:47:00+00:00\" , \"software_version\" : \"3.6.0-0\" , \"database_version\" : \"3.6.0-0\" } The software_version field contains the version of Nominatim used to serve the API. The database_version field contains the version of the data format in the database. On error will also return HTTP status code 200 and a structure with error code and message, e.g. { \"status\" : 700 , \"message\" : \"Database connection failed\" } Possible status codes are message notes 700 \"No database\" connection failed 701 \"Module failed\" database could not load nominatim.so 702 \"Module call failed\" nominatim.so loaded but calling a function failed 703 \"Query failed\" test query against a database table failed 704 \"No value\" test query worked but returned no results","title":"JSON format"},{"location":"appendix/Install-on-Ubuntu-18/","text":"Note: these installation instructions are also available in executable form for use with vagrant under vagrant/Install-on-Ubuntu-18.sh. Installing the Required Software \uf0c1 These instructions expect that you have a freshly installed Ubuntu 18.04. Make sure all packages are up-to-date by running: sudo apt update -qq Now you can install all packages needed for Nominatim: sudo apt install -y php-cgi sudo apt install -y build-essential cmake g++ libboost-dev libboost-system-dev \\ libboost-filesystem-dev libexpat1-dev zlib1g-dev\\ libbz2-dev libpq-dev \\ postgresql-10-postgis-2.4 \\ postgresql-contrib-10 postgresql-10-postgis-scripts \\ php-cli php-pgsql php-intl libicu-dev python3-pip \\ python3-psutil python3-jinja2 python3-yaml python3-icu Some of the Python packages that come with Ubuntu 18.04 are too old, so install the latest version from pip: pip3 install --user python-dotenv datrie pyyaml psycopg2-binary System Configuration \uf0c1 The following steps are meant to configure a fresh Ubuntu installation for use with Nominatim. You may skip some of the steps if you have your OS already configured. Creating Dedicated User Accounts \uf0c1 Nominatim will run as a global service on your machine. It is therefore best to install it under its own separate user account. In the following we assume this user is called nominatim and the installation will be in /srv/nominatim. To create the user and directory run: sudo useradd -d /srv/nominatim -s /bin/bash -m nominatim You may find a more suitable location if you wish. To be able to copy and paste instructions from this manual, export user name and home directory now like this: export USERNAME = nominatim export USERHOME =/ srv / nominatim Never, ever run the installation as a root user. You have been warned. Make sure that system servers can read from the home directory: chmod a+x $USERHOME Setting up PostgreSQL \uf0c1 Tune the postgresql configuration, which is located in /etc/postgresql/10/main/postgresql.conf . See section Postgres Tuning in the installation page for the parameters to change. Restart the postgresql service after updating this config file. sudo systemctl restart postgresql Finally, we need to add two postgres users: one for the user that does the import and another for the webserver which should access the database for reading only: sudo -u postgres createuser -s $USERNAME sudo -u postgres createuser www-data Installing Nominatim \uf0c1 Building and Configuration \uf0c1 Get the source code from Github and change into the source directory cd $USERHOME wget https://nominatim.org/release/Nominatim-4.1.1.tar.bz2 tar xf Nominatim-4.1.1.tar.bz2 The code must be built in a separate directory. Create this directory, then configure and build Nominatim in there: mkdir $USERHOME/build cd $USERHOME/build cmake $USERHOME/Nominatim-4.1.1 make sudo make install Nominatim is now ready to use. You can continue with importing a database from OSM data . If you want to set up a webserver first, continue reading. Setting up a webserver \uf0c1 The webserver should serve the php scripts from the website directory of your project directory . This directory needs to exist when being configured. Therefore set up a project directory and create the website directory: mkdir $USERHOME/nominatim-project mkdir $USERHOME/nominatim-project/website The import process will populate the directory later. Option 1: Using Apache \uf0c1 Apache has a PHP module that can be used to serve Nominatim. To install them run: sudo apt install -y apache2 libapache2-mod-php You need to create an alias to the website directory in your apache configuration. Add a separate nominatim configuration to your webserver: sudo tee /etc/apache2/conf-available/nominatim.conf << EOFAPACHECONF <Directory \"$USERHOME/nominatim-project/website\"> Options FollowSymLinks MultiViews AddType text/html .php DirectoryIndex search.php Require all granted </Directory> Alias /nominatim $USERHOME/nominatim-project/website EOFAPACHECONF Then enable the configuration with sudo a2enconf nominatim and restart apache: sudo systemctl restart apache2 The Nominatim API is now available at http://localhost/nominatim/ . Option 2: Using nginx \uf0c1 Nginx has no native support for php scripts. You need to set up php-fpm for this purpose. First install nginx and php-fpm: sudo apt install -y nginx php-fpm You need to configure php-fpm to listen on a Unix socket. sudo tee /etc/php/7.2/fpm/pool.d/www.conf << EOF_PHP_FPM_CONF [www] ; Replace the tcp listener and add the unix socket listen = /var/run/php7.2-fpm.sock ; Ensure that the daemon runs as the correct user listen.owner = www-data listen.group = www-data listen.mode = 0666 ; Unix user of FPM processes user = www-data group = www-data ; Choose process manager type (static, dynamic, ondemand) pm = ondemand pm.max_children = 5 EOF_PHP_FPM_CONF Then create a Nginx configuration to forward http requests to that socket. sudo tee /etc/nginx/sites-available/default << EOF_NGINX_CONF server { listen 80 default_server; listen [::]:80 default_server; root $USERHOME/nominatim-project/website; index search.php index.html; location / { try_files \\$uri \\$uri/ @php; } location @php { fastcgi_param SCRIPT_FILENAME \"\\$document_root\\$uri.php\"; fastcgi_param PATH_TRANSLATED \"\\$document_root\\$uri.php\"; fastcgi_param QUERY_STRING \\$args; fastcgi_pass unix:/var/run/php7.2-fpm.sock; fastcgi_index index.php; include fastcgi_params; } location ~ [^/]\\.php(/|$) { fastcgi_split_path_info ^(.+?\\.php)(/.*)$; if (!-f \\$document_root\\$fastcgi_script_name) { return 404; } fastcgi_pass unix:/var/run/php7.2-fpm.sock; fastcgi_index search.php; include fastcgi.conf; } } EOF_NGINX_CONF Enable the configuration and restart Nginx sudo systemctl restart php7.2-fpm nginx The Nominatim API is now available at http://localhost/ .","title":"Installation on Ubuntu 18"},{"location":"appendix/Install-on-Ubuntu-18/#installing-the-required-software","text":"These instructions expect that you have a freshly installed Ubuntu 18.04. Make sure all packages are up-to-date by running: sudo apt update -qq Now you can install all packages needed for Nominatim: sudo apt install -y php-cgi sudo apt install -y build-essential cmake g++ libboost-dev libboost-system-dev \\ libboost-filesystem-dev libexpat1-dev zlib1g-dev\\ libbz2-dev libpq-dev \\ postgresql-10-postgis-2.4 \\ postgresql-contrib-10 postgresql-10-postgis-scripts \\ php-cli php-pgsql php-intl libicu-dev python3-pip \\ python3-psutil python3-jinja2 python3-yaml python3-icu Some of the Python packages that come with Ubuntu 18.04 are too old, so install the latest version from pip: pip3 install --user python-dotenv datrie pyyaml psycopg2-binary","title":"Installing the Required Software"},{"location":"appendix/Install-on-Ubuntu-18/#system-configuration","text":"The following steps are meant to configure a fresh Ubuntu installation for use with Nominatim. You may skip some of the steps if you have your OS already configured.","title":"System Configuration"},{"location":"appendix/Install-on-Ubuntu-18/#creating-dedicated-user-accounts","text":"Nominatim will run as a global service on your machine. It is therefore best to install it under its own separate user account. In the following we assume this user is called nominatim and the installation will be in /srv/nominatim. To create the user and directory run: sudo useradd -d /srv/nominatim -s /bin/bash -m nominatim You may find a more suitable location if you wish. To be able to copy and paste instructions from this manual, export user name and home directory now like this: export USERNAME = nominatim export USERHOME =/ srv / nominatim Never, ever run the installation as a root user. You have been warned. Make sure that system servers can read from the home directory: chmod a+x $USERHOME","title":"Creating Dedicated User Accounts"},{"location":"appendix/Install-on-Ubuntu-18/#setting-up-postgresql","text":"Tune the postgresql configuration, which is located in /etc/postgresql/10/main/postgresql.conf . See section Postgres Tuning in the installation page for the parameters to change. Restart the postgresql service after updating this config file. sudo systemctl restart postgresql Finally, we need to add two postgres users: one for the user that does the import and another for the webserver which should access the database for reading only: sudo -u postgres createuser -s $USERNAME sudo -u postgres createuser www-data","title":"Setting up PostgreSQL"},{"location":"appendix/Install-on-Ubuntu-18/#installing-nominatim","text":"","title":"Installing Nominatim"},{"location":"appendix/Install-on-Ubuntu-18/#building-and-configuration","text":"Get the source code from Github and change into the source directory cd $USERHOME wget https://nominatim.org/release/Nominatim-4.1.1.tar.bz2 tar xf Nominatim-4.1.1.tar.bz2 The code must be built in a separate directory. Create this directory, then configure and build Nominatim in there: mkdir $USERHOME/build cd $USERHOME/build cmake $USERHOME/Nominatim-4.1.1 make sudo make install Nominatim is now ready to use. You can continue with importing a database from OSM data . If you want to set up a webserver first, continue reading.","title":"Building and Configuration"},{"location":"appendix/Install-on-Ubuntu-18/#setting-up-a-webserver","text":"The webserver should serve the php scripts from the website directory of your project directory . This directory needs to exist when being configured. Therefore set up a project directory and create the website directory: mkdir $USERHOME/nominatim-project mkdir $USERHOME/nominatim-project/website The import process will populate the directory later.","title":"Setting up a webserver"},{"location":"appendix/Install-on-Ubuntu-18/#option-1-using-apache","text":"Apache has a PHP module that can be used to serve Nominatim. To install them run: sudo apt install -y apache2 libapache2-mod-php You need to create an alias to the website directory in your apache configuration. Add a separate nominatim configuration to your webserver: sudo tee /etc/apache2/conf-available/nominatim.conf << EOFAPACHECONF <Directory \"$USERHOME/nominatim-project/website\"> Options FollowSymLinks MultiViews AddType text/html .php DirectoryIndex search.php Require all granted </Directory> Alias /nominatim $USERHOME/nominatim-project/website EOFAPACHECONF Then enable the configuration with sudo a2enconf nominatim and restart apache: sudo systemctl restart apache2 The Nominatim API is now available at http://localhost/nominatim/ .","title":"Option 1: Using Apache"},{"location":"appendix/Install-on-Ubuntu-18/#option-2-using-nginx","text":"Nginx has no native support for php scripts. You need to set up php-fpm for this purpose. First install nginx and php-fpm: sudo apt install -y nginx php-fpm You need to configure php-fpm to listen on a Unix socket. sudo tee /etc/php/7.2/fpm/pool.d/www.conf << EOF_PHP_FPM_CONF [www] ; Replace the tcp listener and add the unix socket listen = /var/run/php7.2-fpm.sock ; Ensure that the daemon runs as the correct user listen.owner = www-data listen.group = www-data listen.mode = 0666 ; Unix user of FPM processes user = www-data group = www-data ; Choose process manager type (static, dynamic, ondemand) pm = ondemand pm.max_children = 5 EOF_PHP_FPM_CONF Then create a Nginx configuration to forward http requests to that socket. sudo tee /etc/nginx/sites-available/default << EOF_NGINX_CONF server { listen 80 default_server; listen [::]:80 default_server; root $USERHOME/nominatim-project/website; index search.php index.html; location / { try_files \\$uri \\$uri/ @php; } location @php { fastcgi_param SCRIPT_FILENAME \"\\$document_root\\$uri.php\"; fastcgi_param PATH_TRANSLATED \"\\$document_root\\$uri.php\"; fastcgi_param QUERY_STRING \\$args; fastcgi_pass unix:/var/run/php7.2-fpm.sock; fastcgi_index index.php; include fastcgi_params; } location ~ [^/]\\.php(/|$) { fastcgi_split_path_info ^(.+?\\.php)(/.*)$; if (!-f \\$document_root\\$fastcgi_script_name) { return 404; } fastcgi_pass unix:/var/run/php7.2-fpm.sock; fastcgi_index search.php; include fastcgi.conf; } } EOF_NGINX_CONF Enable the configuration and restart Nginx sudo systemctl restart php7.2-fpm nginx The Nominatim API is now available at http://localhost/ .","title":"Option 2: Using nginx"},{"location":"appendix/Install-on-Ubuntu-20/","text":"Note: these installation instructions are also available in executable form for use with vagrant under vagrant/Install-on-Ubuntu-20.sh. Installing the Required Software \uf0c1 These instructions expect that you have a freshly installed Ubuntu 20.04. Make sure all packages are up-to-date by running: sudo apt update -qq Now you can install all packages needed for Nominatim: sudo apt install -y php-cgi sudo apt install -y build-essential cmake g++ libboost-dev libboost-system-dev \\ libboost-filesystem-dev libexpat1-dev zlib1g-dev \\ libbz2-dev libpq-dev \\ postgresql-12-postgis-3 \\ postgresql-contrib-12 postgresql-12-postgis-3-scripts \\ php-cli php-pgsql php-intl libicu-dev python3-dotenv \\ python3-psycopg2 python3-psutil python3-jinja2 \\ python3-icu python3-datrie python3-yaml System Configuration \uf0c1 The following steps are meant to configure a fresh Ubuntu installation for use with Nominatim. You may skip some of the steps if you have your OS already configured. Creating Dedicated User Accounts \uf0c1 Nominatim will run as a global service on your machine. It is therefore best to install it under its own separate user account. In the following we assume this user is called nominatim and the installation will be in /srv/nominatim. To create the user and directory run: sudo useradd -d /srv/nominatim -s /bin/bash -m nominatim You may find a more suitable location if you wish. To be able to copy and paste instructions from this manual, export user name and home directory now like this: export USERNAME = nominatim export USERHOME =/ srv / nominatim Never, ever run the installation as a root user. You have been warned. Make sure that system servers can read from the home directory: chmod a+x $USERHOME Setting up PostgreSQL \uf0c1 Tune the postgresql configuration, which is located in /etc/postgresql/12/main/postgresql.conf . See section Postgres Tuning in the installation page for the parameters to change. Restart the postgresql service after updating this config file. sudo systemctl restart postgresql Finally, we need to add two postgres users: one for the user that does the import and another for the webserver which should access the database for reading only: sudo -u postgres createuser -s $USERNAME sudo -u postgres createuser www-data Installing Nominatim \uf0c1 Building and Configuration \uf0c1 Get the source code from Github and change into the source directory cd $USERHOME wget https://nominatim.org/release/Nominatim-4.1.1.tar.bz2 tar xf Nominatim-4.1.1.tar.bz2 The code must be built in a separate directory. Create this directory, then configure and build Nominatim in there: mkdir $USERHOME/build cd $USERHOME/build cmake $USERHOME/Nominatim-4.1.1 make sudo make install Nominatim is now ready to use. You can continue with importing a database from OSM data . If you want to set up a webserver first, continue reading. Setting up a webserver \uf0c1 The webserver should serve the php scripts from the website directory of your project directory . This directory needs to exist when being configured. Therefore set up a project directory and create a website directory: mkdir $USERHOME/nominatim-project mkdir $USERHOME/nominatim-project/website The import process will populate the directory later. Option 1: Using Apache \uf0c1 Apache has a PHP module that can be used to serve Nominatim. To install them run: sudo apt install -y apache2 libapache2-mod-php You need to create an alias to the website directory in your apache configuration. Add a separate nominatim configuration to your webserver: sudo tee /etc/apache2/conf-available/nominatim.conf << EOFAPACHECONF <Directory \"$USERHOME/nominatim-project/website\"> Options FollowSymLinks MultiViews AddType text/html .php DirectoryIndex search.php Require all granted </Directory> Alias /nominatim $USERHOME/nominatim-project/website EOFAPACHECONF Then enable the configuration and restart apache sudo a2enconf nominatim sudo systemctl restart apache2 The Nominatim API is now available at http://localhost/nominatim/ . Option 2: Using nginx \uf0c1 Nginx has no native support for php scripts. You need to set up php-fpm for this purpose. First install nginx and php-fpm: sudo apt install -y nginx php-fpm You need to configure php-fpm to listen on a Unix socket. sudo tee /etc/php/7.4/fpm/pool.d/www.conf << EOF_PHP_FPM_CONF [www] ; Replace the tcp listener and add the unix socket listen = /var/run/php7.4-fpm.sock ; Ensure that the daemon runs as the correct user listen.owner = www-data listen.group = www-data listen.mode = 0666 ; Unix user of FPM processes user = www-data group = www-data ; Choose process manager type (static, dynamic, ondemand) pm = ondemand pm.max_children = 5 EOF_PHP_FPM_CONF Then create a Nginx configuration to forward http requests to that socket. sudo tee /etc/nginx/sites-available/default << EOF_NGINX_CONF server { listen 80 default_server; listen [::]:80 default_server; root $USERHOME/nominatim-project/website; index search.php index.html; location / { try_files \\$uri \\$uri/ @php; } location @php { fastcgi_param SCRIPT_FILENAME \"\\$document_root\\$uri.php\"; fastcgi_param PATH_TRANSLATED \"\\$document_root\\$uri.php\"; fastcgi_param QUERY_STRING \\$args; fastcgi_pass unix:/var/run/php7.4-fpm.sock; fastcgi_index index.php; include fastcgi_params; } location ~ [^/]\\.php(/|$) { fastcgi_split_path_info ^(.+?\\.php)(/.*)$; if (!-f \\$document_root\\$fastcgi_script_name) { return 404; } fastcgi_pass unix:/var/run/php7.4-fpm.sock; fastcgi_index search.php; include fastcgi.conf; } } EOF_NGINX_CONF If you have some errors, make sure that php7.4-fpm.sock is well under /var/run/ and not under /var/run/php. Otherwise change the Nginx configuration to /var/run/php/php7.4-fpm.sock. Enable the configuration and restart Nginx sudo systemctl restart php7.4-fpm nginx The Nominatim API is now available at http://localhost/ .","title":"Installation on Ubuntu 20"},{"location":"appendix/Install-on-Ubuntu-20/#installing-the-required-software","text":"These instructions expect that you have a freshly installed Ubuntu 20.04. Make sure all packages are up-to-date by running: sudo apt update -qq Now you can install all packages needed for Nominatim: sudo apt install -y php-cgi sudo apt install -y build-essential cmake g++ libboost-dev libboost-system-dev \\ libboost-filesystem-dev libexpat1-dev zlib1g-dev \\ libbz2-dev libpq-dev \\ postgresql-12-postgis-3 \\ postgresql-contrib-12 postgresql-12-postgis-3-scripts \\ php-cli php-pgsql php-intl libicu-dev python3-dotenv \\ python3-psycopg2 python3-psutil python3-jinja2 \\ python3-icu python3-datrie python3-yaml","title":"Installing the Required Software"},{"location":"appendix/Install-on-Ubuntu-20/#system-configuration","text":"The following steps are meant to configure a fresh Ubuntu installation for use with Nominatim. You may skip some of the steps if you have your OS already configured.","title":"System Configuration"},{"location":"appendix/Install-on-Ubuntu-20/#creating-dedicated-user-accounts","text":"Nominatim will run as a global service on your machine. It is therefore best to install it under its own separate user account. In the following we assume this user is called nominatim and the installation will be in /srv/nominatim. To create the user and directory run: sudo useradd -d /srv/nominatim -s /bin/bash -m nominatim You may find a more suitable location if you wish. To be able to copy and paste instructions from this manual, export user name and home directory now like this: export USERNAME = nominatim export USERHOME =/ srv / nominatim Never, ever run the installation as a root user. You have been warned. Make sure that system servers can read from the home directory: chmod a+x $USERHOME","title":"Creating Dedicated User Accounts"},{"location":"appendix/Install-on-Ubuntu-20/#setting-up-postgresql","text":"Tune the postgresql configuration, which is located in /etc/postgresql/12/main/postgresql.conf . See section Postgres Tuning in the installation page for the parameters to change. Restart the postgresql service after updating this config file. sudo systemctl restart postgresql Finally, we need to add two postgres users: one for the user that does the import and another for the webserver which should access the database for reading only: sudo -u postgres createuser -s $USERNAME sudo -u postgres createuser www-data","title":"Setting up PostgreSQL"},{"location":"appendix/Install-on-Ubuntu-20/#installing-nominatim","text":"","title":"Installing Nominatim"},{"location":"appendix/Install-on-Ubuntu-20/#building-and-configuration","text":"Get the source code from Github and change into the source directory cd $USERHOME wget https://nominatim.org/release/Nominatim-4.1.1.tar.bz2 tar xf Nominatim-4.1.1.tar.bz2 The code must be built in a separate directory. Create this directory, then configure and build Nominatim in there: mkdir $USERHOME/build cd $USERHOME/build cmake $USERHOME/Nominatim-4.1.1 make sudo make install Nominatim is now ready to use. You can continue with importing a database from OSM data . If you want to set up a webserver first, continue reading.","title":"Building and Configuration"},{"location":"appendix/Install-on-Ubuntu-20/#setting-up-a-webserver","text":"The webserver should serve the php scripts from the website directory of your project directory . This directory needs to exist when being configured. Therefore set up a project directory and create a website directory: mkdir $USERHOME/nominatim-project mkdir $USERHOME/nominatim-project/website The import process will populate the directory later.","title":"Setting up a webserver"},{"location":"appendix/Install-on-Ubuntu-20/#option-1-using-apache","text":"Apache has a PHP module that can be used to serve Nominatim. To install them run: sudo apt install -y apache2 libapache2-mod-php You need to create an alias to the website directory in your apache configuration. Add a separate nominatim configuration to your webserver: sudo tee /etc/apache2/conf-available/nominatim.conf << EOFAPACHECONF <Directory \"$USERHOME/nominatim-project/website\"> Options FollowSymLinks MultiViews AddType text/html .php DirectoryIndex search.php Require all granted </Directory> Alias /nominatim $USERHOME/nominatim-project/website EOFAPACHECONF Then enable the configuration and restart apache sudo a2enconf nominatim sudo systemctl restart apache2 The Nominatim API is now available at http://localhost/nominatim/ .","title":"Option 1: Using Apache"},{"location":"appendix/Install-on-Ubuntu-20/#option-2-using-nginx","text":"Nginx has no native support for php scripts. You need to set up php-fpm for this purpose. First install nginx and php-fpm: sudo apt install -y nginx php-fpm You need to configure php-fpm to listen on a Unix socket. sudo tee /etc/php/7.4/fpm/pool.d/www.conf << EOF_PHP_FPM_CONF [www] ; Replace the tcp listener and add the unix socket listen = /var/run/php7.4-fpm.sock ; Ensure that the daemon runs as the correct user listen.owner = www-data listen.group = www-data listen.mode = 0666 ; Unix user of FPM processes user = www-data group = www-data ; Choose process manager type (static, dynamic, ondemand) pm = ondemand pm.max_children = 5 EOF_PHP_FPM_CONF Then create a Nginx configuration to forward http requests to that socket. sudo tee /etc/nginx/sites-available/default << EOF_NGINX_CONF server { listen 80 default_server; listen [::]:80 default_server; root $USERHOME/nominatim-project/website; index search.php index.html; location / { try_files \\$uri \\$uri/ @php; } location @php { fastcgi_param SCRIPT_FILENAME \"\\$document_root\\$uri.php\"; fastcgi_param PATH_TRANSLATED \"\\$document_root\\$uri.php\"; fastcgi_param QUERY_STRING \\$args; fastcgi_pass unix:/var/run/php7.4-fpm.sock; fastcgi_index index.php; include fastcgi_params; } location ~ [^/]\\.php(/|$) { fastcgi_split_path_info ^(.+?\\.php)(/.*)$; if (!-f \\$document_root\\$fastcgi_script_name) { return 404; } fastcgi_pass unix:/var/run/php7.4-fpm.sock; fastcgi_index search.php; include fastcgi.conf; } } EOF_NGINX_CONF If you have some errors, make sure that php7.4-fpm.sock is well under /var/run/ and not under /var/run/php. Otherwise change the Nginx configuration to /var/run/php/php7.4-fpm.sock. Enable the configuration and restart Nginx sudo systemctl restart php7.4-fpm nginx The Nominatim API is now available at http://localhost/ .","title":"Option 2: Using nginx"},{"location":"appendix/Install-on-Ubuntu-22/","text":"Note: these installation instructions are also available in executable form for use with vagrant under vagrant/Install-on-Ubuntu-22.sh. Installing the Required Software \uf0c1 These instructions expect that you have a freshly installed Ubuntu 22.04. Make sure all packages are up-to-date by running: sudo apt update -qq Now you can install all packages needed for Nominatim: sudo apt install -y php-cgi sudo apt install -y build-essential cmake g++ libboost-dev libboost-system-dev \\ libboost-filesystem-dev libexpat1-dev zlib1g-dev \\ libbz2-dev libpq-dev \\ postgresql-server-dev-14 postgresql-14-postgis-3 \\ postgresql-contrib-14 postgresql-14-postgis-3-scripts \\ php-cli php-pgsql php-intl libicu-dev python3-dotenv \\ python3-psycopg2 python3-psutil python3-jinja2 \\ python3-icu python3-datrie System Configuration \uf0c1 The following steps are meant to configure a fresh Ubuntu installation for use with Nominatim. You may skip some of the steps if you have your OS already configured. Creating Dedicated User Accounts \uf0c1 Nominatim will run as a global service on your machine. It is therefore best to install it under its own separate user account. In the following we assume this user is called nominatim and the installation will be in /srv/nominatim. To create the user and directory run: sudo useradd -d /srv/nominatim -s /bin/bash -m nominatim You may find a more suitable location if you wish. To be able to copy and paste instructions from this manual, export user name and home directory now like this: export USERNAME = nominatim export USERHOME =/ srv / nominatim Never, ever run the installation as a root user. You have been warned. Make sure that system servers can read from the home directory: chmod a+x $USERHOME Setting up PostgreSQL \uf0c1 Tune the postgresql configuration, which is located in /etc/postgresql/14/main/postgresql.conf . See section Postgres Tuning in the installation page for the parameters to change. Restart the postgresql service after updating this config file. sudo systemctl restart postgresql Finally, we need to add two postgres users: one for the user that does the import and another for the webserver which should access the database for reading only: sudo -u postgres createuser -s $USERNAME sudo -u postgres createuser www-data Installing Nominatim \uf0c1 Building and Configuration \uf0c1 Get the source code from Github and change into the source directory cd $USERHOME wget https://nominatim.org/release/Nominatim-4.1.1.tar.bz2 tar xf Nominatim-4.1.1.tar.bz2 The code must be built in a separate directory. Create this directory, then configure and build Nominatim in there: mkdir $USERHOME/build cd $USERHOME/build cmake $USERHOME/Nominatim-4.1.1 make sudo make install Nominatim is now ready to use. You can continue with importing a database from OSM data . If you want to set up a webserver first, continue reading. Setting up a webserver \uf0c1 The webserver should serve the php scripts from the website directory of your project directory . This directory needs to exist when being configured. Therefore set up a project directory and create a website directory: mkdir $USERHOME/nominatim-project mkdir $USERHOME/nominatim-project/website The import process will populate the directory later. Option 1: Using Apache \uf0c1 Apache has a PHP module that can be used to serve Nominatim. To install them run: sudo apt install -y apache2 libapache2-mod-php You need to create an alias to the website directory in your apache configuration. Add a separate nominatim configuration to your webserver: sudo tee /etc/apache2/conf-available/nominatim.conf << EOFAPACHECONF <Directory \"$USERHOME/nominatim-project/website\"> Options FollowSymLinks MultiViews AddType text/html .php DirectoryIndex search.php Require all granted </Directory> Alias /nominatim $USERHOME/nominatim-project/website EOFAPACHECONF Then enable the configuration and restart apache sudo a2enconf nominatim sudo systemctl restart apache2 The Nominatim API is now available at http://localhost/nominatim/ . Option 2: Using nginx \uf0c1 Nginx has no native support for php scripts. You need to set up php-fpm for this purpose. First install nginx and php-fpm: sudo apt install -y nginx php-fpm You need to configure php-fpm to listen on a Unix socket. sudo tee /etc/php/8.1/fpm/pool.d/www.conf << EOF_PHP_FPM_CONF [www] ; Replace the tcp listener and add the unix socket listen = /var/run/php8.1-fpm.sock ; Ensure that the daemon runs as the correct user listen.owner = www-data listen.group = www-data listen.mode = 0666 ; Unix user of FPM processes user = www-data group = www-data ; Choose process manager type (static, dynamic, ondemand) pm = ondemand pm.max_children = 5 EOF_PHP_FPM_CONF Then create a Nginx configuration to forward http requests to that socket. sudo tee /etc/nginx/sites-available/default << EOF_NGINX_CONF server { listen 80 default_server; listen [::]:80 default_server; root $USERHOME/nominatim-project/website; index search.php index.html; location / { try_files \\$uri \\$uri/ @php; } location @php { fastcgi_param SCRIPT_FILENAME \"\\$document_root\\$uri.php\"; fastcgi_param PATH_TRANSLATED \"\\$document_root\\$uri.php\"; fastcgi_param QUERY_STRING \\$args; fastcgi_pass unix:/var/run/php8.1-fpm.sock; fastcgi_index index.php; include fastcgi_params; } location ~ [^/]\\.php(/|$) { fastcgi_split_path_info ^(.+?\\.php)(/.*)$; if (!-f \\$document_root\\$fastcgi_script_name) { return 404; } fastcgi_pass unix:/var/run/php7.4-fpm.sock; fastcgi_index search.php; include fastcgi.conf; } } EOF_NGINX_CONF If you have some errors, make sure that php8.1-fpm.sock is well under /var/run/ and not under /var/run/php. Otherwise change the Nginx configuration to /var/run/php/php8.1-fpm.sock. Enable the configuration and restart Nginx sudo systemctl restart php8.1-fpm nginx The Nominatim API is now available at http://localhost/ .","title":"Installation on Ubuntu 22"},{"location":"appendix/Install-on-Ubuntu-22/#installing-the-required-software","text":"These instructions expect that you have a freshly installed Ubuntu 22.04. Make sure all packages are up-to-date by running: sudo apt update -qq Now you can install all packages needed for Nominatim: sudo apt install -y php-cgi sudo apt install -y build-essential cmake g++ libboost-dev libboost-system-dev \\ libboost-filesystem-dev libexpat1-dev zlib1g-dev \\ libbz2-dev libpq-dev \\ postgresql-server-dev-14 postgresql-14-postgis-3 \\ postgresql-contrib-14 postgresql-14-postgis-3-scripts \\ php-cli php-pgsql php-intl libicu-dev python3-dotenv \\ python3-psycopg2 python3-psutil python3-jinja2 \\ python3-icu python3-datrie","title":"Installing the Required Software"},{"location":"appendix/Install-on-Ubuntu-22/#system-configuration","text":"The following steps are meant to configure a fresh Ubuntu installation for use with Nominatim. You may skip some of the steps if you have your OS already configured.","title":"System Configuration"},{"location":"appendix/Install-on-Ubuntu-22/#creating-dedicated-user-accounts","text":"Nominatim will run as a global service on your machine. It is therefore best to install it under its own separate user account. In the following we assume this user is called nominatim and the installation will be in /srv/nominatim. To create the user and directory run: sudo useradd -d /srv/nominatim -s /bin/bash -m nominatim You may find a more suitable location if you wish. To be able to copy and paste instructions from this manual, export user name and home directory now like this: export USERNAME = nominatim export USERHOME =/ srv / nominatim Never, ever run the installation as a root user. You have been warned. Make sure that system servers can read from the home directory: chmod a+x $USERHOME","title":"Creating Dedicated User Accounts"},{"location":"appendix/Install-on-Ubuntu-22/#setting-up-postgresql","text":"Tune the postgresql configuration, which is located in /etc/postgresql/14/main/postgresql.conf . See section Postgres Tuning in the installation page for the parameters to change. Restart the postgresql service after updating this config file. sudo systemctl restart postgresql Finally, we need to add two postgres users: one for the user that does the import and another for the webserver which should access the database for reading only: sudo -u postgres createuser -s $USERNAME sudo -u postgres createuser www-data","title":"Setting up PostgreSQL"},{"location":"appendix/Install-on-Ubuntu-22/#installing-nominatim","text":"","title":"Installing Nominatim"},{"location":"appendix/Install-on-Ubuntu-22/#building-and-configuration","text":"Get the source code from Github and change into the source directory cd $USERHOME wget https://nominatim.org/release/Nominatim-4.1.1.tar.bz2 tar xf Nominatim-4.1.1.tar.bz2 The code must be built in a separate directory. Create this directory, then configure and build Nominatim in there: mkdir $USERHOME/build cd $USERHOME/build cmake $USERHOME/Nominatim-4.1.1 make sudo make install Nominatim is now ready to use. You can continue with importing a database from OSM data . If you want to set up a webserver first, continue reading.","title":"Building and Configuration"},{"location":"appendix/Install-on-Ubuntu-22/#setting-up-a-webserver","text":"The webserver should serve the php scripts from the website directory of your project directory . This directory needs to exist when being configured. Therefore set up a project directory and create a website directory: mkdir $USERHOME/nominatim-project mkdir $USERHOME/nominatim-project/website The import process will populate the directory later.","title":"Setting up a webserver"},{"location":"appendix/Install-on-Ubuntu-22/#option-1-using-apache","text":"Apache has a PHP module that can be used to serve Nominatim. To install them run: sudo apt install -y apache2 libapache2-mod-php You need to create an alias to the website directory in your apache configuration. Add a separate nominatim configuration to your webserver: sudo tee /etc/apache2/conf-available/nominatim.conf << EOFAPACHECONF <Directory \"$USERHOME/nominatim-project/website\"> Options FollowSymLinks MultiViews AddType text/html .php DirectoryIndex search.php Require all granted </Directory> Alias /nominatim $USERHOME/nominatim-project/website EOFAPACHECONF Then enable the configuration and restart apache sudo a2enconf nominatim sudo systemctl restart apache2 The Nominatim API is now available at http://localhost/nominatim/ .","title":"Option 1: Using Apache"},{"location":"appendix/Install-on-Ubuntu-22/#option-2-using-nginx","text":"Nginx has no native support for php scripts. You need to set up php-fpm for this purpose. First install nginx and php-fpm: sudo apt install -y nginx php-fpm You need to configure php-fpm to listen on a Unix socket. sudo tee /etc/php/8.1/fpm/pool.d/www.conf << EOF_PHP_FPM_CONF [www] ; Replace the tcp listener and add the unix socket listen = /var/run/php8.1-fpm.sock ; Ensure that the daemon runs as the correct user listen.owner = www-data listen.group = www-data listen.mode = 0666 ; Unix user of FPM processes user = www-data group = www-data ; Choose process manager type (static, dynamic, ondemand) pm = ondemand pm.max_children = 5 EOF_PHP_FPM_CONF Then create a Nginx configuration to forward http requests to that socket. sudo tee /etc/nginx/sites-available/default << EOF_NGINX_CONF server { listen 80 default_server; listen [::]:80 default_server; root $USERHOME/nominatim-project/website; index search.php index.html; location / { try_files \\$uri \\$uri/ @php; } location @php { fastcgi_param SCRIPT_FILENAME \"\\$document_root\\$uri.php\"; fastcgi_param PATH_TRANSLATED \"\\$document_root\\$uri.php\"; fastcgi_param QUERY_STRING \\$args; fastcgi_pass unix:/var/run/php8.1-fpm.sock; fastcgi_index index.php; include fastcgi_params; } location ~ [^/]\\.php(/|$) { fastcgi_split_path_info ^(.+?\\.php)(/.*)$; if (!-f \\$document_root\\$fastcgi_script_name) { return 404; } fastcgi_pass unix:/var/run/php7.4-fpm.sock; fastcgi_index search.php; include fastcgi.conf; } } EOF_NGINX_CONF If you have some errors, make sure that php8.1-fpm.sock is well under /var/run/ and not under /var/run/php. Otherwise change the Nginx configuration to /var/run/php/php8.1-fpm.sock. Enable the configuration and restart Nginx sudo systemctl restart php8.1-fpm nginx The Nominatim API is now available at http://localhost/ .","title":"Option 2: Using nginx"},{"location":"customize/Country-Settings/","text":"Customizing Per-Country Data \uf0c1 Whenever an OSM is imported into Nominatim, the object is first assigned a country. Nominatim can use this information to adapt various aspects of the address computation to the local customs of the country. This section explains how country assignment works and the principal per-country localizations. Country assignment \uf0c1 Countries are assigned on the basis of country data from the OpenStreetMap input data itself. Countries are expected to be tagged according to the administrative boundary schema : a OSM relation with boundary=administrative and admin_level=2 . Nominatim uses the country code to distinguish the countries. If there is no country data available for a point, then Nominatim uses the fallback data imported from data/country_osm_grid.sql.gz . This was computed from OSM data as well but is guaranteed to cover all countries. Some OSM objects may also be located outside any country, for example a buoy in the middle of the ocean. These object do not get any country assigned and get a default treatment when it comes to localized handling of data. Per-country settings \uf0c1 Global country settings \uf0c1 The main place to configure settings per country is the file settings/country_settings.yaml . This file has one section per country that is recognised by Nominatim. Each section is tagged with the country code (in lower case) and contains the different localization information. Only countries which are listed in this file are taken into account for computations. For example, the section for Andorra looks like this: partition: 35 languages: ca names: !include country-names/ad.yaml postcode: pattern: \"(ddd)\" output: AD\\1 The individual settings are described below. partition \uf0c1 Nominatim internally splits the data into multiple tables to improve performance. The partition number tells Nominatim into which table to put the country. This is purely internal management and has no effect on the output data. The default is to have one partition per country. languages \uf0c1 A comma-separated list of ISO-639 language codes of default languages in the country. These are the languages used in name tags without a language suffix. Note that this is not necessarily the same as the list of official languages in the country. There may be officially recognised languages in a country which are only ever used in name tags with the appropriate language suffixes. Conversely, a non-official language may appear a lot in the name tags, for example when used as an unofficial Lingua Franca. List the languages in order of frequency of appearance with the most frequently used language first. It is not recommended to add languages when there are only very few occurrences. If only one language is listed, then Nominatim will 'auto-complete' the language of names without an explicit language-suffix. names \uf0c1 List of names of the country and its translations. These names are used as a baseline. It is always possible to search countries by the given names, no matter what other names are in the OSM data. They are also used as a fallback when a needed translation is not available. Note The list of names per country is currently fairly large because Nominatim supports translations in many languages per default. That is why the name lists have been separated out into extra files. You can find the name lists in the file settings/country-names/<country code>.yaml . The names section in the main country settings file only refers to these files via the special !include directive. postcode \uf0c1 Describes the format of the postcode that is in use in the country. When a country has no official postcodes, set this to no. Example: ae : postcode : no When a country has a postcode, you need to state the postcode pattern and the default output format. Example: bm : postcode : pattern : \"(ll)[ -]?(dd)\" output : \\ 1 \\ 2 The pattern is a regular expression that describes the possible formats accepted as a postcode. The pattern follows the standard syntax for regular expressions in Python with two extra shortcuts: d is a shortcut for a single digit([0-9]) and l for a single ASCII letter ([A-Z]). Use match groups to indicate groups in the postcode that may optionally be separated with a space or a hyphen. For example, the postcode for Bermuda above always consists of two letters and two digits. They may optionally be separated by a space or hyphen. That means that Nominatim will consider AB56 , AB 56 and AB-56 spelling variants for one and the same postcode. Never add the country code in front of the postcode pattern. Nominatim will automatically accept variants with a country code prefix for all postcodes. The output field is an optional field that describes what the canonical spelling of the postcode should be. The format is the regular expression expand syntax referring back to the bracket groups in the pattern. Most simple postcodes only have one spelling variant. In that case, the output can be omitted. The postcode will simply be used as is. In the Bermuda example above, the canonical spelling would be to have a space between letters and digits. Warning When your postcode pattern covers multiple variants of the postcode, then you must explicitly state the canonical output or Nominatim will not handle the variations correctly. Other country-specific configuration \uf0c1 There are some other configuration files where you can set localized settings according to the assigned country. These are: Place ranking configuration Please see the linked documentation sections for more information.","title":"Per-Country Data"},{"location":"customize/Country-Settings/#customizing-per-country-data","text":"Whenever an OSM is imported into Nominatim, the object is first assigned a country. Nominatim can use this information to adapt various aspects of the address computation to the local customs of the country. This section explains how country assignment works and the principal per-country localizations.","title":"Customizing Per-Country Data"},{"location":"customize/Country-Settings/#country-assignment","text":"Countries are assigned on the basis of country data from the OpenStreetMap input data itself. Countries are expected to be tagged according to the administrative boundary schema : a OSM relation with boundary=administrative and admin_level=2 . Nominatim uses the country code to distinguish the countries. If there is no country data available for a point, then Nominatim uses the fallback data imported from data/country_osm_grid.sql.gz . This was computed from OSM data as well but is guaranteed to cover all countries. Some OSM objects may also be located outside any country, for example a buoy in the middle of the ocean. These object do not get any country assigned and get a default treatment when it comes to localized handling of data.","title":"Country assignment"},{"location":"customize/Country-Settings/#per-country-settings","text":"","title":"Per-country settings"},{"location":"customize/Country-Settings/#global-country-settings","text":"The main place to configure settings per country is the file settings/country_settings.yaml . This file has one section per country that is recognised by Nominatim. Each section is tagged with the country code (in lower case) and contains the different localization information. Only countries which are listed in this file are taken into account for computations. For example, the section for Andorra looks like this: partition: 35 languages: ca names: !include country-names/ad.yaml postcode: pattern: \"(ddd)\" output: AD\\1 The individual settings are described below.","title":"Global country settings"},{"location":"customize/Country-Settings/#partition","text":"Nominatim internally splits the data into multiple tables to improve performance. The partition number tells Nominatim into which table to put the country. This is purely internal management and has no effect on the output data. The default is to have one partition per country.","title":"partition"},{"location":"customize/Country-Settings/#languages","text":"A comma-separated list of ISO-639 language codes of default languages in the country. These are the languages used in name tags without a language suffix. Note that this is not necessarily the same as the list of official languages in the country. There may be officially recognised languages in a country which are only ever used in name tags with the appropriate language suffixes. Conversely, a non-official language may appear a lot in the name tags, for example when used as an unofficial Lingua Franca. List the languages in order of frequency of appearance with the most frequently used language first. It is not recommended to add languages when there are only very few occurrences. If only one language is listed, then Nominatim will 'auto-complete' the language of names without an explicit language-suffix.","title":"languages"},{"location":"customize/Country-Settings/#names","text":"List of names of the country and its translations. These names are used as a baseline. It is always possible to search countries by the given names, no matter what other names are in the OSM data. They are also used as a fallback when a needed translation is not available. Note The list of names per country is currently fairly large because Nominatim supports translations in many languages per default. That is why the name lists have been separated out into extra files. You can find the name lists in the file settings/country-names/<country code>.yaml . The names section in the main country settings file only refers to these files via the special !include directive.","title":"names"},{"location":"customize/Country-Settings/#postcode","text":"Describes the format of the postcode that is in use in the country. When a country has no official postcodes, set this to no. Example: ae : postcode : no When a country has a postcode, you need to state the postcode pattern and the default output format. Example: bm : postcode : pattern : \"(ll)[ -]?(dd)\" output : \\ 1 \\ 2 The pattern is a regular expression that describes the possible formats accepted as a postcode. The pattern follows the standard syntax for regular expressions in Python with two extra shortcuts: d is a shortcut for a single digit([0-9]) and l for a single ASCII letter ([A-Z]). Use match groups to indicate groups in the postcode that may optionally be separated with a space or a hyphen. For example, the postcode for Bermuda above always consists of two letters and two digits. They may optionally be separated by a space or hyphen. That means that Nominatim will consider AB56 , AB 56 and AB-56 spelling variants for one and the same postcode. Never add the country code in front of the postcode pattern. Nominatim will automatically accept variants with a country code prefix for all postcodes. The output field is an optional field that describes what the canonical spelling of the postcode should be. The format is the regular expression expand syntax referring back to the bracket groups in the pattern. Most simple postcodes only have one spelling variant. In that case, the output can be omitted. The postcode will simply be used as is. In the Bermuda example above, the canonical spelling would be to have a space between letters and digits. Warning When your postcode pattern covers multiple variants of the postcode, then you must explicitly state the canonical output or Nominatim will not handle the variations correctly.","title":"postcode"},{"location":"customize/Country-Settings/#other-country-specific-configuration","text":"There are some other configuration files where you can set localized settings according to the assigned country. These are: Place ranking configuration Please see the linked documentation sections for more information.","title":"Other country-specific configuration"},{"location":"customize/Import-Styles/","text":"Configuring the Import \uf0c1 Which OSM objects are added to the database and which of the tags are used can be configured via the import style configuration file. This is a JSON file which contains a list of rules which are matched against every tag of every object and then assign the tag its specific role. The style to use is given by the NOMINATIM_IMPORT_STYLE configuration option. There are a number of default styles, which are explained in detail in the Import section . These standard styles may be referenced by their name. You can also create your own custom style. Put the style file into your project directory and then set NOMINATIM_IMPORT_STYLE to the name of the file. It is always recommended to start with one of the standard styles and customize those. You find the standard styles under the name import-<stylename>.style in the standard Nominatim configuration path (usually /etc/nominatim or /usr/local/etc/nominatim ). The remainder of the page describes the format of the file. Configuration Rules \uf0c1 A single rule looks like this: { \"keys\" : [ \"key1\" , \"key2\" , ... ], \"values\" : { \"value1\" : \"prop\" , \"value2\" : \"prop1,prop2\" } } A rule first defines a list of keys to apply the rule to. This is always a list of strings. The string may have four forms. An empty string matches against any key. A string that ends in an asterisk * is a prefix match and accordingly matches against any key that starts with the given string (minus the * ). A suffix match can be defined similarly with a string that starts with a * . Any other string constitutes an exact match. The second part of the rules defines a list of values and the properties that apply to a successful match. Value strings may be either empty, which means that they match any value, or describe an exact match. Prefix or suffix matching of values is not possible. For a rule to match, it has to find a valid combination of keys and values. The resulting property is that of the matched values. The rules in a configuration file are processed sequentially and the first match for each tag wins. A rule where key and value are the empty string is special. This defines the fallback when none of the rules match. The fallback is always used as a last resort when nothing else matches, no matter where the rule appears in the file. Defining multiple fallback rules is not allowed. What happens in this case, is undefined. Tag Properties \uf0c1 One or more of the following properties may be given for each tag: main A principal tag. A new row will be added for the object with key and value as class and type . with_name When the tag is a principal tag ( main property set): only really add a new row, if there is any name tag found (a reference tag is not sufficient, see below). with_name_key When the tag is a principal tag ( main property set): only really add a new row, if there is also a name tag that matches the key of the principal tag. For example, if the main tag is bridge=yes , then it will only be added as an extra row, if there is a tag bridge:name[:XXX] for the same object. If this property is set, all other names that are not domain-specific are ignored. fallback When the tag is a principal tag ( main property set): only really add a new row, when no other principal tags for this object have been found. Only one fallback tag can win for an object. operator When the tag is a principal tag ( main property set): also include the operator tag in the list of names. This is a special construct for an out-dated tagging practise in OSM. Fuel stations and chain restaurants in particular used to have the name of the chain tagged as operator . These days the chain can be more commonly found in the brand tag but there is still enough old data around to warrant this special case. name Add tag to the list of names. ref Add tag to the list of names as a reference. At the moment this only means that the object is not considered to be named for with_name . address Add tag to the list of address tags. If the tag starts with addr: or is_in: , then this prefix is cut off before adding it to the list. postcode Add the value as a postcode to the address tags. If multiple tags are candidate for postcodes, one wins out and the others are dropped. country Add the value as a country code to the address tags. The value must be a two letter country code, otherwise it is ignored. If there are multiple tags that match, then one wins out and the others are dropped. house If no principle tags can be found for the object, still add the object with class = place and type = house . Use this for address nodes that have no other function. interpolation Add this object as an address interpolation (appears as class = place and type = houses in the database). extra Add tag to the list of extra tags. skip Skip the tag completely. Useful when a custom default fallback is defined or to define exceptions to rules. A rule can define as many of these properties for one match as it likes. For example, if the property is \"main,extra\" then the tag will open a new row but also have the tag appear in the list of extra tags. Changing the Style of Existing Databases \uf0c1 There is normally no issue changing the style of a database that is already imported and now kept up-to-date with change files. Just be aware that any change in the style applies to updates only. If you want to change the data that is already in the database, then a reimport is necessary.","title":"Import Styles"},{"location":"customize/Import-Styles/#configuring-the-import","text":"Which OSM objects are added to the database and which of the tags are used can be configured via the import style configuration file. This is a JSON file which contains a list of rules which are matched against every tag of every object and then assign the tag its specific role. The style to use is given by the NOMINATIM_IMPORT_STYLE configuration option. There are a number of default styles, which are explained in detail in the Import section . These standard styles may be referenced by their name. You can also create your own custom style. Put the style file into your project directory and then set NOMINATIM_IMPORT_STYLE to the name of the file. It is always recommended to start with one of the standard styles and customize those. You find the standard styles under the name import-<stylename>.style in the standard Nominatim configuration path (usually /etc/nominatim or /usr/local/etc/nominatim ). The remainder of the page describes the format of the file.","title":"Configuring the Import"},{"location":"customize/Import-Styles/#configuration-rules","text":"A single rule looks like this: { \"keys\" : [ \"key1\" , \"key2\" , ... ], \"values\" : { \"value1\" : \"prop\" , \"value2\" : \"prop1,prop2\" } } A rule first defines a list of keys to apply the rule to. This is always a list of strings. The string may have four forms. An empty string matches against any key. A string that ends in an asterisk * is a prefix match and accordingly matches against any key that starts with the given string (minus the * ). A suffix match can be defined similarly with a string that starts with a * . Any other string constitutes an exact match. The second part of the rules defines a list of values and the properties that apply to a successful match. Value strings may be either empty, which means that they match any value, or describe an exact match. Prefix or suffix matching of values is not possible. For a rule to match, it has to find a valid combination of keys and values. The resulting property is that of the matched values. The rules in a configuration file are processed sequentially and the first match for each tag wins. A rule where key and value are the empty string is special. This defines the fallback when none of the rules match. The fallback is always used as a last resort when nothing else matches, no matter where the rule appears in the file. Defining multiple fallback rules is not allowed. What happens in this case, is undefined.","title":"Configuration Rules"},{"location":"customize/Import-Styles/#tag-properties","text":"One or more of the following properties may be given for each tag: main A principal tag. A new row will be added for the object with key and value as class and type . with_name When the tag is a principal tag ( main property set): only really add a new row, if there is any name tag found (a reference tag is not sufficient, see below). with_name_key When the tag is a principal tag ( main property set): only really add a new row, if there is also a name tag that matches the key of the principal tag. For example, if the main tag is bridge=yes , then it will only be added as an extra row, if there is a tag bridge:name[:XXX] for the same object. If this property is set, all other names that are not domain-specific are ignored. fallback When the tag is a principal tag ( main property set): only really add a new row, when no other principal tags for this object have been found. Only one fallback tag can win for an object. operator When the tag is a principal tag ( main property set): also include the operator tag in the list of names. This is a special construct for an out-dated tagging practise in OSM. Fuel stations and chain restaurants in particular used to have the name of the chain tagged as operator . These days the chain can be more commonly found in the brand tag but there is still enough old data around to warrant this special case. name Add tag to the list of names. ref Add tag to the list of names as a reference. At the moment this only means that the object is not considered to be named for with_name . address Add tag to the list of address tags. If the tag starts with addr: or is_in: , then this prefix is cut off before adding it to the list. postcode Add the value as a postcode to the address tags. If multiple tags are candidate for postcodes, one wins out and the others are dropped. country Add the value as a country code to the address tags. The value must be a two letter country code, otherwise it is ignored. If there are multiple tags that match, then one wins out and the others are dropped. house If no principle tags can be found for the object, still add the object with class = place and type = house . Use this for address nodes that have no other function. interpolation Add this object as an address interpolation (appears as class = place and type = houses in the database). extra Add tag to the list of extra tags. skip Skip the tag completely. Useful when a custom default fallback is defined or to define exceptions to rules. A rule can define as many of these properties for one match as it likes. For example, if the property is \"main,extra\" then the tag will open a new row but also have the tag appear in the list of extra tags.","title":"Tag Properties"},{"location":"customize/Import-Styles/#changing-the-style-of-existing-databases","text":"There is normally no issue changing the style of a database that is already imported and now kept up-to-date with change files. Just be aware that any change in the style applies to updates only. If you want to change the data that is already in the database, then a reimport is necessary.","title":"Changing the Style of Existing Databases"},{"location":"customize/Overview/","text":"Nominatim comes with a predefined set of configuration options that should work for most standard installations. If you have special requirements, there are many places where the configuration can be adapted. This chapter describes the following configurable parts: Global Settings has a detailed description of all parameters that can be set in your local .env configuration Import styles explains how to write your own import style in order to control what kind of OSM data will be imported Place ranking describes the configuration around classifing places in terms of their importance and their role in an address Tokenizers describes the configuration of the module responsible for analysing and indexing names Special Phrases are common nouns or phrases that can be used in search to identify a class of places There are also guides for adding the following external data: US house numbers from the TIGER dataset External postcodes","title":"Overview"},{"location":"customize/Postcodes/","text":"External postcode data \uf0c1 Nominatim creates a table of known postcode centroids during import. This table is used for searches of postcodes and for adding postcodes to places where the OSM data does not provide one. These postcode centroids are mainly computed from the OSM data itself. In addition, Nominatim supports reading postcode information from an external CSV file, to supplement the postcodes that are missing in OSM. To enable external postcode support, simply put one CSV file per country into your project directory and name it <CC>_postcodes.csv . <CC> must be the two-letter country code for which to apply the file. The file may also be gzipped. Then it must be called <CC>_postcodes.csv.gz . The CSV file must use commas as a delimiter and have a header line. Nominatim expects three columns to be present: postcode , lat and lon . All other columns are ignored. lon and lat must describe the x and y coordinates of the postcode centroids in WGS84. The postcode files are loaded only when there is data for the given country in your database. For example, if there is a us_postcodes.csv file in your project directory but you import only an excerpt of Italy, then the US postcodes will simply be ignored. As a rule, the external postcode data should be put into the project directory before starting the initial import. Still, you can add, remove and update the external postcode data at any time. Simply run: nominatim refresh --postcodes to make the changes visible in your database. Be aware, however, that the changes only have an immediate effect on searches for postcodes. Postcodes that were added to places are only updated, when they are reindexed. That usually happens only during replication updates.","title":"External data: Postcodes"},{"location":"customize/Postcodes/#external-postcode-data","text":"Nominatim creates a table of known postcode centroids during import. This table is used for searches of postcodes and for adding postcodes to places where the OSM data does not provide one. These postcode centroids are mainly computed from the OSM data itself. In addition, Nominatim supports reading postcode information from an external CSV file, to supplement the postcodes that are missing in OSM. To enable external postcode support, simply put one CSV file per country into your project directory and name it <CC>_postcodes.csv . <CC> must be the two-letter country code for which to apply the file. The file may also be gzipped. Then it must be called <CC>_postcodes.csv.gz . The CSV file must use commas as a delimiter and have a header line. Nominatim expects three columns to be present: postcode , lat and lon . All other columns are ignored. lon and lat must describe the x and y coordinates of the postcode centroids in WGS84. The postcode files are loaded only when there is data for the given country in your database. For example, if there is a us_postcodes.csv file in your project directory but you import only an excerpt of Italy, then the US postcodes will simply be ignored. As a rule, the external postcode data should be put into the project directory before starting the initial import. Still, you can add, remove and update the external postcode data at any time. Simply run: nominatim refresh --postcodes to make the changes visible in your database. Be aware, however, that the changes only have an immediate effect on searches for postcodes. Postcodes that were added to places are only updated, when they are reindexed. That usually happens only during replication updates.","title":"External postcode data"},{"location":"customize/Ranking/","text":"Place Ranking in Nominatim \uf0c1 Nominatim uses two metrics to rank a place: search rank and address rank. This chapter explains what place ranking means and how it can be customized. Search rank \uf0c1 The search rank describes the extent and importance of a place. It is used when ranking search results. Simply put, if there are two results for a search query which are otherwise equal, then the result with the lower search rank will be appear higher in the result list. Search ranks are not so important these days because many well-known places use the Wikipedia importance ranking instead. The following table gives an overview of the kind of features that Nominatim expects for each rank: rank typical place types extent 1-3 oceans, continents - 4 countries - 5-9 states, regions, provinces - 10-12 counties - 13-16 cities, municipalities, islands 15 km 17-18 towns, boroughs 4 km 19 villages, suburbs 2 km 20 hamlets, farms, neighbourhoods 1 km 21-25 isolated dwellings, city blocks 500 m The extent column describes how far a feature is assumed to reach when it is mapped only as a point. Larger features like countries and states are usually available with their exact area in the OpenStreetMap data. That is why no extent is given. Address rank \uf0c1 The address rank describes where a place shows up in an address hierarchy. Usually only administrative boundaries and place nodes and areas are eligible to be part of an address. Places that should not appear in the address must have an address rank of 0. The following table gives an overview how ranks are mapped to address parts: rank address part 1-3 unused 4 country 5-9 state 10-12 county 13-16 city 17-21 suburb 22-24 neighbourhood 25 squares, farms, localities 26-27 street 28-30 POI/house number The country rank 4 usually doesn't show up in the address parts of an object. The country is determined indirectly from the country code. Ranks 5-24 can be assigned more or less freely. They make up the major part of the address. Rank 25 is also an addressing rank but it is special because while it can be the parent to a POI with an addr:place of the same name, it cannot be a parent to streets. Use it for place features that are technically on the same level as a street (e.g. squares, city blocks) or for places that should not normally appear in an address unless explicitly tagged so (e.g place=locality which should be uninhabited and as such not addressable). The street ranks 26 and 27 are handled slightly differently. Only one object from these ranks shows up in an address. For POI level objects like shops, buildings or house numbers always use rank 30. Ranks 28 is reserved for house number interpolations. 29 is for internal use only. Rank configuration \uf0c1 Search and address ranks are assigned to a place when it is first imported into the database. There are a few hard-coded rules for the assignment: postcodes follow special rules according to their length boundaries that are not areas and railway=rail are dropped completely the following are always search rank 30 and address rank 0: highway nodes landuse that is not an area Other than that, the ranks can be freely assigned via the JSON file according to their type and the country they are in. The name of the config file to be used can be changed with the setting NOMINATIM_ADDRESS_LEVEL_CONFIG . The address level configuration must consist of an array of configuration entries, each containing a tag definition and an optional country array: [ { \"tags\" : { \"place\" : { \"county\" : 12, \"city\" : 16, }, \"landuse\" : { \"residential\" : 22, \"\" : 30 } } }, { \"countries\" : [ \"ca\", \"us\" ], \"tags\" : { \"boundary\" : { \"administrative8\" : 18, \"administrative9\" : 20 }, \"landuse\" : { \"residential\" : [22, 0] } } } ] The countries field contains a list of countries (as ISO 3166-1 alpha 2 code) for which the definition applies. When the field is omitted, then the definition is used as a fallback, when nothing more specific for a given country exists. tags contains the ranks for key/value pairs. The ranks can be either a single number, in which case they are the search and address rank, or an array of search and address rank (in that order). The value may be left empty. Then the rank is used when no more specific value is found for the given key. Countries and key/value combination may appear in multiple definitions. Just make sure that each combination of country/key/value appears only once per file. Otherwise the import will fail with a UNIQUE INDEX constraint violation on import.","title":"Place Ranking"},{"location":"customize/Ranking/#place-ranking-in-nominatim","text":"Nominatim uses two metrics to rank a place: search rank and address rank. This chapter explains what place ranking means and how it can be customized.","title":"Place Ranking in Nominatim"},{"location":"customize/Ranking/#search-rank","text":"The search rank describes the extent and importance of a place. It is used when ranking search results. Simply put, if there are two results for a search query which are otherwise equal, then the result with the lower search rank will be appear higher in the result list. Search ranks are not so important these days because many well-known places use the Wikipedia importance ranking instead. The following table gives an overview of the kind of features that Nominatim expects for each rank: rank typical place types extent 1-3 oceans, continents - 4 countries - 5-9 states, regions, provinces - 10-12 counties - 13-16 cities, municipalities, islands 15 km 17-18 towns, boroughs 4 km 19 villages, suburbs 2 km 20 hamlets, farms, neighbourhoods 1 km 21-25 isolated dwellings, city blocks 500 m The extent column describes how far a feature is assumed to reach when it is mapped only as a point. Larger features like countries and states are usually available with their exact area in the OpenStreetMap data. That is why no extent is given.","title":"Search rank"},{"location":"customize/Ranking/#address-rank","text":"The address rank describes where a place shows up in an address hierarchy. Usually only administrative boundaries and place nodes and areas are eligible to be part of an address. Places that should not appear in the address must have an address rank of 0. The following table gives an overview how ranks are mapped to address parts: rank address part 1-3 unused 4 country 5-9 state 10-12 county 13-16 city 17-21 suburb 22-24 neighbourhood 25 squares, farms, localities 26-27 street 28-30 POI/house number The country rank 4 usually doesn't show up in the address parts of an object. The country is determined indirectly from the country code. Ranks 5-24 can be assigned more or less freely. They make up the major part of the address. Rank 25 is also an addressing rank but it is special because while it can be the parent to a POI with an addr:place of the same name, it cannot be a parent to streets. Use it for place features that are technically on the same level as a street (e.g. squares, city blocks) or for places that should not normally appear in an address unless explicitly tagged so (e.g place=locality which should be uninhabited and as such not addressable). The street ranks 26 and 27 are handled slightly differently. Only one object from these ranks shows up in an address. For POI level objects like shops, buildings or house numbers always use rank 30. Ranks 28 is reserved for house number interpolations. 29 is for internal use only.","title":"Address rank"},{"location":"customize/Ranking/#rank-configuration","text":"Search and address ranks are assigned to a place when it is first imported into the database. There are a few hard-coded rules for the assignment: postcodes follow special rules according to their length boundaries that are not areas and railway=rail are dropped completely the following are always search rank 30 and address rank 0: highway nodes landuse that is not an area Other than that, the ranks can be freely assigned via the JSON file according to their type and the country they are in. The name of the config file to be used can be changed with the setting NOMINATIM_ADDRESS_LEVEL_CONFIG . The address level configuration must consist of an array of configuration entries, each containing a tag definition and an optional country array: [ { \"tags\" : { \"place\" : { \"county\" : 12, \"city\" : 16, }, \"landuse\" : { \"residential\" : 22, \"\" : 30 } } }, { \"countries\" : [ \"ca\", \"us\" ], \"tags\" : { \"boundary\" : { \"administrative8\" : 18, \"administrative9\" : 20 }, \"landuse\" : { \"residential\" : [22, 0] } } } ] The countries field contains a list of countries (as ISO 3166-1 alpha 2 code) for which the definition applies. When the field is omitted, then the definition is used as a fallback, when nothing more specific for a given country exists. tags contains the ranks for key/value pairs. The ranks can be either a single number, in which case they are the search and address rank, or an array of search and address rank (in that order). The value may be left empty. Then the rank is used when no more specific value is found for the given key. Countries and key/value combination may appear in multiple definitions. Just make sure that each combination of country/key/value appears only once per file. Otherwise the import will fail with a UNIQUE INDEX constraint violation on import.","title":"Rank configuration"},{"location":"customize/Settings/","text":"This section provides a reference of all configuration parameters that can be used with Nominatim. Configuring Nominatim \uf0c1 Nominatim uses dotenv to manage its configuration settings. There are two means to set configuration variables: through an .env configuration file or through an environment variable. The .env configuration file needs to be placed into the project directory . It must contain configuration parameters in <parameter>=<value> format. Please refer to the dotenv documentation for details. The configuration options may also be set in the form of shell environment variables. This is particularly useful, when you want to temporarily change a configuration option. For example, to force the replication serve to download the next change, you can temporarily disable the update interval: NOMINATIM_REPLICATION_UPDATE_INTERVAL=0 nominatim replication --once If a configuration option is defined through .env file and environment variable, then the latter takes precedence. Configuration Parameter Reference \uf0c1 Import and Database Settings \uf0c1 NOMINATIM_DATABASE_DSN \uf0c1 Summary Description: Database connection string Format: string: pgsql:<param1>=<value1>;<param2>=<value2>;... Default: pgsql:dbname=nominatim After Changes: run nominatim refresh --website Sets the connection parameters for the Nominatim database. At a minimum the name of the database ( dbname ) is required. You can set any additional parameter that is understood by libpq. See the Postgres documentation for a full list. Note It is usually recommended not to set the password directly in this configuration parameter. Use a password file instead. NOMINATIM_DATABASE_WEBUSER \uf0c1 Summary Description: Database query user Format: string Default: www-data After Changes: cannot be changed after import Defines the name of the database user that will run search queries. Usually this is the user under which the webserver is executed. When running Nominatim via php-fpm, you can also define a separate query user. The Postgres user needs to be set up before starting the import. Nominatim grants minimal rights to this user to all tables that are needed for running geocoding queries. NOMINATIM_DATABASE_MODULE_PATH \uf0c1 Summary Description: Directory where to find the PostgreSQL server module Format: path Default: empty (use <project_directory>/module ) After Changes: run nominatim refresh --functions Comment: Legacy tokenizer only Defines the directory in which the PostgreSQL server module nominatim.so is stored. The directory and module must be accessible by the PostgreSQL server. For information on how to use this setting when working with external databases, see Advanced Installations . The option is only used by the Legacy tokenizer and ignored otherwise. NOMINATIM_TOKENIZER \uf0c1 Summary Description: Tokenizer used for normalizing and parsing queries and names Format: string Default: legacy After Changes: cannot be changed after import Sets the tokenizer type to use for the import. For more information on available tokenizers and how they are configured, see Tokenizers . NOMINATIM_TOKENIZER_CONFIG \uf0c1 Summary Description: Configuration file for the tokenizer Format: path Default: empty (default file depends on tokenizer) After Changes: see documentation for each tokenizer Points to the file with additional configuration for the tokenizer. See the Tokenizer descriptions for details on the file format. If a relative path is given, then the file is searched first relative to the project directory and then in the global settings directory. NOMINATIM_MAX_WORD_FREQUENCY \uf0c1 Summary Description: Number of occurrences before a word is considered frequent Format: int Default: 50000 After Changes: cannot be changed after import Comment: Legacy tokenizer only The word frequency count is used by the Legacy tokenizer to automatically identify stop words . Any partial term that occurs more often then what is defined in this setting, is effectively ignored during search. NOMINATIM_LIMIT_REINDEXING \uf0c1 Summary Description: Avoid invalidating large areas Format: bool Default: yes Nominatim computes the address of each place at indexing time. This has the advantage to make search faster but also means that more objects needs to be invalidated when the data changes. For example, changing the name of the state of Florida would require recomputing every single address point in the state to make the new name searchable in conjunction with addresses. Setting this option to 'yes' means that Nominatim skips reindexing of contained objects when the area becomes too large. NOMINATIM_LANGUAGES \uf0c1 Summary Description: Restrict search languages Format: string: comma-separated list of language codes Default: empty Normally Nominatim will include all language variants of name:XX in the search index. Set this to a comma separated list of language codes, to restrict import to a subset of languages. Currently only affects the initial import of country names and special phrases. NOMINATIM_TERM_NORMALIZATION \uf0c1 Summary Description: Rules for normalizing terms for comparisons Format: string: semicolon-separated list of ICU rules Default: :: NFD (); [ :Nonspacing Mark: ] >; :: lower (); [ :Punctuation: ]+ > ' '; :: NFC (); Comment: Legacy tokenizer only Special phrases have stricter matching requirements than normal search terms. They must appear exactly in the query after this term normalization has been applied. Only has an effect on the Legacy tokenizer. For the ICU tokenizer the rules defined in the normalization section will be used. NOMINATIM_USE_US_TIGER_DATA \uf0c1 Summary Description: Enable searching for Tiger house number data Format: boolean Default: no After Changes: run nominatim refresh --functions When this setting is enabled, search and reverse queries also take data from Tiger house number data into account. NOMINATIM_USE_AUX_LOCATION_DATA \uf0c1 Summary Description: Enable searching in external house number tables Format: boolean Default: no After Changes: run nominatim refresh --functions Comment: Do not use. When this setting is enabled, search queries also take data from external house number tables into account. Warning: This feature is currently unmaintained and should not be used. NOMINATIM_HTTP_PROXY \uf0c1 Summary Description: Use HTTP proxy when downloading data Format: boolean Default: no When this setting is enabled and at least NOMINATIM_HTTP_PROXY_HOST and NOMINATIM_HTTP_PROXY_PORT are set, the configured proxy will be used, when downloading external data like replication diffs. NOMINATIM_HTTP_PROXY_HOST \uf0c1 Summary Description: Host name of the proxy to use Format: string Default: empty When NOMINATIM_HTTP_PROXY is enabled, this setting configures the proxy host name. NOMINATIM_HTTP_PROXY_PORT \uf0c1 Summary Description: Port number of the proxy to use Format: integer Default: 3128 When NOMINATIM_HTTP_PROXY is enabled, this setting configures the port number to use with the proxy. NOMINATIM_HTTP_PROXY_LOGIN \uf0c1 Summary Description: Username for proxies that require login Format: string Default: empty When NOMINATIM_HTTP_PROXY is enabled, use this setting to define the username for proxies that require a login. NOMINATIM_HTTP_PROXY_PASSWORD \uf0c1 Summary Description: Password for proxies that require login Format: string Default: empty When NOMINATIM_HTTP_PROXY is enabled, use this setting to define the password for proxies that require a login. NOMINATIM_OSM2PGSQL_BINARY \uf0c1 Summary Description: Location of the osm2pgsql binary Format: path Default: empty (use binary shipped with Nominatim) Comment: EXPERT ONLY Nominatim uses osm2pgsql to load the OSM data initially into the database. Nominatim comes bundled with a version of osm2pgsql that is guaranteed to be compatible. Use this setting to use a different binary instead. You should do this only when you know exactly what you are doing. If the osm2pgsql version is not compatible, then the result is undefined. NOMINATIM_WIKIPEDIA_DATA_PATH \uf0c1 Summary Description: Directory with the wikipedia importance data Format: path Default: empty (project directory) Set a custom location for the wikipedia ranking file . When unset, Nominatim expects the data to be saved in the project directory. NOMINATIM_ADDRESS_LEVEL_CONFIG \uf0c1 Summary Description: Configuration file for rank assignments Format: path Default: address-levels.json The address level configuration defines the rank assignments for places. See Place Ranking for a detailed explanation what rank assignments are and what the configuration file must look like. When a relative path is given, then the file is searched first relative to the project directory and then in the global settings directory. NOMINATIM_IMPORT_STYLE \uf0c1 Summary Description: Configuration to use for the initial OSM data import Format: string or path Default: extratags The style configuration describes which OSM objects and tags are taken into consideration for the search database. Nominatim comes with a set of pre-configured styles, that may be configured here. You can also write your own custom style and point the setting to the file with the style. When a relative path is given, then the style file is searched first relative to the project directory and then in the global settings directory. See Import Styles for more information on the available internal styles and the format of the configuration file. NOMINATIM_FLATNODE_FILE \uf0c1 Summary Description: Location of osm2pgsql flatnode file Format: path Default: empty (do not use a flatnote file) After Changes: Only change when moving the file physically. The osm2pgsql flatnode file is file that efficiently stores geographic location for OSM nodes. For larger imports it can significantly speed up the import. When this option is unset, then osm2pgsql uses a PsotgreSQL table to store the locations. When a relative path is given, then the flatnode file is created/searched relative to the project directory. Warning The flatnode file is not only used during the initial import but also when adding new data with nominatim add-data or nominatim replication . Make sure you keep the flatnode file around and this setting unmodified, if you plan to add more data or run regular updates. NOMINATIM_TABLESPACE_* \uf0c1 Summary Description: Group of settings for distributing the database over tablespaces Format: string Default: empty (do not use a table space) After Changes: no effect after initial import Nominatim allows to distribute the search database over up to 10 different PostgreSQL tablespaces . If you use this option, make sure that the tablespaces exist before starting the import. The available tablespace groups are: NOMINATIM_TABLESPACE_SEARCH_DATA Data used by the geocoding frontend. NOMINATIM_TABLESPACE_SEARCH_INDEX Indexes used by the geocoding frontend. NOMINATIM_TABLESPACE_OSM_DATA Raw OSM data cache used for import and updates. NOMINATIM_TABLESPACE_OSM_DATA Indexes on the raw OSM data cache. NOMINATIM_TABLESPACE_PLACE_DATA Data table with the pre-filtered but still unprocessed OSM data. Used only during imports and updates. NOMINATIM_TABLESPACE_PLACE_INDEX Indexes on raw data table. Used only during imports and updates. NOMINATIM_TABLESPACE_ADDRESS_DATA Data tables used for computing search terms and addresses of places during import and updates. NOMINATIM_TABLESPACE_ADDRESS_INDEX Indexes on the data tables for search term and address computation. Used only for import and updates. NOMINATIM_TABLESPACE_AUX_DATA Auxiliary data tables for non-OSM data, e.g. for Tiger house number data. NOMINATIM_TABLESPACE_AUX_INDEX Indexes on auxiliary data tables. Replication Update Settings \uf0c1 NOMINATIM_REPLICATION_URL \uf0c1 Summary Description: Base URL of the replication service Format: url Default: https://planet.openstreetmap.org/replication/minute After Changes: run nominatim replication --init Replication services deliver updates to OSM data. Use this setting to choose which replication service to use. See Updates for more information on how to set up regular updates. NOMINATIM_REPLICATION_MAX_DIFF \uf0c1 Summary Description: Maximum amount of data to download per update cycle (in MB) Format: integer Default: 50 After Changes: restart the replication process At each update cycle Nominatim downloads diffs until either no more diffs are available on the server (i.e. the database is up-to-date) or the limit given in this setting is exceeded. Nominatim guarantees to downloads at least one diff, if one is available, no matter how small the setting. The default for this setting is fairly conservative because Nominatim keeps all data downloaded in one cycle in RAM. Using large values in a production server may interfere badly with the search frontend because it evicts data from RAM that is needed for speedy answers to incoming requests. It is usually a better idea to keep this setting lower and run multiple update cycles to catch up with updates. When catching up in non-production mode, for example after the initial import, the setting can easily be changed temporarily on the command line: NOMINATIM_REPLICATION_MAX_DIFF=3000 nominatim replication NOMINATIM_REPLICATION_UPDATE_INTERVAL \uf0c1 Summary Description: Publication interval of the replication service (in seconds) Format: integer Default: 75 After Changes: restart the replication process This setting determines when Nominatim will attempt to download again a new update. The time is computed from the publication date of the last diff downloaded. Setting this to a slightly higher value than the actual publication interval avoids unnecessary rechecks. NOMINATIM_REPLICATION_RECHECK_INTERVAL \uf0c1 Summary Description: Wait time to recheck for a pending update (in seconds) Format: integer Default: 60 After Changes: restart the replication process When replication updates are run in continuous mode (using nominatim replication ), this setting determines how long Nominatim waits until it looks for updates again when updates were not available on the server. Note that this is different from NOMINATIM_REPLICATION_UPDATE_INTERVAL . Nominatim will never attempt to query for new updates for UPDATE_INTERVAL seconds after the current database date. Only after the update interval has passed it asks for new data. If then no new data is found, it waits for RECHECK_INTERVAL seconds before it attempts again. API Settings \uf0c1 NOMINATIM_CORS_NOACCESSCONTROL \uf0c1 Summary Description: Send permissive CORS access headers Format: boolean Default: yes After Changes: run nominatim refresh --website When this setting is enabled, API HTTP responses include the HTTP CORS headers access-control-allow-origin: * and access-control-allow-methods: OPTIONS,GET . NOMINATIM_MAPICON_URL \uf0c1 Summary Description: URL prefix for static icon images Format: url Default: empty After Changes: run nominatim refresh --website When a mapicon URL is configured, then Nominatim includes an additional icon field in the responses, pointing to an appropriate icon for the place type. Map icons used to be included in Nominatim itself but now have moved to the nominatim-ui project. If you want the URL to be included in API responses, make the /mapicon directory of the project available under a public URL and point this setting to the directory. NOMINATIM_DEFAULT_LANGUAGE \uf0c1 Summary Description: Language of responses when no language is requested Format: language code Default: empty (use the local language of the feature) After Changes: run nominatim refresh --website Nominatim localizes the place names in responses when the corresponding translation is available. Users can request a custom language setting through the HTTP accept-languages header or through the explicit parameter accept-languages . If neither is given, it falls back to this setting. If the setting is also empty, then the local languages (in OSM: the name tag without any language suffix) is used. NOMINATIM_SEARCH_BATCH_MODE \uf0c1 Summary Description: Enable a special batch query mode Format: boolean Default: no After Changes: run nominatim refresh --website This feature is currently undocumented and potentially broken. NOMINATIM_SEARCH_NAME_ONLY_THRESHOLD \uf0c1 Summary Description: Threshold for switching the search index lookup strategy Format: integer Default: 500 After Changes: run nominatim refresh --website This setting defines the threshold over which a name is no longer considered as rare. When searching for places with rare names, only the name is used for place lookups. Otherwise the name and any address information is used. This setting only has an effect after nominatim refresh --word-counts has been called to compute the word frequencies. NOMINATIM_LOOKUP_MAX_COUNT \uf0c1 Summary Description: Maximum number of OSM ids accepted by /lookup Format: integer Default: 50 After Changes: run nominatim refresh --website The /lookup point accepts list of ids to look up address details for. This setting restricts the number of places a user may look up with a single request. NOMINATIM_POLYGON_OUTPUT_MAX_TYPES \uf0c1 Summary Description: Number of different geometry formats that may be returned Format: integer Default: 1 After Changes: run nominatim refresh --website Nominatim supports returning full geometries of places. The geometries may be requested in different formats with one of the polygon_* parameters . Use this setting to restrict the number of geometry types that may be requested with a single query. Setting this parameter to 0 disables polygon output completely. Logging Settings \uf0c1 NOMINATIM_LOG_DB \uf0c1 Summary Description: Log requests into the database Format: boolean Default: no After Changes: run nominatim refresh --website Enable logging requests into a database table with this setting. The logs can be found in the table new_query_log . When using this logging method, it is advisable to set up a job that regularly clears out old logging information. Nominatim will not do that on its own. Can be used as the same time as NOMINATIM_LOG_FILE. NOMINATIM_LOG_FILE \uf0c1 Summary Description: Log requests into a file Format: path Default: empty (logging disabled) After Changes: run nominatim refresh --website Enable logging of requests into a file with this setting by setting the log file where to log to. A relative file name is assumed to be relative to the project directory. The entries in the log file have the following format: <request time> <execution time in s> <number of results> <type> \"<query string>\" Request time is the time when the request was started. The execution time is given in ms and corresponds to the time the query took executing in PHP. type contains the name of the endpoint used. Can be used as the same time as NOMINATIM_LOG_DB.","title":"Configuration Settings"},{"location":"customize/Settings/#configuring-nominatim","text":"Nominatim uses dotenv to manage its configuration settings. There are two means to set configuration variables: through an .env configuration file or through an environment variable. The .env configuration file needs to be placed into the project directory . It must contain configuration parameters in <parameter>=<value> format. Please refer to the dotenv documentation for details. The configuration options may also be set in the form of shell environment variables. This is particularly useful, when you want to temporarily change a configuration option. For example, to force the replication serve to download the next change, you can temporarily disable the update interval: NOMINATIM_REPLICATION_UPDATE_INTERVAL=0 nominatim replication --once If a configuration option is defined through .env file and environment variable, then the latter takes precedence.","title":"Configuring Nominatim"},{"location":"customize/Settings/#configuration-parameter-reference","text":"","title":"Configuration Parameter Reference"},{"location":"customize/Settings/#import-and-database-settings","text":"","title":"Import and Database Settings"},{"location":"customize/Settings/#nominatim_database_dsn","text":"Summary Description: Database connection string Format: string: pgsql:<param1>=<value1>;<param2>=<value2>;... Default: pgsql:dbname=nominatim After Changes: run nominatim refresh --website Sets the connection parameters for the Nominatim database. At a minimum the name of the database ( dbname ) is required. You can set any additional parameter that is understood by libpq. See the Postgres documentation for a full list. Note It is usually recommended not to set the password directly in this configuration parameter. Use a password file instead.","title":"NOMINATIM_DATABASE_DSN"},{"location":"customize/Settings/#nominatim_database_webuser","text":"Summary Description: Database query user Format: string Default: www-data After Changes: cannot be changed after import Defines the name of the database user that will run search queries. Usually this is the user under which the webserver is executed. When running Nominatim via php-fpm, you can also define a separate query user. The Postgres user needs to be set up before starting the import. Nominatim grants minimal rights to this user to all tables that are needed for running geocoding queries.","title":"NOMINATIM_DATABASE_WEBUSER"},{"location":"customize/Settings/#nominatim_database_module_path","text":"Summary Description: Directory where to find the PostgreSQL server module Format: path Default: empty (use <project_directory>/module ) After Changes: run nominatim refresh --functions Comment: Legacy tokenizer only Defines the directory in which the PostgreSQL server module nominatim.so is stored. The directory and module must be accessible by the PostgreSQL server. For information on how to use this setting when working with external databases, see Advanced Installations . The option is only used by the Legacy tokenizer and ignored otherwise.","title":"NOMINATIM_DATABASE_MODULE_PATH"},{"location":"customize/Settings/#nominatim_tokenizer","text":"Summary Description: Tokenizer used for normalizing and parsing queries and names Format: string Default: legacy After Changes: cannot be changed after import Sets the tokenizer type to use for the import. For more information on available tokenizers and how they are configured, see Tokenizers .","title":"NOMINATIM_TOKENIZER"},{"location":"customize/Settings/#nominatim_tokenizer_config","text":"Summary Description: Configuration file for the tokenizer Format: path Default: empty (default file depends on tokenizer) After Changes: see documentation for each tokenizer Points to the file with additional configuration for the tokenizer. See the Tokenizer descriptions for details on the file format. If a relative path is given, then the file is searched first relative to the project directory and then in the global settings directory.","title":"NOMINATIM_TOKENIZER_CONFIG"},{"location":"customize/Settings/#nominatim_max_word_frequency","text":"Summary Description: Number of occurrences before a word is considered frequent Format: int Default: 50000 After Changes: cannot be changed after import Comment: Legacy tokenizer only The word frequency count is used by the Legacy tokenizer to automatically identify stop words . Any partial term that occurs more often then what is defined in this setting, is effectively ignored during search.","title":"NOMINATIM_MAX_WORD_FREQUENCY"},{"location":"customize/Settings/#nominatim_limit_reindexing","text":"Summary Description: Avoid invalidating large areas Format: bool Default: yes Nominatim computes the address of each place at indexing time. This has the advantage to make search faster but also means that more objects needs to be invalidated when the data changes. For example, changing the name of the state of Florida would require recomputing every single address point in the state to make the new name searchable in conjunction with addresses. Setting this option to 'yes' means that Nominatim skips reindexing of contained objects when the area becomes too large.","title":"NOMINATIM_LIMIT_REINDEXING"},{"location":"customize/Settings/#nominatim_languages","text":"Summary Description: Restrict search languages Format: string: comma-separated list of language codes Default: empty Normally Nominatim will include all language variants of name:XX in the search index. Set this to a comma separated list of language codes, to restrict import to a subset of languages. Currently only affects the initial import of country names and special phrases.","title":"NOMINATIM_LANGUAGES"},{"location":"customize/Settings/#nominatim_term_normalization","text":"Summary Description: Rules for normalizing terms for comparisons Format: string: semicolon-separated list of ICU rules Default: :: NFD (); [ :Nonspacing Mark: ] >; :: lower (); [ :Punctuation: ]+ > ' '; :: NFC (); Comment: Legacy tokenizer only Special phrases have stricter matching requirements than normal search terms. They must appear exactly in the query after this term normalization has been applied. Only has an effect on the Legacy tokenizer. For the ICU tokenizer the rules defined in the normalization section will be used.","title":"NOMINATIM_TERM_NORMALIZATION"},{"location":"customize/Settings/#nominatim_use_us_tiger_data","text":"Summary Description: Enable searching for Tiger house number data Format: boolean Default: no After Changes: run nominatim refresh --functions When this setting is enabled, search and reverse queries also take data from Tiger house number data into account.","title":"NOMINATIM_USE_US_TIGER_DATA"},{"location":"customize/Settings/#nominatim_use_aux_location_data","text":"Summary Description: Enable searching in external house number tables Format: boolean Default: no After Changes: run nominatim refresh --functions Comment: Do not use. When this setting is enabled, search queries also take data from external house number tables into account. Warning: This feature is currently unmaintained and should not be used.","title":"NOMINATIM_USE_AUX_LOCATION_DATA"},{"location":"customize/Settings/#nominatim_http_proxy","text":"Summary Description: Use HTTP proxy when downloading data Format: boolean Default: no When this setting is enabled and at least NOMINATIM_HTTP_PROXY_HOST and NOMINATIM_HTTP_PROXY_PORT are set, the configured proxy will be used, when downloading external data like replication diffs.","title":"NOMINATIM_HTTP_PROXY"},{"location":"customize/Settings/#nominatim_http_proxy_host","text":"Summary Description: Host name of the proxy to use Format: string Default: empty When NOMINATIM_HTTP_PROXY is enabled, this setting configures the proxy host name.","title":"NOMINATIM_HTTP_PROXY_HOST"},{"location":"customize/Settings/#nominatim_http_proxy_port","text":"Summary Description: Port number of the proxy to use Format: integer Default: 3128 When NOMINATIM_HTTP_PROXY is enabled, this setting configures the port number to use with the proxy.","title":"NOMINATIM_HTTP_PROXY_PORT"},{"location":"customize/Settings/#nominatim_http_proxy_login","text":"Summary Description: Username for proxies that require login Format: string Default: empty When NOMINATIM_HTTP_PROXY is enabled, use this setting to define the username for proxies that require a login.","title":"NOMINATIM_HTTP_PROXY_LOGIN"},{"location":"customize/Settings/#nominatim_http_proxy_password","text":"Summary Description: Password for proxies that require login Format: string Default: empty When NOMINATIM_HTTP_PROXY is enabled, use this setting to define the password for proxies that require a login.","title":"NOMINATIM_HTTP_PROXY_PASSWORD"},{"location":"customize/Settings/#nominatim_osm2pgsql_binary","text":"Summary Description: Location of the osm2pgsql binary Format: path Default: empty (use binary shipped with Nominatim) Comment: EXPERT ONLY Nominatim uses osm2pgsql to load the OSM data initially into the database. Nominatim comes bundled with a version of osm2pgsql that is guaranteed to be compatible. Use this setting to use a different binary instead. You should do this only when you know exactly what you are doing. If the osm2pgsql version is not compatible, then the result is undefined.","title":"NOMINATIM_OSM2PGSQL_BINARY"},{"location":"customize/Settings/#nominatim_wikipedia_data_path","text":"Summary Description: Directory with the wikipedia importance data Format: path Default: empty (project directory) Set a custom location for the wikipedia ranking file . When unset, Nominatim expects the data to be saved in the project directory.","title":"NOMINATIM_WIKIPEDIA_DATA_PATH"},{"location":"customize/Settings/#nominatim_address_level_config","text":"Summary Description: Configuration file for rank assignments Format: path Default: address-levels.json The address level configuration defines the rank assignments for places. See Place Ranking for a detailed explanation what rank assignments are and what the configuration file must look like. When a relative path is given, then the file is searched first relative to the project directory and then in the global settings directory.","title":"NOMINATIM_ADDRESS_LEVEL_CONFIG"},{"location":"customize/Settings/#nominatim_import_style","text":"Summary Description: Configuration to use for the initial OSM data import Format: string or path Default: extratags The style configuration describes which OSM objects and tags are taken into consideration for the search database. Nominatim comes with a set of pre-configured styles, that may be configured here. You can also write your own custom style and point the setting to the file with the style. When a relative path is given, then the style file is searched first relative to the project directory and then in the global settings directory. See Import Styles for more information on the available internal styles and the format of the configuration file.","title":"NOMINATIM_IMPORT_STYLE"},{"location":"customize/Settings/#nominatim_flatnode_file","text":"Summary Description: Location of osm2pgsql flatnode file Format: path Default: empty (do not use a flatnote file) After Changes: Only change when moving the file physically. The osm2pgsql flatnode file is file that efficiently stores geographic location for OSM nodes. For larger imports it can significantly speed up the import. When this option is unset, then osm2pgsql uses a PsotgreSQL table to store the locations. When a relative path is given, then the flatnode file is created/searched relative to the project directory. Warning The flatnode file is not only used during the initial import but also when adding new data with nominatim add-data or nominatim replication . Make sure you keep the flatnode file around and this setting unmodified, if you plan to add more data or run regular updates.","title":"NOMINATIM_FLATNODE_FILE"},{"location":"customize/Settings/#nominatim_tablespace_","text":"Summary Description: Group of settings for distributing the database over tablespaces Format: string Default: empty (do not use a table space) After Changes: no effect after initial import Nominatim allows to distribute the search database over up to 10 different PostgreSQL tablespaces . If you use this option, make sure that the tablespaces exist before starting the import. The available tablespace groups are: NOMINATIM_TABLESPACE_SEARCH_DATA Data used by the geocoding frontend. NOMINATIM_TABLESPACE_SEARCH_INDEX Indexes used by the geocoding frontend. NOMINATIM_TABLESPACE_OSM_DATA Raw OSM data cache used for import and updates. NOMINATIM_TABLESPACE_OSM_DATA Indexes on the raw OSM data cache. NOMINATIM_TABLESPACE_PLACE_DATA Data table with the pre-filtered but still unprocessed OSM data. Used only during imports and updates. NOMINATIM_TABLESPACE_PLACE_INDEX Indexes on raw data table. Used only during imports and updates. NOMINATIM_TABLESPACE_ADDRESS_DATA Data tables used for computing search terms and addresses of places during import and updates. NOMINATIM_TABLESPACE_ADDRESS_INDEX Indexes on the data tables for search term and address computation. Used only for import and updates. NOMINATIM_TABLESPACE_AUX_DATA Auxiliary data tables for non-OSM data, e.g. for Tiger house number data. NOMINATIM_TABLESPACE_AUX_INDEX Indexes on auxiliary data tables.","title":"NOMINATIM_TABLESPACE_*"},{"location":"customize/Settings/#replication-update-settings","text":"","title":"Replication Update Settings"},{"location":"customize/Settings/#nominatim_replication_url","text":"Summary Description: Base URL of the replication service Format: url Default: https://planet.openstreetmap.org/replication/minute After Changes: run nominatim replication --init Replication services deliver updates to OSM data. Use this setting to choose which replication service to use. See Updates for more information on how to set up regular updates.","title":"NOMINATIM_REPLICATION_URL"},{"location":"customize/Settings/#nominatim_replication_max_diff","text":"Summary Description: Maximum amount of data to download per update cycle (in MB) Format: integer Default: 50 After Changes: restart the replication process At each update cycle Nominatim downloads diffs until either no more diffs are available on the server (i.e. the database is up-to-date) or the limit given in this setting is exceeded. Nominatim guarantees to downloads at least one diff, if one is available, no matter how small the setting. The default for this setting is fairly conservative because Nominatim keeps all data downloaded in one cycle in RAM. Using large values in a production server may interfere badly with the search frontend because it evicts data from RAM that is needed for speedy answers to incoming requests. It is usually a better idea to keep this setting lower and run multiple update cycles to catch up with updates. When catching up in non-production mode, for example after the initial import, the setting can easily be changed temporarily on the command line: NOMINATIM_REPLICATION_MAX_DIFF=3000 nominatim replication","title":"NOMINATIM_REPLICATION_MAX_DIFF"},{"location":"customize/Settings/#nominatim_replication_update_interval","text":"Summary Description: Publication interval of the replication service (in seconds) Format: integer Default: 75 After Changes: restart the replication process This setting determines when Nominatim will attempt to download again a new update. The time is computed from the publication date of the last diff downloaded. Setting this to a slightly higher value than the actual publication interval avoids unnecessary rechecks.","title":"NOMINATIM_REPLICATION_UPDATE_INTERVAL"},{"location":"customize/Settings/#nominatim_replication_recheck_interval","text":"Summary Description: Wait time to recheck for a pending update (in seconds) Format: integer Default: 60 After Changes: restart the replication process When replication updates are run in continuous mode (using nominatim replication ), this setting determines how long Nominatim waits until it looks for updates again when updates were not available on the server. Note that this is different from NOMINATIM_REPLICATION_UPDATE_INTERVAL . Nominatim will never attempt to query for new updates for UPDATE_INTERVAL seconds after the current database date. Only after the update interval has passed it asks for new data. If then no new data is found, it waits for RECHECK_INTERVAL seconds before it attempts again.","title":"NOMINATIM_REPLICATION_RECHECK_INTERVAL"},{"location":"customize/Settings/#api-settings","text":"","title":"API Settings"},{"location":"customize/Settings/#nominatim_cors_noaccesscontrol","text":"Summary Description: Send permissive CORS access headers Format: boolean Default: yes After Changes: run nominatim refresh --website When this setting is enabled, API HTTP responses include the HTTP CORS headers access-control-allow-origin: * and access-control-allow-methods: OPTIONS,GET .","title":"NOMINATIM_CORS_NOACCESSCONTROL"},{"location":"customize/Settings/#nominatim_mapicon_url","text":"Summary Description: URL prefix for static icon images Format: url Default: empty After Changes: run nominatim refresh --website When a mapicon URL is configured, then Nominatim includes an additional icon field in the responses, pointing to an appropriate icon for the place type. Map icons used to be included in Nominatim itself but now have moved to the nominatim-ui project. If you want the URL to be included in API responses, make the /mapicon directory of the project available under a public URL and point this setting to the directory.","title":"NOMINATIM_MAPICON_URL"},{"location":"customize/Settings/#nominatim_default_language","text":"Summary Description: Language of responses when no language is requested Format: language code Default: empty (use the local language of the feature) After Changes: run nominatim refresh --website Nominatim localizes the place names in responses when the corresponding translation is available. Users can request a custom language setting through the HTTP accept-languages header or through the explicit parameter accept-languages . If neither is given, it falls back to this setting. If the setting is also empty, then the local languages (in OSM: the name tag without any language suffix) is used.","title":"NOMINATIM_DEFAULT_LANGUAGE"},{"location":"customize/Settings/#nominatim_search_batch_mode","text":"Summary Description: Enable a special batch query mode Format: boolean Default: no After Changes: run nominatim refresh --website This feature is currently undocumented and potentially broken.","title":"NOMINATIM_SEARCH_BATCH_MODE"},{"location":"customize/Settings/#nominatim_search_name_only_threshold","text":"Summary Description: Threshold for switching the search index lookup strategy Format: integer Default: 500 After Changes: run nominatim refresh --website This setting defines the threshold over which a name is no longer considered as rare. When searching for places with rare names, only the name is used for place lookups. Otherwise the name and any address information is used. This setting only has an effect after nominatim refresh --word-counts has been called to compute the word frequencies.","title":"NOMINATIM_SEARCH_NAME_ONLY_THRESHOLD"},{"location":"customize/Settings/#nominatim_lookup_max_count","text":"Summary Description: Maximum number of OSM ids accepted by /lookup Format: integer Default: 50 After Changes: run nominatim refresh --website The /lookup point accepts list of ids to look up address details for. This setting restricts the number of places a user may look up with a single request.","title":"NOMINATIM_LOOKUP_MAX_COUNT"},{"location":"customize/Settings/#nominatim_polygon_output_max_types","text":"Summary Description: Number of different geometry formats that may be returned Format: integer Default: 1 After Changes: run nominatim refresh --website Nominatim supports returning full geometries of places. The geometries may be requested in different formats with one of the polygon_* parameters . Use this setting to restrict the number of geometry types that may be requested with a single query. Setting this parameter to 0 disables polygon output completely.","title":"NOMINATIM_POLYGON_OUTPUT_MAX_TYPES"},{"location":"customize/Settings/#logging-settings","text":"","title":"Logging Settings"},{"location":"customize/Settings/#nominatim_log_db","text":"Summary Description: Log requests into the database Format: boolean Default: no After Changes: run nominatim refresh --website Enable logging requests into a database table with this setting. The logs can be found in the table new_query_log . When using this logging method, it is advisable to set up a job that regularly clears out old logging information. Nominatim will not do that on its own. Can be used as the same time as NOMINATIM_LOG_FILE.","title":"NOMINATIM_LOG_DB"},{"location":"customize/Settings/#nominatim_log_file","text":"Summary Description: Log requests into a file Format: path Default: empty (logging disabled) After Changes: run nominatim refresh --website Enable logging of requests into a file with this setting by setting the log file where to log to. A relative file name is assumed to be relative to the project directory. The entries in the log file have the following format: <request time> <execution time in s> <number of results> <type> \"<query string>\" Request time is the time when the request was started. The execution time is given in ms and corresponds to the time the query took executing in PHP. type contains the name of the endpoint used. Can be used as the same time as NOMINATIM_LOG_DB.","title":"NOMINATIM_LOG_FILE"},{"location":"customize/Special-Phrases/","text":"Special phrases \uf0c1 Importing OSM user-maintained special phrases \uf0c1 As described in the Import section , it is possible to import special phrases from the wiki with the following command: nominatim special-phrases --import-from-wiki Importing custom special phrases \uf0c1 But, it is also possible to import some phrases from a csv file. To do so, you have access to the following command: nominatim special-phrases --import-from-csv <csv file> Note that the two previous import commands will update the phrases from your database. This means that if you import some phrases from a csv file, only the phrases present in the csv file will be kept into the database. All other phrases will be removed. If you want to only add new phrases and not update the other ones you can add the argument --no-replace to the import command. For example: nominatim special-phrases --import-from-csv <csv file> --no-replace This will add the phrases present in the csv file into the database without removing the other ones.","title":"Special Phrases"},{"location":"customize/Special-Phrases/#special-phrases","text":"","title":"Special phrases"},{"location":"customize/Special-Phrases/#importing-osm-user-maintained-special-phrases","text":"As described in the Import section , it is possible to import special phrases from the wiki with the following command: nominatim special-phrases --import-from-wiki","title":"Importing OSM user-maintained special phrases"},{"location":"customize/Special-Phrases/#importing-custom-special-phrases","text":"But, it is also possible to import some phrases from a csv file. To do so, you have access to the following command: nominatim special-phrases --import-from-csv <csv file> Note that the two previous import commands will update the phrases from your database. This means that if you import some phrases from a csv file, only the phrases present in the csv file will be kept into the database. All other phrases will be removed. If you want to only add new phrases and not update the other ones you can add the argument --no-replace to the import command. For example: nominatim special-phrases --import-from-csv <csv file> --no-replace This will add the phrases present in the csv file into the database without removing the other ones.","title":"Importing custom special phrases"},{"location":"customize/Tiger/","text":"Installing TIGER housenumber data for the US \uf0c1 Nominatim is able to use the official TIGER address set to complement the OSM house number data in the US. You can add TIGER data to your own Nominatim instance by following these steps. The entire US adds about 10GB to your database. Get preprocessed TIGER data: cd $PROJECT_DIR wget https://nominatim.org/data/tiger-nominatim-preprocessed-latest.csv.tar.gz Import the data into your Nominatim database: nominatim add-data --tiger-data tiger-nominatim-preprocessed-latest.csv.tar.gz Enable use of the Tiger data in your existing .env file by adding: echo NOMINATIM_USE_US_TIGER_DATA=yes >> .env Apply the new settings: nominatim refresh --functions --website See the TIGER-data project for more information on how the data got preprocessed.","title":"External data: US housenumbers from TIGER"},{"location":"customize/Tiger/#installing-tiger-housenumber-data-for-the-us","text":"Nominatim is able to use the official TIGER address set to complement the OSM house number data in the US. You can add TIGER data to your own Nominatim instance by following these steps. The entire US adds about 10GB to your database. Get preprocessed TIGER data: cd $PROJECT_DIR wget https://nominatim.org/data/tiger-nominatim-preprocessed-latest.csv.tar.gz Import the data into your Nominatim database: nominatim add-data --tiger-data tiger-nominatim-preprocessed-latest.csv.tar.gz Enable use of the Tiger data in your existing .env file by adding: echo NOMINATIM_USE_US_TIGER_DATA=yes >> .env Apply the new settings: nominatim refresh --functions --website See the TIGER-data project for more information on how the data got preprocessed.","title":"Installing TIGER housenumber data for the US"},{"location":"customize/Tokenizers/","text":"Tokenizers \uf0c1 The tokenizer module in Nominatim is responsible for analysing the names given to OSM objects and the terms of an incoming query in order to make sure, they can be matched appropriately. Nominatim offers different tokenizer modules, which behave differently and have different configuration options. This sections describes the tokenizers and how they can be configured. Important The use of a tokenizer is tied to a database installation. You need to choose and configure the tokenizer before starting the initial import. Once the import is done, you cannot switch to another tokenizer anymore. Reconfiguring the chosen tokenizer is very limited as well. See the comments in each tokenizer section. Legacy tokenizer \uf0c1 The legacy tokenizer implements the analysis algorithms of older Nominatim versions. It uses a special Postgresql module to normalize names and queries. This tokenizer is automatically installed and used when upgrading an older database. It should not be used for new installations anymore. Compiling the PostgreSQL module \uf0c1 The tokeinzer needs a special C module for PostgreSQL which is not compiled by default. If you need the legacy tokenizer, compile Nominatim as follows: mkdir build cd build cmake -DBUILD_MODULE=on make Enabling the tokenizer \uf0c1 To enable the tokenizer add the following line to your project configuration: NOMINATIM_TOKENIZER=legacy The Postgresql module for the tokenizer is available in the module directory and also installed with the remainder of the software under lib/nominatim/module/nominatim.so . You can specify a custom location for the module with NOMINATIM_DATABASE_MODULE_PATH=<path to directory where nominatim.so resides> This is in particular useful when the database runs on a different server. See Advanced installations for details. There are no other configuration options for the legacy tokenizer. All normalization functions are hard-coded. ICU tokenizer \uf0c1 The ICU tokenizer uses the ICU library to normalize names and queries. It also offers configurable decomposition and abbreviation handling. This tokenizer is currently the default. To enable the tokenizer add the following line to your project configuration: NOMINATIM_TOKENIZER=icu How it works \uf0c1 On import the tokenizer processes names in the following three stages: During the Sanitizer step incoming names are cleaned up and converted to full names . This step can be used to regularize spelling, split multi-name tags into their parts and tag names with additional attributes. See the Sanitizers section below for available cleaning routines. The Normalization part removes all information from the full names that are not relevant for search. The Token analysis step takes the normalized full names and creates all transliterated variants under which the name should be searchable. See the Token analysis section below for more information. During query time, only normalization and transliteration are relevant. An incoming query is first split into name chunks (this usually means splitting the string at the commas) and the each part is normalised and transliterated. The result is used to look up places in the search index. Configuration \uf0c1 The ICU tokenizer is configured using a YAML file which can be configured using NOMINATIM_TOKENIZER_CONFIG . The configuration is read on import and then saved as part of the internal database status. Later changes to the variable have no effect. Here is an example configuration file: normalization : - \":: lower ()\" - \"\u00df > 'ss'\" # German szet is unimbigiously equal to double ss transliteration : - !include /etc/nominatim/icu-rules/extended-unicode-to-asccii.yaml - \":: Ascii ()\" sanitizers : - step : split-name-list token-analysis : - analyzer : generic variants : - !include icu-rules/variants-ca.yaml - words : - road -> rd - bridge -> bdge,br,brdg,bri,brg mutations : - pattern : '\u00e4' replacements : [ '\u00e4' , 'ae' ] The configuration file contains four sections: normalization , transliteration , sanitizers and token-analysis . Normalization and Transliteration \uf0c1 The normalization and transliteration sections each define a set of ICU rules that are applied to the names. The normalisation rules are applied after sanitation. They should remove any information that is not relevant for search at all. Usual rules to be applied here are: lower-casing, removing of special characters, cleanup of spaces. The transliteration rules are applied at the end of the tokenization process to transfer the name into an ASCII representation. Transliteration can be useful to allow for further fuzzy matching, especially between different scripts. Each section must contain a list of ICU transformation rules . The rules are applied in the order in which they appear in the file. You can also include additional rules from external yaml file using the !include tag. The included file must contain a valid YAML list of ICU rules and may again include other files. Warning The ICU rule syntax contains special characters that conflict with the YAML syntax. You should therefore always enclose the ICU rules in double-quotes. Sanitizers \uf0c1 The sanitizers section defines an ordered list of functions that are applied to the name and address tags before they are further processed by the tokenizer. They allows to clean up the tagging and bring it to a standardized form more suitable for building the search index. Hint Sanitizers only have an effect on how the search index is built. They do not change the information about each place that is saved in the database. In particular, they have no influence on how the results are displayed. The returned results always show the original information as stored in the OpenStreetMap database. Each entry contains information of a sanitizer to be applied. It has a mandatory parameter step which gives the name of the sanitizer. Depending on the type, it may have additional parameters to configure its operation. The order of the list matters. The sanitizers are applied exactly in the order that is configured. Each sanitizer works on the results of the previous one. The following is a list of sanitizers that are shipped with Nominatim. split-name-list \uf0c1 Sanitizer that splits lists of names into their components. Parameters: delimiters \u2013 Define the set of characters to be used for splitting the list. (default: ',;') strip-brace-terms \uf0c1 This sanitizer creates additional name variants for names that have addendums in brackets (e.g. \"Halle (Saale)\"). The additional variant contains only the main name part with the bracket part removed. tag-analyzer-by-language \uf0c1 This sanitizer sets the analyzer property depending on the language of the tag. The language is taken from the suffix of the name. If a name already has an analyzer tagged, then this is kept. Parameters: filter-kind \u2013 Restrict the names the sanitizer should be applied to to the given tags. The parameter expects a list of regular expressions which are matched against 'kind'. Note that a match against the full string is expected. whitelist \u2013 Restrict the set of languages that should be tagged. Expects a list of acceptable suffixes. When unset, all 2- and 3-letter lower-case codes are accepted. use-defaults \u2013 Configure what happens when the name has no suffix. When set to 'all', a variant is created for each of the default languages in the country the feature is in. When set to 'mono', a variant is only created, when exactly one language is spoken in the country. The default is to do nothing with the default languages of a country. mode \u2013 Define how the variants are created and may be 'replace' or 'append'. When set to 'append' the original name (without any analyzer tagged) is retained. (default: replace) clean-housenumbers \uf0c1 Sanitizer that preprocesses address tags for house numbers. The sanitizer allows to define which tags are to be considered house numbers (see 'filter-kind') split house number lists into individual numbers (see 'delimiters') Parameters: delimiters \u2013 Define the set of characters to be used for splitting a list of house numbers into parts. (default: ',;') filter-kind \u2013 Define the address tags that are considered to be a house number. Either takes a single string or a list of strings, where each string is a regular expression. An address item is considered a house number if the 'kind' fully matches any of the given regular expressions. (default: 'housenumber') convert-to-name \u2013 Define house numbers that should be treated as a name instead of a house number. Either takes a single string or a list of strings, where each string is a regular expression that must match the full house number value. clean-postcodes \uf0c1 Sanitizer that filters postcodes by their officially allowed pattern. Parameters: convert-to-address \u2013 If set to 'yes' (the default), then postcodes that do not conform with their country-specific pattern are converted to an address component. That means that the postcode does not take part when computing the postcode centroids of a country but is still searchable. When set to 'no', non-conforming postcodes are not searchable either. default-pattern \u2013 Pattern to use, when there is none available for the country in question. Warning: will not be used for objects that have no country assigned. These are always assumed to have no postcode. Token Analysis \uf0c1 Token analyzers take a full name and transform it into one or more normalized form that are then saved in the search index. In its simplest form, the analyzer only applies the transliteration rules. More complex analyzers create additional spelling variants of a name. This is useful to handle decomposition and abbreviation. The ICU tokenizer may use different analyzers for different names. To select the analyzer to be used, the name must be tagged with the analyzer attribute by a sanitizer (see for example the tag-analyzer-by-language sanitizer ). The token-analysis section contains the list of configured analyzers. Each analyzer must have an id parameter that uniquely identifies the analyzer. The only exception is the default analyzer that is used when no special analyzer was selected. There are analysers with special ids: '@housenumber'. If an analyzer with that name is present, it is used for normalization of house numbers. '@potcode'. If an analyzer with that name is present, it is used for normalization of postcodes. Different analyzer implementations may exist. To select the implementation, the analyzer parameter must be set. The different implementations are described in the following. Generic token analyzer \uf0c1 The generic analyzer generic is able to create variants from a list of given abbreviation and decomposition replacements and introduce spelling variations. Variants \uf0c1 The optional 'variants' section defines lists of replacements which create alternative spellings of a name. To create the variants, a name is scanned from left to right and the longest matching replacement is applied until the end of the string is reached. The variants section must contain a list of replacement groups. Each group defines a set of properties that describes where the replacements are applicable. In addition, the word section defines the list of replacements to be made. The basic replacement description is of the form: <source>[,<source>[...]] => <target>[,<target>[...]] The left side contains one or more source terms to be replaced. The right side lists one or more replacements. Each source is replaced with each replacement term. Tip The source and target terms are internally normalized using the normalization rules given in the configuration. This ensures that the strings match as expected. In fact, it is better to use unnormalized words in the configuration because then it is possible to change the rules for normalization later without having to adapt the variant rules. Decomposition \uf0c1 In its standard form, only full words match against the source. There is a special notation to match the prefix and suffix of a word: - ~strasse => str # matches \"strasse\" as full word and in suffix position - hinter~ => hntr # matches \"hinter\" as full word and in prefix position There is no facility to match a string in the middle of the word. The suffix and prefix notation automatically trigger the decomposition mode: two variants are created for each replacement, one with the replacement attached to the word and one separate. So in above example, the tokenization of \"hauptstrasse\" will create the variants \"hauptstr\" and \"haupt str\". Similarly, the name \"rote strasse\" triggers the variants \"rote str\" and \"rotestr\". By having decomposition work both ways, it is sufficient to create the variants at index time. The variant rules are not applied at query time. To avoid automatic decomposition, use the '|' notation: - ~strasse |=> str simply changes \"hauptstrasse\" to \"hauptstr\" and \"rote strasse\" to \"rote str\". Initial and final terms \uf0c1 It is also possible to restrict replacements to the beginning and end of a name: - ^south => s # matches only at the beginning of the name - road$ => rd # matches only at the end of the name So the first example would trigger a replacement for \"south 45th street\" but not for \"the south beach restaurant\". Replacements vs. variants \uf0c1 The replacement syntax source => target works as a pure replacement. It changes the name instead of creating a variant. To create an additional version, you'd have to write source => source,target . As this is a frequent case, there is a shortcut notation for it: <source>[,<source>[...]] -> <target>[,<target>[...]] The simple arrow causes an additional variant to be added. Note that decomposition has an effect here on the source as well. So a rule - \"~strasse -> str\" means that for a word like hauptstrasse four variants are created: hauptstrasse , haupt strasse , hauptstr and haupt str . Mutations \uf0c1 The 'mutation' section in the configuration describes an additional set of replacements to be applied after the variants have been computed. Each mutation is described by two parameters: pattern and replacements . The pattern must contain a single regular expression to search for in the variant name. The regular expressions need to follow the syntax for Python regular expressions . Capturing groups are not permitted. replacements must contain a list of strings that the pattern should be replaced with. Each occurrence of the pattern is replaced with all given replacements. Be mindful of combinatorial explosion of variants. Modes \uf0c1 The generic analyser supports a special mode variant-only . When configured then it consumes the input token and emits only variants (if any exist). Enable the mode by adding: mode : variant - only to the analyser configuration. Housenumber token analyzer \uf0c1 The analyzer housenumbers is purpose-made to analyze house numbers. It creates variants with optional spaces between numbers and letters. Thus, house numbers of the form '3 a', '3A', '3-A' etc. are all considered equivalent. The analyzer cannot be customized. Postcode token analyzer \uf0c1 The analyzer postcodes is pupose-made to analyze postcodes. It supports a 'lookup' varaint of the token, which produces variants with optional spaces. Use together with the clean-postcodes sanitizer. The analyzer cannot be customized. Reconfiguration \uf0c1 Changing the configuration after the import is currently not possible, although this feature may be added at a later time.","title":"Tokenizers"},{"location":"customize/Tokenizers/#tokenizers","text":"The tokenizer module in Nominatim is responsible for analysing the names given to OSM objects and the terms of an incoming query in order to make sure, they can be matched appropriately. Nominatim offers different tokenizer modules, which behave differently and have different configuration options. This sections describes the tokenizers and how they can be configured. Important The use of a tokenizer is tied to a database installation. You need to choose and configure the tokenizer before starting the initial import. Once the import is done, you cannot switch to another tokenizer anymore. Reconfiguring the chosen tokenizer is very limited as well. See the comments in each tokenizer section.","title":"Tokenizers"},{"location":"customize/Tokenizers/#legacy-tokenizer","text":"The legacy tokenizer implements the analysis algorithms of older Nominatim versions. It uses a special Postgresql module to normalize names and queries. This tokenizer is automatically installed and used when upgrading an older database. It should not be used for new installations anymore.","title":"Legacy tokenizer"},{"location":"customize/Tokenizers/#compiling-the-postgresql-module","text":"The tokeinzer needs a special C module for PostgreSQL which is not compiled by default. If you need the legacy tokenizer, compile Nominatim as follows: mkdir build cd build cmake -DBUILD_MODULE=on make","title":"Compiling the PostgreSQL module"},{"location":"customize/Tokenizers/#enabling-the-tokenizer","text":"To enable the tokenizer add the following line to your project configuration: NOMINATIM_TOKENIZER=legacy The Postgresql module for the tokenizer is available in the module directory and also installed with the remainder of the software under lib/nominatim/module/nominatim.so . You can specify a custom location for the module with NOMINATIM_DATABASE_MODULE_PATH=<path to directory where nominatim.so resides> This is in particular useful when the database runs on a different server. See Advanced installations for details. There are no other configuration options for the legacy tokenizer. All normalization functions are hard-coded.","title":"Enabling the tokenizer"},{"location":"customize/Tokenizers/#icu-tokenizer","text":"The ICU tokenizer uses the ICU library to normalize names and queries. It also offers configurable decomposition and abbreviation handling. This tokenizer is currently the default. To enable the tokenizer add the following line to your project configuration: NOMINATIM_TOKENIZER=icu","title":"ICU tokenizer"},{"location":"customize/Tokenizers/#how-it-works","text":"On import the tokenizer processes names in the following three stages: During the Sanitizer step incoming names are cleaned up and converted to full names . This step can be used to regularize spelling, split multi-name tags into their parts and tag names with additional attributes. See the Sanitizers section below for available cleaning routines. The Normalization part removes all information from the full names that are not relevant for search. The Token analysis step takes the normalized full names and creates all transliterated variants under which the name should be searchable. See the Token analysis section below for more information. During query time, only normalization and transliteration are relevant. An incoming query is first split into name chunks (this usually means splitting the string at the commas) and the each part is normalised and transliterated. The result is used to look up places in the search index.","title":"How it works"},{"location":"customize/Tokenizers/#configuration","text":"The ICU tokenizer is configured using a YAML file which can be configured using NOMINATIM_TOKENIZER_CONFIG . The configuration is read on import and then saved as part of the internal database status. Later changes to the variable have no effect. Here is an example configuration file: normalization : - \":: lower ()\" - \"\u00df > 'ss'\" # German szet is unimbigiously equal to double ss transliteration : - !include /etc/nominatim/icu-rules/extended-unicode-to-asccii.yaml - \":: Ascii ()\" sanitizers : - step : split-name-list token-analysis : - analyzer : generic variants : - !include icu-rules/variants-ca.yaml - words : - road -> rd - bridge -> bdge,br,brdg,bri,brg mutations : - pattern : '\u00e4' replacements : [ '\u00e4' , 'ae' ] The configuration file contains four sections: normalization , transliteration , sanitizers and token-analysis .","title":"Configuration"},{"location":"customize/Tokenizers/#normalization-and-transliteration","text":"The normalization and transliteration sections each define a set of ICU rules that are applied to the names. The normalisation rules are applied after sanitation. They should remove any information that is not relevant for search at all. Usual rules to be applied here are: lower-casing, removing of special characters, cleanup of spaces. The transliteration rules are applied at the end of the tokenization process to transfer the name into an ASCII representation. Transliteration can be useful to allow for further fuzzy matching, especially between different scripts. Each section must contain a list of ICU transformation rules . The rules are applied in the order in which they appear in the file. You can also include additional rules from external yaml file using the !include tag. The included file must contain a valid YAML list of ICU rules and may again include other files. Warning The ICU rule syntax contains special characters that conflict with the YAML syntax. You should therefore always enclose the ICU rules in double-quotes.","title":"Normalization and Transliteration"},{"location":"customize/Tokenizers/#sanitizers","text":"The sanitizers section defines an ordered list of functions that are applied to the name and address tags before they are further processed by the tokenizer. They allows to clean up the tagging and bring it to a standardized form more suitable for building the search index. Hint Sanitizers only have an effect on how the search index is built. They do not change the information about each place that is saved in the database. In particular, they have no influence on how the results are displayed. The returned results always show the original information as stored in the OpenStreetMap database. Each entry contains information of a sanitizer to be applied. It has a mandatory parameter step which gives the name of the sanitizer. Depending on the type, it may have additional parameters to configure its operation. The order of the list matters. The sanitizers are applied exactly in the order that is configured. Each sanitizer works on the results of the previous one. The following is a list of sanitizers that are shipped with Nominatim.","title":"Sanitizers"},{"location":"customize/Tokenizers/#split-name-list","text":"Sanitizer that splits lists of names into their components. Parameters: delimiters \u2013 Define the set of characters to be used for splitting the list. (default: ',;')","title":"split-name-list"},{"location":"customize/Tokenizers/#strip-brace-terms","text":"This sanitizer creates additional name variants for names that have addendums in brackets (e.g. \"Halle (Saale)\"). The additional variant contains only the main name part with the bracket part removed.","title":"strip-brace-terms"},{"location":"customize/Tokenizers/#tag-analyzer-by-language","text":"This sanitizer sets the analyzer property depending on the language of the tag. The language is taken from the suffix of the name. If a name already has an analyzer tagged, then this is kept. Parameters: filter-kind \u2013 Restrict the names the sanitizer should be applied to to the given tags. The parameter expects a list of regular expressions which are matched against 'kind'. Note that a match against the full string is expected. whitelist \u2013 Restrict the set of languages that should be tagged. Expects a list of acceptable suffixes. When unset, all 2- and 3-letter lower-case codes are accepted. use-defaults \u2013 Configure what happens when the name has no suffix. When set to 'all', a variant is created for each of the default languages in the country the feature is in. When set to 'mono', a variant is only created, when exactly one language is spoken in the country. The default is to do nothing with the default languages of a country. mode \u2013 Define how the variants are created and may be 'replace' or 'append'. When set to 'append' the original name (without any analyzer tagged) is retained. (default: replace)","title":"tag-analyzer-by-language"},{"location":"customize/Tokenizers/#clean-housenumbers","text":"Sanitizer that preprocesses address tags for house numbers. The sanitizer allows to define which tags are to be considered house numbers (see 'filter-kind') split house number lists into individual numbers (see 'delimiters') Parameters: delimiters \u2013 Define the set of characters to be used for splitting a list of house numbers into parts. (default: ',;') filter-kind \u2013 Define the address tags that are considered to be a house number. Either takes a single string or a list of strings, where each string is a regular expression. An address item is considered a house number if the 'kind' fully matches any of the given regular expressions. (default: 'housenumber') convert-to-name \u2013 Define house numbers that should be treated as a name instead of a house number. Either takes a single string or a list of strings, where each string is a regular expression that must match the full house number value.","title":"clean-housenumbers"},{"location":"customize/Tokenizers/#clean-postcodes","text":"Sanitizer that filters postcodes by their officially allowed pattern. Parameters: convert-to-address \u2013 If set to 'yes' (the default), then postcodes that do not conform with their country-specific pattern are converted to an address component. That means that the postcode does not take part when computing the postcode centroids of a country but is still searchable. When set to 'no', non-conforming postcodes are not searchable either. default-pattern \u2013 Pattern to use, when there is none available for the country in question. Warning: will not be used for objects that have no country assigned. These are always assumed to have no postcode.","title":"clean-postcodes"},{"location":"customize/Tokenizers/#token-analysis","text":"Token analyzers take a full name and transform it into one or more normalized form that are then saved in the search index. In its simplest form, the analyzer only applies the transliteration rules. More complex analyzers create additional spelling variants of a name. This is useful to handle decomposition and abbreviation. The ICU tokenizer may use different analyzers for different names. To select the analyzer to be used, the name must be tagged with the analyzer attribute by a sanitizer (see for example the tag-analyzer-by-language sanitizer ). The token-analysis section contains the list of configured analyzers. Each analyzer must have an id parameter that uniquely identifies the analyzer. The only exception is the default analyzer that is used when no special analyzer was selected. There are analysers with special ids: '@housenumber'. If an analyzer with that name is present, it is used for normalization of house numbers. '@potcode'. If an analyzer with that name is present, it is used for normalization of postcodes. Different analyzer implementations may exist. To select the implementation, the analyzer parameter must be set. The different implementations are described in the following.","title":"Token Analysis"},{"location":"customize/Tokenizers/#generic-token-analyzer","text":"The generic analyzer generic is able to create variants from a list of given abbreviation and decomposition replacements and introduce spelling variations.","title":"Generic token analyzer"},{"location":"customize/Tokenizers/#variants","text":"The optional 'variants' section defines lists of replacements which create alternative spellings of a name. To create the variants, a name is scanned from left to right and the longest matching replacement is applied until the end of the string is reached. The variants section must contain a list of replacement groups. Each group defines a set of properties that describes where the replacements are applicable. In addition, the word section defines the list of replacements to be made. The basic replacement description is of the form: <source>[,<source>[...]] => <target>[,<target>[...]] The left side contains one or more source terms to be replaced. The right side lists one or more replacements. Each source is replaced with each replacement term. Tip The source and target terms are internally normalized using the normalization rules given in the configuration. This ensures that the strings match as expected. In fact, it is better to use unnormalized words in the configuration because then it is possible to change the rules for normalization later without having to adapt the variant rules.","title":"Variants"},{"location":"customize/Tokenizers/#decomposition","text":"In its standard form, only full words match against the source. There is a special notation to match the prefix and suffix of a word: - ~strasse => str # matches \"strasse\" as full word and in suffix position - hinter~ => hntr # matches \"hinter\" as full word and in prefix position There is no facility to match a string in the middle of the word. The suffix and prefix notation automatically trigger the decomposition mode: two variants are created for each replacement, one with the replacement attached to the word and one separate. So in above example, the tokenization of \"hauptstrasse\" will create the variants \"hauptstr\" and \"haupt str\". Similarly, the name \"rote strasse\" triggers the variants \"rote str\" and \"rotestr\". By having decomposition work both ways, it is sufficient to create the variants at index time. The variant rules are not applied at query time. To avoid automatic decomposition, use the '|' notation: - ~strasse |=> str simply changes \"hauptstrasse\" to \"hauptstr\" and \"rote strasse\" to \"rote str\".","title":"Decomposition"},{"location":"customize/Tokenizers/#initial-and-final-terms","text":"It is also possible to restrict replacements to the beginning and end of a name: - ^south => s # matches only at the beginning of the name - road$ => rd # matches only at the end of the name So the first example would trigger a replacement for \"south 45th street\" but not for \"the south beach restaurant\".","title":"Initial and final terms"},{"location":"customize/Tokenizers/#replacements-vs-variants","text":"The replacement syntax source => target works as a pure replacement. It changes the name instead of creating a variant. To create an additional version, you'd have to write source => source,target . As this is a frequent case, there is a shortcut notation for it: <source>[,<source>[...]] -> <target>[,<target>[...]] The simple arrow causes an additional variant to be added. Note that decomposition has an effect here on the source as well. So a rule - \"~strasse -> str\" means that for a word like hauptstrasse four variants are created: hauptstrasse , haupt strasse , hauptstr and haupt str .","title":"Replacements vs. variants"},{"location":"customize/Tokenizers/#mutations","text":"The 'mutation' section in the configuration describes an additional set of replacements to be applied after the variants have been computed. Each mutation is described by two parameters: pattern and replacements . The pattern must contain a single regular expression to search for in the variant name. The regular expressions need to follow the syntax for Python regular expressions . Capturing groups are not permitted. replacements must contain a list of strings that the pattern should be replaced with. Each occurrence of the pattern is replaced with all given replacements. Be mindful of combinatorial explosion of variants.","title":"Mutations"},{"location":"customize/Tokenizers/#modes","text":"The generic analyser supports a special mode variant-only . When configured then it consumes the input token and emits only variants (if any exist). Enable the mode by adding: mode : variant - only to the analyser configuration.","title":"Modes"},{"location":"customize/Tokenizers/#housenumber-token-analyzer","text":"The analyzer housenumbers is purpose-made to analyze house numbers. It creates variants with optional spaces between numbers and letters. Thus, house numbers of the form '3 a', '3A', '3-A' etc. are all considered equivalent. The analyzer cannot be customized.","title":"Housenumber token analyzer"},{"location":"customize/Tokenizers/#postcode-token-analyzer","text":"The analyzer postcodes is pupose-made to analyze postcodes. It supports a 'lookup' varaint of the token, which produces variants with optional spaces. Use together with the clean-postcodes sanitizer. The analyzer cannot be customized.","title":"Postcode token analyzer"},{"location":"customize/Tokenizers/#reconfiguration","text":"Changing the configuration after the import is currently not possible, although this feature may be added at a later time.","title":"Reconfiguration"},{"location":"develop/Database-Layout/","text":"Database Layout \uf0c1 Import tables \uf0c1 OSM data is initially imported using osm2pgsql . Nominatim uses its own data output style 'gazetteer', which differs from the output style created for map rendering. The import process creates the following tables: The planet_osm_* tables are the usual backing tables for OSM data. Note that Nominatim uses them to look up special relations and to find nodes on ways. The gazetteer style produces a single table place as output with the following columns: osm_type - kind of OSM object ( N - node, W - way, R - relation) osm_id - original OSM ID class - key of principal tag defining the object type type - value of principal tag defining the object type name - collection of tags that contain a name or reference admin_level - numerical value of the tagged administrative level address - collection of tags defining the address of an object extratags - collection of additional interesting tags that are not directly relevant for searching geometry - geometry of the object (in WGS84) A single OSM object may appear multiple times in this table when it is tagged with multiple tags that may constitute a principal tag. Take for example a motorway bridge. In OSM, this would be a way which is tagged with highway=motorway and bridge=yes . This way would appear in the place table once with class of highway and once with a class of bridge . Thus the unique key for place is ( osm_type , osm_id , class ). How raw OSM tags are mapped to the columns in the place table is to a certain degree configurable. See Customizing Import Styles for more information. Search tables \uf0c1 The following tables carry all information needed to do the search: The placex table is the central table that saves all information about the searchable places in Nominatim. The basic columns are the same as for the place table and have the same meaning. The placex tables adds the following additional columns: place_id - the internal unique ID to identify the place partition - the id to use with partitioned tables (see below) geometry_sector - a location hash used for geographically close ordering parent_place_id - the next higher place in the address hierarchy, only relevant for POI-type places (with rank 30) linked_place_id - place ID of the place this object has been merged with. When this ID is set, then the place is invisible for search. importance - measure how well known the place is rank_search , rank_address - search and address rank (see Customizing ranking wikipedia - the wikipedia page used for computing the importance of the place country_code - the country the place is located in housenumber - normalized housenumber, if the place has one postcode - computed postcode for the place indexed_status - processing status of the place (0 - ready, 1 - freshly inserted, 2 - needs updating, 100 - needs deletion) indexed_date - timestamp when the place was processed last centroid - a point feature for the place The location_property_osmline table is a special table for address interpolations . The columns have the same meaning and use as the columns with the same name in the placex table. Only three columns are special: startnumber and endnumber - beginning and end of the number range for the interpolation interpolationtype - a string odd , even or all to indicate the interval between the numbers Address interpolations are always ways in OSM, which is why there is no column osm_type . The location_postcode table holds computed centroids of all postcodes that can be found in the OSM data. The meaning of the columns is again the same as that of the placex table. Every place needs an address, a set of surrounding places that describe the location of the place. The set of address places is made up of OSM places themselves. The place_addressline table cross-references for each place all the places that make up its address. Two columns define the address relation: place_id - reference to the place being addressed address_place_id - reference to the place serving as an address part The most of the columns cache information from the placex entry of the address part. The exceptions are: fromarea - is true if the address part has an area geometry and can therefore be considered preceise isaddress - is true if the address part should show up in the address output. Sometimes there are multiple places competing for for same address type (e.g. multiple cities) and this field resolves the tie. The search_name table contains the search index proper. It saves for each place the terms with which the place can be found. The terms are split into the name itself and all terms that make up the address. The table mirrors some of the columns from placex for faster lookup. Search terms are not saved as strings. Each term is assigned an integer and those integers are saved in the name and address vectors of the search_name table. The word table serves as the lookup table from string to such a word ID. The exact content of the word table depends on the tokenizer used. Address computation tables \uf0c1 Next to the main search tables, there is a set of secondary helper tables used to compute the address relations between places. These tables are partitioned. Each country is assigned a partition number in the country_name table (see below) and the data is then split between a set of tables, one for each partition. Note that Nominatim still manually manages partitioned tables. Native support for partitions in PostgreSQL only became usable with version 13. It will be a little while before Nominatim drops support for older versions. The search_name_X tables are used to look up streets that appear in the addr:street tag. The location_area_large_X tables are used to look up larger areas (administrative boundaries and place nodes) either through their geographic closeness or through addr:* entries. The location_road_X tables are used to find the closest street for a dependent place. All three table cache specific information from the placex table for their selected subset of places: keywords and name_vector contain lists of term ids (from the word table) that the full name of the place should match against isguess is true for places that are not described by an area All other columns reflect their counterpart in the placex table. Static data tables \uf0c1 Nominatim also creates a number of static tables at import: nominatim_properties saves settings that must not be changed after import address_levels save the rank information from the ranking configuration country_name contains a fallback of names for all countries, their default languages and saves the assignment of countries to partitions. country_osm_grid provides a fallback for country geometries Auxiliary data tables \uf0c1 Finally there are some table for auxiliary data: location_property_tiger - saves housenumber from the Tiger import. Its layout is similar to that of location_propoerty_osmline . place_class_* tables are helper tables to facilitate lookup of POIs by their class and type. They exist because it is not possible to create combined indexes with geometries.","title":"Database Layout"},{"location":"develop/Database-Layout/#database-layout","text":"","title":"Database Layout"},{"location":"develop/Database-Layout/#import-tables","text":"OSM data is initially imported using osm2pgsql . Nominatim uses its own data output style 'gazetteer', which differs from the output style created for map rendering. The import process creates the following tables: The planet_osm_* tables are the usual backing tables for OSM data. Note that Nominatim uses them to look up special relations and to find nodes on ways. The gazetteer style produces a single table place as output with the following columns: osm_type - kind of OSM object ( N - node, W - way, R - relation) osm_id - original OSM ID class - key of principal tag defining the object type type - value of principal tag defining the object type name - collection of tags that contain a name or reference admin_level - numerical value of the tagged administrative level address - collection of tags defining the address of an object extratags - collection of additional interesting tags that are not directly relevant for searching geometry - geometry of the object (in WGS84) A single OSM object may appear multiple times in this table when it is tagged with multiple tags that may constitute a principal tag. Take for example a motorway bridge. In OSM, this would be a way which is tagged with highway=motorway and bridge=yes . This way would appear in the place table once with class of highway and once with a class of bridge . Thus the unique key for place is ( osm_type , osm_id , class ). How raw OSM tags are mapped to the columns in the place table is to a certain degree configurable. See Customizing Import Styles for more information.","title":"Import tables"},{"location":"develop/Database-Layout/#search-tables","text":"The following tables carry all information needed to do the search: The placex table is the central table that saves all information about the searchable places in Nominatim. The basic columns are the same as for the place table and have the same meaning. The placex tables adds the following additional columns: place_id - the internal unique ID to identify the place partition - the id to use with partitioned tables (see below) geometry_sector - a location hash used for geographically close ordering parent_place_id - the next higher place in the address hierarchy, only relevant for POI-type places (with rank 30) linked_place_id - place ID of the place this object has been merged with. When this ID is set, then the place is invisible for search. importance - measure how well known the place is rank_search , rank_address - search and address rank (see Customizing ranking wikipedia - the wikipedia page used for computing the importance of the place country_code - the country the place is located in housenumber - normalized housenumber, if the place has one postcode - computed postcode for the place indexed_status - processing status of the place (0 - ready, 1 - freshly inserted, 2 - needs updating, 100 - needs deletion) indexed_date - timestamp when the place was processed last centroid - a point feature for the place The location_property_osmline table is a special table for address interpolations . The columns have the same meaning and use as the columns with the same name in the placex table. Only three columns are special: startnumber and endnumber - beginning and end of the number range for the interpolation interpolationtype - a string odd , even or all to indicate the interval between the numbers Address interpolations are always ways in OSM, which is why there is no column osm_type . The location_postcode table holds computed centroids of all postcodes that can be found in the OSM data. The meaning of the columns is again the same as that of the placex table. Every place needs an address, a set of surrounding places that describe the location of the place. The set of address places is made up of OSM places themselves. The place_addressline table cross-references for each place all the places that make up its address. Two columns define the address relation: place_id - reference to the place being addressed address_place_id - reference to the place serving as an address part The most of the columns cache information from the placex entry of the address part. The exceptions are: fromarea - is true if the address part has an area geometry and can therefore be considered preceise isaddress - is true if the address part should show up in the address output. Sometimes there are multiple places competing for for same address type (e.g. multiple cities) and this field resolves the tie. The search_name table contains the search index proper. It saves for each place the terms with which the place can be found. The terms are split into the name itself and all terms that make up the address. The table mirrors some of the columns from placex for faster lookup. Search terms are not saved as strings. Each term is assigned an integer and those integers are saved in the name and address vectors of the search_name table. The word table serves as the lookup table from string to such a word ID. The exact content of the word table depends on the tokenizer used.","title":"Search tables"},{"location":"develop/Database-Layout/#address-computation-tables","text":"Next to the main search tables, there is a set of secondary helper tables used to compute the address relations between places. These tables are partitioned. Each country is assigned a partition number in the country_name table (see below) and the data is then split between a set of tables, one for each partition. Note that Nominatim still manually manages partitioned tables. Native support for partitions in PostgreSQL only became usable with version 13. It will be a little while before Nominatim drops support for older versions. The search_name_X tables are used to look up streets that appear in the addr:street tag. The location_area_large_X tables are used to look up larger areas (administrative boundaries and place nodes) either through their geographic closeness or through addr:* entries. The location_road_X tables are used to find the closest street for a dependent place. All three table cache specific information from the placex table for their selected subset of places: keywords and name_vector contain lists of term ids (from the word table) that the full name of the place should match against isguess is true for places that are not described by an area All other columns reflect their counterpart in the placex table.","title":"Address computation tables"},{"location":"develop/Database-Layout/#static-data-tables","text":"Nominatim also creates a number of static tables at import: nominatim_properties saves settings that must not be changed after import address_levels save the rank information from the ranking configuration country_name contains a fallback of names for all countries, their default languages and saves the assignment of countries to partitions. country_osm_grid provides a fallback for country geometries","title":"Static data tables"},{"location":"develop/Database-Layout/#auxiliary-data-tables","text":"Finally there are some table for auxiliary data: location_property_tiger - saves housenumber from the Tiger import. Its layout is similar to that of location_propoerty_osmline . place_class_* tables are helper tables to facilitate lookup of POIs by their class and type. They exist because it is not possible to create combined indexes with geometries.","title":"Auxiliary data tables"},{"location":"develop/Development-Environment/","text":"Setting up Nominatim for Development \uf0c1 This chapter gives an overview how to set up Nominatim for development and how to run tests. Important This guide assumes that you develop under the latest version of Ubuntu. You can of course also use your favourite distribution. You just might have to adapt the commands below slightly, in particular the commands for installing additional software. Installing Nominatim \uf0c1 The first step is to install Nominatim itself. Please follow the installation instructions in the Admin section . You don't need to set up a webserver for development, the webserver that is included with PHP is sufficient. If you want to run Nominatim in a VM via Vagrant, use the default ubuntu setup. Vagrant's libvirt provider runs out-of-the-box under Ubuntu. You also need to install an NFS daemon to enable directory sharing between host and guest. The following packages should get you started: sudo apt install vagrant vagrant-libvirt libvirt-daemon nfs-kernel-server Prerequisites for testing and documentation \uf0c1 The Nominatim test suite consists of behavioural tests (using behave) and unit tests (using PHPUnit for PHP code and pytest for Python code). It has the following additional requirements: behave test framework >= 1.2.6 phpunit (9.5 is known to work) PHP CodeSniffer Pylint (CI always runs the latest version from pip) mypy (plus typing information for external libs) Python Typing Extensions (for Python < 3.9) pytest The documentation is built with mkdocs: mkdocs >= 1.1.2 mkdocstrings >= 0.16 mkdocstrings-python-legacy Installing prerequisites on Ubuntu/Debian \uf0c1 Some of the Python packages require the newest version which is not yet available with the current distributions. Therefore it is recommended to install pip to get the newest versions. To install all necessary packages run: sudo apt install php-cgi phpunit php-codesniffer \\ python3-pip python3-setuptools python3-dev pip3 install --user behave mkdocs mkdocstrings pytest pylint \\ mypy types-PyYAML types-jinja2 types-psycopg2 types-psutil The mkdocs executable will be located in .local/bin . You may have to add this directory to your path, for example by running: echo 'export PATH=~/.local/bin:$PATH' > ~/. profile If your distribution does not have PHPUnit 7.3+, you can install it (as well as CodeSniffer) via composer: sudo apt-get install composer composer global require \"squizlabs/php_codesniffer=*\" composer global require \"phpunit/phpunit=8.*\" The binaries are found in .config/composer/vendor/bin . You need to add this to your PATH as well: echo 'export PATH=~/.config/composer/vendor/bin:$PATH' > ~/. profile Executing Tests \uf0c1 All tests are located in the /test directory. To run all tests just go to the build directory and run make: cd build make test For more information about the structure of the tests and how to change and extend the test suite, see the Testing chapter . Documentation Pages \uf0c1 The Nominatim documentation is built using the MkDocs static site generation framework. The master branch is automatically deployed every night on https://nominatim.org/release-docs/develop/ To build the documentation, go to the build directory and run make doc INFO - Cleaning site directory INFO - Building documentation to directory: /home/vagrant/build/site-html This runs mkdocs build plus extra transformation of some files and adds symlinks (see CMakeLists.txt for the exact steps). Now you can start webserver for local testing build> make serve-doc [server:296] Serving on http://127.0.0.1:8000 [handlers:62] Start watching changes If you develop inside a Vagrant virtual machine, use a port that is forwarded to your host: build> PYTHONPATH=$SRCDIR mkdocs serve --dev-addr 0.0.0.0:8088 [server:296] Serving on http://0.0.0.0:8088 [handlers:62] Start watching changes","title":"Setup for Development"},{"location":"develop/Development-Environment/#setting-up-nominatim-for-development","text":"This chapter gives an overview how to set up Nominatim for development and how to run tests. Important This guide assumes that you develop under the latest version of Ubuntu. You can of course also use your favourite distribution. You just might have to adapt the commands below slightly, in particular the commands for installing additional software.","title":"Setting up Nominatim for Development"},{"location":"develop/Development-Environment/#installing-nominatim","text":"The first step is to install Nominatim itself. Please follow the installation instructions in the Admin section . You don't need to set up a webserver for development, the webserver that is included with PHP is sufficient. If you want to run Nominatim in a VM via Vagrant, use the default ubuntu setup. Vagrant's libvirt provider runs out-of-the-box under Ubuntu. You also need to install an NFS daemon to enable directory sharing between host and guest. The following packages should get you started: sudo apt install vagrant vagrant-libvirt libvirt-daemon nfs-kernel-server","title":"Installing Nominatim"},{"location":"develop/Development-Environment/#prerequisites-for-testing-and-documentation","text":"The Nominatim test suite consists of behavioural tests (using behave) and unit tests (using PHPUnit for PHP code and pytest for Python code). It has the following additional requirements: behave test framework >= 1.2.6 phpunit (9.5 is known to work) PHP CodeSniffer Pylint (CI always runs the latest version from pip) mypy (plus typing information for external libs) Python Typing Extensions (for Python < 3.9) pytest The documentation is built with mkdocs: mkdocs >= 1.1.2 mkdocstrings >= 0.16 mkdocstrings-python-legacy","title":"Prerequisites for testing and documentation"},{"location":"develop/Development-Environment/#installing-prerequisites-on-ubuntudebian","text":"Some of the Python packages require the newest version which is not yet available with the current distributions. Therefore it is recommended to install pip to get the newest versions. To install all necessary packages run: sudo apt install php-cgi phpunit php-codesniffer \\ python3-pip python3-setuptools python3-dev pip3 install --user behave mkdocs mkdocstrings pytest pylint \\ mypy types-PyYAML types-jinja2 types-psycopg2 types-psutil The mkdocs executable will be located in .local/bin . You may have to add this directory to your path, for example by running: echo 'export PATH=~/.local/bin:$PATH' > ~/. profile If your distribution does not have PHPUnit 7.3+, you can install it (as well as CodeSniffer) via composer: sudo apt-get install composer composer global require \"squizlabs/php_codesniffer=*\" composer global require \"phpunit/phpunit=8.*\" The binaries are found in .config/composer/vendor/bin . You need to add this to your PATH as well: echo 'export PATH=~/.config/composer/vendor/bin:$PATH' > ~/. profile","title":"Installing prerequisites on Ubuntu/Debian"},{"location":"develop/Development-Environment/#executing-tests","text":"All tests are located in the /test directory. To run all tests just go to the build directory and run make: cd build make test For more information about the structure of the tests and how to change and extend the test suite, see the Testing chapter .","title":"Executing Tests"},{"location":"develop/Development-Environment/#documentation-pages","text":"The Nominatim documentation is built using the MkDocs static site generation framework. The master branch is automatically deployed every night on https://nominatim.org/release-docs/develop/ To build the documentation, go to the build directory and run make doc INFO - Cleaning site directory INFO - Building documentation to directory: /home/vagrant/build/site-html This runs mkdocs build plus extra transformation of some files and adds symlinks (see CMakeLists.txt for the exact steps). Now you can start webserver for local testing build> make serve-doc [server:296] Serving on http://127.0.0.1:8000 [handlers:62] Start watching changes If you develop inside a Vagrant virtual machine, use a port that is forwarded to your host: build> PYTHONPATH=$SRCDIR mkdocs serve --dev-addr 0.0.0.0:8088 [server:296] Serving on http://0.0.0.0:8088 [handlers:62] Start watching changes","title":"Documentation Pages"},{"location":"develop/ICU-Tokenizer-Modules/","text":"Writing custom sanitizer and token analysis modules for the ICU tokenizer \uf0c1 The ICU tokenizer provides a highly customizable method to pre-process and normalize the name information of the input data before it is added to the search index. It comes with a selection of sanitizers and token analyzers which you can use to adapt your installation to your needs. If the provided modules are not enough, you can also provide your own implementations. This section describes the API of sanitizers and token analysis. Warning This API is currently in early alpha status. While this API is meant to be a public API on which other sanitizers and token analyzers may be implemented, it is not guaranteed to be stable at the moment. Using non-standard sanitizers and token analyzers \uf0c1 Sanitizer names (in the step property) and token analysis names (in the analyzer ) may refer to externally supplied modules. There are two ways to include external modules: through a library or from the project directory. To include a module from a library, use the absolute import path as name and make sure the library can be found in your PYTHONPATH. To use a custom module without creating a library, you can put the module somewhere in your project directory and then use the relative path to the file. Include the whole name of the file including the .py ending. Custom sanitizer modules \uf0c1 A sanitizer module must export a single factory function create with the following signature: def create ( config : SanitizerConfig ) -> Callable [[ ProcessInfo ], None ] The function receives the custom configuration for the sanitizer and must return a callable (function or class) that transforms the name and address terms of a place. When a place is processed, then a ProcessInfo object is created from the information that was queried from the database. This object is sequentially handed to each configured sanitizer, so that each sanitizer receives the result of processing from the previous sanitizer. After the last sanitizer is finished, the resulting name and address lists are forwarded to the token analysis module. Sanitizer functions are instantiated once and then called for each place that is imported or updated. They don't need to be thread-safe. If multi-threading is used, each thread creates their own instance of the function. Sanitizer configuration \uf0c1 The SanitizerConfig class is a read-only dictionary with configuration options for the sanitizer. In addition to the usual dictionary functions, the class provides accessors to standard sanitizer options that are used by many of the sanitizers. get_bool ( self , param , default = None ) \uf0c1 Extract a configuration parameter as a boolean. Parameters: param ( str ) \u2013 Name of the configuration parameter. The parameter must contain one of the yaml boolean values or an UsageError will be raised. default ( Optional[bool] ) \u2013 Value to return, when the parameter is missing. When set to None , the parameter must be defined. Returns: bool \u2013 Boolean value of the given parameter. get_delimiter ( self , default = ',;' ) \uf0c1 Return the 'delimiters' parameter in the configuration as a compiled regular expression that can be used to split strings on these delimiters. Parameters: default ( str ) \u2013 Delimiters to be used when 'delimiters' parameter is not explicitly configured. Returns: Pattern[str] \u2013 A regular expression pattern which can be used to split a string. The regular expression makes sure that the resulting names are stripped and that repeated delimiters are ignored. It may still create empty fields on occasion. The code needs to filter those. get_filter_kind ( self , * default ) \uf0c1 Return a filter function for the name kind from the 'filter-kind' config parameter. If the 'filter-kind' parameter is empty, the filter lets all items pass. If the parameter is a string, it is interpreted as a single regular expression that must match the full kind string. If the parameter is a list then any of the regular expressions in the list must match to pass. Parameters: default ( str ) \u2013 Filters to be used, when the 'filter-kind' parameter is not specified. If omitted then the default is to let all names pass. Returns: Callable[[str], bool] \u2013 A filter function which takes a name string and returns True when the item passes the filter. get_string_list ( self , param , default = ()) \uf0c1 Extract a configuration parameter as a string list. Parameters: param ( str ) \u2013 Name of the configuration parameter. default ( Sequence[str] ) \u2013 Value to return, when the parameter is missing. Returns: Sequence[str] \u2013 If the parameter value is a simple string, it is returned as a one-item list. If the parameter value does not exist, the given default is returned. If the parameter value is a list, it is checked to contain only strings before being returned. The main filter function of the sanitizer \uf0c1 The filter function receives a single object of type ProcessInfo which has with three members: place : read-only information about the place being processed. See PlaceInfo below. names : The current list of names for the place. Each name is a PlaceName object. address : The current list of address names for the place. Each name is a PlaceName object. While the place member is provided for information only, the names and address lists are meant to be manipulated by the sanitizer. It may add and remove entries, change information within a single entry (for example by adding extra attributes) or completely replace the list with a different one. PlaceInfo - information about the place \uf0c1 This data class contains all information the tokenizer can access about a place. address : Optional [ Mapping [ str , str ]] property readonly \uf0c1 A dictionary with the address elements of the place. They key usually corresponds to the suffix part of the key of an OSM 'addr: ' or 'isin: ' tag. There are also some special keys like country or country_code which merge OSM keys that contain the same information. See Import Styles for details. The property may be None if the place has no address information. centroid : Optional [ Tuple [ float , float ]] property readonly \uf0c1 A center point of the place in WGS84. May be None when the geometry of the place is unknown. country_code : Optional [ str ] property readonly \uf0c1 The country code of the country the place is in. Guaranteed to be a two-letter lower-case string. If the place is not inside any country, the property is set to None. name : Optional [ Mapping [ str , str ]] property readonly \uf0c1 A dictionary with the names of the place. Keys and values represent the full key and value of the corresponding OSM tag. Which tags are saved as names is determined by the import style. The property may be None if the place has no names. rank_address : int property readonly \uf0c1 The rank address before ant rank correction is applied. is_a ( self , key , value ) \uf0c1 Set to True when the place's primary tag corresponds to the given key and value. is_country ( self ) \uf0c1 Set to True when the place is a valid country boundary. PlaceName - extended naming information \uf0c1 Each name and address part of a place is encapsulated in an object of this class. It saves not only the name proper but also describes the kind of name with two properties: kind describes the name of the OSM key used without any suffixes (i.e. the part after the colon removed) suffix contains the suffix of the OSM tag, if any. The suffix is the part of the key after the first colon. In addition to that, a name may have arbitrary additional attributes. How attributes are used, depends on the sanitizers and token analysers. The exception is is the 'analyzer' attribute. This attribute determines which token analysis module will be used to finalize the treatment of names. clone ( self , name = None , kind = None , suffix = None , attr = None ) \uf0c1 Create a deep copy of the place name, optionally with the given parameters replaced. In the attribute list only the given keys are updated. The list is not replaced completely. In particular, the function cannot to be used to remove an attribute from a place name. get_attr ( self , key , default = None ) \uf0c1 Return the given property or the value of 'default' if it is not set. has_attr ( self , key ) \uf0c1 Check if the given attribute is set. set_attr ( self , key , value ) \uf0c1 Add the given property to the name. If the property was already set, then the value is overwritten. Example: Filter for US street prefixes \uf0c1 The following sanitizer removes the directional prefixes from street names in the US: import re def _filter_function ( obj ): if obj . place . country_code == 'us' \\ and obj . place . rank_address >= 26 and obj . place . rank_address <= 27 : for name in obj . names : name . name = re . sub ( r '^(north|south|west|east) ' , '' , name . name , flags = re . IGNORECASE ) def create ( config ): return _filter_function This is the most simple form of a sanitizer module. If defines a single filter function and implements the required create() function by returning the filter. The filter function first checks if the object is interesting for the sanitizer. Namely it checks if the place is in the US (through country_code ) and it the place is a street (a rank_address of 26 or 27). If the conditions are met, then it goes through all available names and removes any leading directional prefix using a simple regular expression. Save the source code in a file in your project directory, for example as us_streets.py . Then you can use the sanitizer in your icu_tokenizer.yaml : ... sanitizers : - step : us_streets.py ... Warning This example is just a simplified show case on how to create a sanitizer. It is not really read for real-world use: while the sanitizer would correcly transform West 5th Street into 5th Street . it would also shorten a simple North Street to Street . For more sanitizer examples, have a look at the sanitizers provided by Nominatim. They can be found in the directory nominatim/tokenizer/sanitizers . Custom token analysis module \uf0c1 The setup of the token analysis is split into two parts: configuration and analyser factory. A token analysis module must therefore implement the two functions here described. configure ( self , rules , normalizer , transliterator ) \uf0c1 Prepare the configuration of the analysis module. This function should prepare all data that can be shared between instances of this analyser. Parameters: rules ( Mapping[str, Any] ) \u2013 A dictionary with the additional configuration options as specified in the tokenizer configuration. normalizer ( Any ) \u2013 an ICU Transliterator with the compiled global normalization rules. transliterator ( Any ) \u2013 an ICU Transliterator with the compiled global transliteration rules. Returns: Any \u2013 A data object with configuration data. This will be handed as is into the create() function and may be used freely by the analysis module as needed. create ( self , normalizer , transliterator , config ) \uf0c1 Create a new instance of the analyser. A separate instance of the analyser is created for each thread when used in multi-threading context. Parameters: normalizer ( Any ) \u2013 an ICU Transliterator with the compiled normalization rules. transliterator ( Any ) \u2013 an ICU Transliterator with the compiled transliteration rules. config ( Any ) \u2013 The object that was returned by the call to configure(). Returns: Analyzer \u2013 A new analyzer instance. This must be an object that implements the Analyzer protocol. The create() function of an analysis module needs to return an object that implements the following functions. compute_variants ( self , canonical_id ) \uf0c1 Compute the transliterated spelling variants for the given canonical ID. Parameters: canonical_id ( str ) \u2013 ID string previously computed with get_canonical_id() . Returns: List[str] \u2013 A list of possible spelling variants. All strings must have been transformed with the global normalizer and transliterator ICU rules. Otherwise they cannot be matched against the input by the query frontend. The list may be empty, when there are no useful spelling variants. This may happen when an analyzer only usually outputs additional variants to the canonical spelling and there are no such variants. get_canonical_id ( self , name ) \uf0c1 Return the canonical form of the given name. The canonical ID must be unique (the same ID must always yield the same variants) and must be a form from which the variants can be derived. Parameters: name ( PlaceName ) \u2013 Extended place name description as prepared by the sanitizers. Returns: str \u2013 ID string with a canonical form of the name. The string may be empty, when the analyzer cannot analyze the name at all, for example because the character set in use does not match. Example: Creating acronym variants for long names \uf0c1 The following example of a token analysis module creates acronyms from very long names and adds them as a variant: class AcronymMaker : \"\"\" This class is the actual analyzer. \"\"\" def __init__ ( self , norm , trans ): self . norm = norm self . trans = trans def get_canonical_id ( self , name ): # In simple cases, the normalized name can be used as a canonical id. return self . norm . transliterate ( name . name ) . strip () def compute_variants ( self , name ): # The transliterated form of the name always makes up a variant. variants = [ self . trans . transliterate ( name )] # Only create acronyms from very long words. if len ( name ) > 20 : # Take the first letter from each word to form the acronym. acronym = '' . join ( w [ 0 ] for w in name . split ()) # If that leds to an acronym with at least three letters, # add the resulting acronym as a variant. if len ( acronym ) > 2 : # Never forget to transliterate the variants before returning them. variants . append ( self . trans . transliterate ( acronym )) return variants # The following two functions are the module interface. def configure ( rules , normalizer , transliterator ): # There is no configuration to parse and no data to set up. # Just return an empty configuration. return None def create ( normalizer , transliterator , config ): # Return a new instance of our token analysis class above. return AcronymMaker ( normalizer , transliterator ) Given the name Trans-Siberian Railway , the code above would return the full name Trans-Siberian Railway and the acronym TSR as variant, so that searching would work for both. Sanitizers vs. Token analysis - what to use for variants? \uf0c1 It is not always clear when to implement variations in the sanitizer and when to write a token analysis module. Just take the acronym example above: it would also have been possible to write a sanitizer which adds the acronym as an additional name to the name list. The result would have been similar. So which should be used when? The most important thing to keep in mind is that variants created by the token analysis are only saved in the word lookup table. They do not need extra space in the search index. If there are many spelling variations, this can mean quite a significant amount of space is saved. When creating additional names with a sanitizer, these names are completely independent. In particular, they can be fed into different token analysis modules. This gives a much greater flexibility but at the price that the additional names increase the size of the search index.","title":"Custom modules for ICU tokenizer"},{"location":"develop/ICU-Tokenizer-Modules/#writing-custom-sanitizer-and-token-analysis-modules-for-the-icu-tokenizer","text":"The ICU tokenizer provides a highly customizable method to pre-process and normalize the name information of the input data before it is added to the search index. It comes with a selection of sanitizers and token analyzers which you can use to adapt your installation to your needs. If the provided modules are not enough, you can also provide your own implementations. This section describes the API of sanitizers and token analysis. Warning This API is currently in early alpha status. While this API is meant to be a public API on which other sanitizers and token analyzers may be implemented, it is not guaranteed to be stable at the moment.","title":"Writing custom sanitizer and token analysis modules for the ICU tokenizer"},{"location":"develop/ICU-Tokenizer-Modules/#using-non-standard-sanitizers-and-token-analyzers","text":"Sanitizer names (in the step property) and token analysis names (in the analyzer ) may refer to externally supplied modules. There are two ways to include external modules: through a library or from the project directory. To include a module from a library, use the absolute import path as name and make sure the library can be found in your PYTHONPATH. To use a custom module without creating a library, you can put the module somewhere in your project directory and then use the relative path to the file. Include the whole name of the file including the .py ending.","title":"Using non-standard sanitizers and token analyzers"},{"location":"develop/ICU-Tokenizer-Modules/#custom-sanitizer-modules","text":"A sanitizer module must export a single factory function create with the following signature: def create ( config : SanitizerConfig ) -> Callable [[ ProcessInfo ], None ] The function receives the custom configuration for the sanitizer and must return a callable (function or class) that transforms the name and address terms of a place. When a place is processed, then a ProcessInfo object is created from the information that was queried from the database. This object is sequentially handed to each configured sanitizer, so that each sanitizer receives the result of processing from the previous sanitizer. After the last sanitizer is finished, the resulting name and address lists are forwarded to the token analysis module. Sanitizer functions are instantiated once and then called for each place that is imported or updated. They don't need to be thread-safe. If multi-threading is used, each thread creates their own instance of the function.","title":"Custom sanitizer modules"},{"location":"develop/ICU-Tokenizer-Modules/#sanitizer-configuration","text":"The SanitizerConfig class is a read-only dictionary with configuration options for the sanitizer. In addition to the usual dictionary functions, the class provides accessors to standard sanitizer options that are used by many of the sanitizers.","title":"Sanitizer configuration"},{"location":"develop/ICU-Tokenizer-Modules/#nominatim.tokenizer.sanitizers.config.SanitizerConfig.get_bool","text":"Extract a configuration parameter as a boolean. Parameters: param ( str ) \u2013 Name of the configuration parameter. The parameter must contain one of the yaml boolean values or an UsageError will be raised. default ( Optional[bool] ) \u2013 Value to return, when the parameter is missing. When set to None , the parameter must be defined. Returns: bool \u2013 Boolean value of the given parameter.","title":"get_bool()"},{"location":"develop/ICU-Tokenizer-Modules/#nominatim.tokenizer.sanitizers.config.SanitizerConfig.get_delimiter","text":"Return the 'delimiters' parameter in the configuration as a compiled regular expression that can be used to split strings on these delimiters. Parameters: default ( str ) \u2013 Delimiters to be used when 'delimiters' parameter is not explicitly configured. Returns: Pattern[str] \u2013 A regular expression pattern which can be used to split a string. The regular expression makes sure that the resulting names are stripped and that repeated delimiters are ignored. It may still create empty fields on occasion. The code needs to filter those.","title":"get_delimiter()"},{"location":"develop/ICU-Tokenizer-Modules/#nominatim.tokenizer.sanitizers.config.SanitizerConfig.get_filter_kind","text":"Return a filter function for the name kind from the 'filter-kind' config parameter. If the 'filter-kind' parameter is empty, the filter lets all items pass. If the parameter is a string, it is interpreted as a single regular expression that must match the full kind string. If the parameter is a list then any of the regular expressions in the list must match to pass. Parameters: default ( str ) \u2013 Filters to be used, when the 'filter-kind' parameter is not specified. If omitted then the default is to let all names pass. Returns: Callable[[str], bool] \u2013 A filter function which takes a name string and returns True when the item passes the filter.","title":"get_filter_kind()"},{"location":"develop/ICU-Tokenizer-Modules/#nominatim.tokenizer.sanitizers.config.SanitizerConfig.get_string_list","text":"Extract a configuration parameter as a string list. Parameters: param ( str ) \u2013 Name of the configuration parameter. default ( Sequence[str] ) \u2013 Value to return, when the parameter is missing. Returns: Sequence[str] \u2013 If the parameter value is a simple string, it is returned as a one-item list. If the parameter value does not exist, the given default is returned. If the parameter value is a list, it is checked to contain only strings before being returned.","title":"get_string_list()"},{"location":"develop/ICU-Tokenizer-Modules/#the-main-filter-function-of-the-sanitizer","text":"The filter function receives a single object of type ProcessInfo which has with three members: place : read-only information about the place being processed. See PlaceInfo below. names : The current list of names for the place. Each name is a PlaceName object. address : The current list of address names for the place. Each name is a PlaceName object. While the place member is provided for information only, the names and address lists are meant to be manipulated by the sanitizer. It may add and remove entries, change information within a single entry (for example by adding extra attributes) or completely replace the list with a different one.","title":"The main filter function of the sanitizer"},{"location":"develop/ICU-Tokenizer-Modules/#placeinfo-information-about-the-place","text":"This data class contains all information the tokenizer can access about a place.","title":"PlaceInfo - information about the place"},{"location":"develop/ICU-Tokenizer-Modules/#nominatim.data.place_info.PlaceInfo.address","text":"A dictionary with the address elements of the place. They key usually corresponds to the suffix part of the key of an OSM 'addr: ' or 'isin: ' tag. There are also some special keys like country or country_code which merge OSM keys that contain the same information. See Import Styles for details. The property may be None if the place has no address information.","title":"address"},{"location":"develop/ICU-Tokenizer-Modules/#nominatim.data.place_info.PlaceInfo.centroid","text":"A center point of the place in WGS84. May be None when the geometry of the place is unknown.","title":"centroid"},{"location":"develop/ICU-Tokenizer-Modules/#nominatim.data.place_info.PlaceInfo.country_code","text":"The country code of the country the place is in. Guaranteed to be a two-letter lower-case string. If the place is not inside any country, the property is set to None.","title":"country_code"},{"location":"develop/ICU-Tokenizer-Modules/#nominatim.data.place_info.PlaceInfo.name","text":"A dictionary with the names of the place. Keys and values represent the full key and value of the corresponding OSM tag. Which tags are saved as names is determined by the import style. The property may be None if the place has no names.","title":"name"},{"location":"develop/ICU-Tokenizer-Modules/#nominatim.data.place_info.PlaceInfo.rank_address","text":"The rank address before ant rank correction is applied.","title":"rank_address"},{"location":"develop/ICU-Tokenizer-Modules/#nominatim.data.place_info.PlaceInfo.is_a","text":"Set to True when the place's primary tag corresponds to the given key and value.","title":"is_a()"},{"location":"develop/ICU-Tokenizer-Modules/#nominatim.data.place_info.PlaceInfo.is_country","text":"Set to True when the place is a valid country boundary.","title":"is_country()"},{"location":"develop/ICU-Tokenizer-Modules/#placename-extended-naming-information","text":"Each name and address part of a place is encapsulated in an object of this class. It saves not only the name proper but also describes the kind of name with two properties: kind describes the name of the OSM key used without any suffixes (i.e. the part after the colon removed) suffix contains the suffix of the OSM tag, if any. The suffix is the part of the key after the first colon. In addition to that, a name may have arbitrary additional attributes. How attributes are used, depends on the sanitizers and token analysers. The exception is is the 'analyzer' attribute. This attribute determines which token analysis module will be used to finalize the treatment of names.","title":"PlaceName - extended naming information"},{"location":"develop/ICU-Tokenizer-Modules/#nominatim.data.place_name.PlaceName.clone","text":"Create a deep copy of the place name, optionally with the given parameters replaced. In the attribute list only the given keys are updated. The list is not replaced completely. In particular, the function cannot to be used to remove an attribute from a place name.","title":"clone()"},{"location":"develop/ICU-Tokenizer-Modules/#nominatim.data.place_name.PlaceName.get_attr","text":"Return the given property or the value of 'default' if it is not set.","title":"get_attr()"},{"location":"develop/ICU-Tokenizer-Modules/#nominatim.data.place_name.PlaceName.has_attr","text":"Check if the given attribute is set.","title":"has_attr()"},{"location":"develop/ICU-Tokenizer-Modules/#nominatim.data.place_name.PlaceName.set_attr","text":"Add the given property to the name. If the property was already set, then the value is overwritten.","title":"set_attr()"},{"location":"develop/ICU-Tokenizer-Modules/#example-filter-for-us-street-prefixes","text":"The following sanitizer removes the directional prefixes from street names in the US: import re def _filter_function ( obj ): if obj . place . country_code == 'us' \\ and obj . place . rank_address >= 26 and obj . place . rank_address <= 27 : for name in obj . names : name . name = re . sub ( r '^(north|south|west|east) ' , '' , name . name , flags = re . IGNORECASE ) def create ( config ): return _filter_function This is the most simple form of a sanitizer module. If defines a single filter function and implements the required create() function by returning the filter. The filter function first checks if the object is interesting for the sanitizer. Namely it checks if the place is in the US (through country_code ) and it the place is a street (a rank_address of 26 or 27). If the conditions are met, then it goes through all available names and removes any leading directional prefix using a simple regular expression. Save the source code in a file in your project directory, for example as us_streets.py . Then you can use the sanitizer in your icu_tokenizer.yaml : ... sanitizers : - step : us_streets.py ... Warning This example is just a simplified show case on how to create a sanitizer. It is not really read for real-world use: while the sanitizer would correcly transform West 5th Street into 5th Street . it would also shorten a simple North Street to Street . For more sanitizer examples, have a look at the sanitizers provided by Nominatim. They can be found in the directory nominatim/tokenizer/sanitizers .","title":"Example: Filter for US street prefixes"},{"location":"develop/ICU-Tokenizer-Modules/#custom-token-analysis-module","text":"The setup of the token analysis is split into two parts: configuration and analyser factory. A token analysis module must therefore implement the two functions here described.","title":"Custom token analysis module"},{"location":"develop/ICU-Tokenizer-Modules/#nominatim.tokenizer.token_analysis.base.AnalysisModule.configure","text":"Prepare the configuration of the analysis module. This function should prepare all data that can be shared between instances of this analyser. Parameters: rules ( Mapping[str, Any] ) \u2013 A dictionary with the additional configuration options as specified in the tokenizer configuration. normalizer ( Any ) \u2013 an ICU Transliterator with the compiled global normalization rules. transliterator ( Any ) \u2013 an ICU Transliterator with the compiled global transliteration rules. Returns: Any \u2013 A data object with configuration data. This will be handed as is into the create() function and may be used freely by the analysis module as needed.","title":"configure()"},{"location":"develop/ICU-Tokenizer-Modules/#nominatim.tokenizer.token_analysis.base.AnalysisModule.create","text":"Create a new instance of the analyser. A separate instance of the analyser is created for each thread when used in multi-threading context. Parameters: normalizer ( Any ) \u2013 an ICU Transliterator with the compiled normalization rules. transliterator ( Any ) \u2013 an ICU Transliterator with the compiled transliteration rules. config ( Any ) \u2013 The object that was returned by the call to configure(). Returns: Analyzer \u2013 A new analyzer instance. This must be an object that implements the Analyzer protocol. The create() function of an analysis module needs to return an object that implements the following functions.","title":"create()"},{"location":"develop/ICU-Tokenizer-Modules/#nominatim.tokenizer.token_analysis.base.Analyzer.compute_variants","text":"Compute the transliterated spelling variants for the given canonical ID. Parameters: canonical_id ( str ) \u2013 ID string previously computed with get_canonical_id() . Returns: List[str] \u2013 A list of possible spelling variants. All strings must have been transformed with the global normalizer and transliterator ICU rules. Otherwise they cannot be matched against the input by the query frontend. The list may be empty, when there are no useful spelling variants. This may happen when an analyzer only usually outputs additional variants to the canonical spelling and there are no such variants.","title":"compute_variants()"},{"location":"develop/ICU-Tokenizer-Modules/#nominatim.tokenizer.token_analysis.base.Analyzer.get_canonical_id","text":"Return the canonical form of the given name. The canonical ID must be unique (the same ID must always yield the same variants) and must be a form from which the variants can be derived. Parameters: name ( PlaceName ) \u2013 Extended place name description as prepared by the sanitizers. Returns: str \u2013 ID string with a canonical form of the name. The string may be empty, when the analyzer cannot analyze the name at all, for example because the character set in use does not match.","title":"get_canonical_id()"},{"location":"develop/ICU-Tokenizer-Modules/#example-creating-acronym-variants-for-long-names","text":"The following example of a token analysis module creates acronyms from very long names and adds them as a variant: class AcronymMaker : \"\"\" This class is the actual analyzer. \"\"\" def __init__ ( self , norm , trans ): self . norm = norm self . trans = trans def get_canonical_id ( self , name ): # In simple cases, the normalized name can be used as a canonical id. return self . norm . transliterate ( name . name ) . strip () def compute_variants ( self , name ): # The transliterated form of the name always makes up a variant. variants = [ self . trans . transliterate ( name )] # Only create acronyms from very long words. if len ( name ) > 20 : # Take the first letter from each word to form the acronym. acronym = '' . join ( w [ 0 ] for w in name . split ()) # If that leds to an acronym with at least three letters, # add the resulting acronym as a variant. if len ( acronym ) > 2 : # Never forget to transliterate the variants before returning them. variants . append ( self . trans . transliterate ( acronym )) return variants # The following two functions are the module interface. def configure ( rules , normalizer , transliterator ): # There is no configuration to parse and no data to set up. # Just return an empty configuration. return None def create ( normalizer , transliterator , config ): # Return a new instance of our token analysis class above. return AcronymMaker ( normalizer , transliterator ) Given the name Trans-Siberian Railway , the code above would return the full name Trans-Siberian Railway and the acronym TSR as variant, so that searching would work for both.","title":"Example: Creating acronym variants for long names"},{"location":"develop/ICU-Tokenizer-Modules/#sanitizers-vs-token-analysis-what-to-use-for-variants","text":"It is not always clear when to implement variations in the sanitizer and when to write a token analysis module. Just take the acronym example above: it would also have been possible to write a sanitizer which adds the acronym as an additional name to the name list. The result would have been similar. So which should be used when? The most important thing to keep in mind is that variants created by the token analysis are only saved in the word lookup table. They do not need extra space in the search index. If there are many spelling variations, this can mean quite a significant amount of space is saved. When creating additional names with a sanitizer, these names are completely independent. In particular, they can be fed into different token analysis modules. This gives a much greater flexibility but at the price that the additional names increase the size of the search index.","title":"Sanitizers vs. Token analysis - what to use for variants?"},{"location":"develop/Indexing/","text":"Indexing Places \uf0c1 In Nominatim, the word indexing refers to the process that takes the raw OpenStreetMap data from the place table, enriches it with address information and creates the search indexes. This section explains the basic data flow. Initial import \uf0c1 After osm2pgsql has loaded the raw OSM data into the place table, the data is copied to the final search tables placex and location_property_osmline. While they are copied, some basic properties are added: country_code, geometry_sector and partition initial search and address rank In addition the column indexed_status is set to 1 marking the place as one that needs to be indexed. All this happens in the triggers placex_insert and osmline_insert . Indexing \uf0c1 The main work horse of the data import is the indexing step, where Nominatim takes every place from the placex and location_property_osmline tables where the indexed_status != 0 and computes the search terms and the address parts of the place. The indexing happens in three major steps: Data preparation - The indexer gets the data for the place to be indexed from the database. Search name processing - The prepared data is given to the tokenizer which computes the search terms from the names and potentially other information. Address processing - The indexer then hands the prepared data and the tokenizer information back to the database via an INSERT statement which also sets the indexed_status to 0 . This triggers the update triggers placex_update / osmline_update which do the work of computing address parts and filling all the search tables. When computing the address terms of a place, Nominatim relies on the processed search names of all the address parts. That is why places are processed in rank order, from smallest rank to largest. To ensure correct handling of linked place nodes, administrative boundaries are processed before all other places. Apart from these restrictions, each place can be indexed independently from the others. This allows a large degree of parallelization during the indexing. It also means that the indexing process can be interrupted at any time and will simply pick up where it left of when restarted. Data preparation \uf0c1 The data preparation step computes and retrieves all data for a place that might be needed for the next step of processing the search name. That includes location information (country code) place classification (class, type, ranks) names (including names of linked places) address information ( addr:* tags) Data preparation is implemented in pl/PgSQL mostly in the functions placex_indexing_prepare() and get_interpolation_address() . addr:* tag inheritance \uf0c1 Nominatim has limited support for inheriting address tags from a building to POIs inside the building. This only works when the address tags are on the building outline. Any rank 30 object inside such a building or on its outline inherits all address tags when it does not have any address tags of its own. The inheritance is computed in the data preparation step. Search name processing \uf0c1 The prepared place information is handed to the tokenizer next. This is a Python module responsible for processing the names from both name and address terms and building up the word index from them. The process is explained in more detail in the Tokenizer chapter . Address processing \uf0c1 Finally, the preprocessed place information and the results of the search name processing are written back to the database. At this point the update trigger of the placex/location_property_osmline tables take over and fill all the dependent tables. This makes up the most work-intensive part of the indexing. Nominatim distinguishes between dependent and independent places. Dependent places are all places on rank 30: house numbers, POIs etc. These places don't have a full address of their own. Instead they are attached to a parent street or place and use the information of the parent for searching and displaying information. Everything else are independent places : streets, parks, water bodies, suburbs, cities, states etc. They receive a full address on their own. The address processing for both types of places is very different. Independent places \uf0c1 To compute the address of an independent place Nominatim searches for all places that cover the place to compute the address for at least partially. For places with an area, that area is used to check for coverage. For place nodes an artificial square area is computed according to the rank of the place. The lower the rank the lager the area. The location_area_large_X tables are there to facilitate the lookup. All places that can function as the address of another place are saved in those tables. addr:* and isin:* tags are taken into account to compute the address, too. Nominatim will give preference to places with the same name as in these tags when looking for places in the vicinity. If there are no matching place names at all, then the tags are at least added to the search index. That means that the names will not be shown in the result as the 'address' of the place, but searching by them still works. Independent places are always added to the global search index search_name . Dependent places \uf0c1 Dependent places skip the full address computation for performance reasons. Instead they just find a parent place to attach themselves to. By default a POI or house number will be attached to the closest street. That can be any major or minor street indexed by Nominatim. In the default configuration that means that it can attach itself to a footway but only when it has a name. When the dependent place has an addr:street tag, then Nominatim will first try to find a street with the same name before falling back to the closest street. There are also addresses in OSM, where the housenumber does not belong to a street at all. These have an addr:place tag. For these places, Nominatim tries to find a place with the given name in the indexed places with an address rank between 16 and 25. If none is found, then the dependent place is attached to the closest place in that category and the addr:place name is added as unlisted place, which indicates to Nominatim that it needs to add it to the address output, no matter what. This special case is necessary to cover addresses that don't really refer to an existing object. When an address has both the addr:street and addr:place tag, then Nominatim assumes that the addr:place tag in fact should be the city part of the address and give the POI the usual street number address. Dependent places are only added to the global search index search_name when they have either a name themselves or when they have address tags that are not covered by the places that make up their address. The latter ensures that addresses are always searchable by those address tags.","title":"Indexing"},{"location":"develop/Indexing/#indexing-places","text":"In Nominatim, the word indexing refers to the process that takes the raw OpenStreetMap data from the place table, enriches it with address information and creates the search indexes. This section explains the basic data flow.","title":"Indexing Places"},{"location":"develop/Indexing/#initial-import","text":"After osm2pgsql has loaded the raw OSM data into the place table, the data is copied to the final search tables placex and location_property_osmline. While they are copied, some basic properties are added: country_code, geometry_sector and partition initial search and address rank In addition the column indexed_status is set to 1 marking the place as one that needs to be indexed. All this happens in the triggers placex_insert and osmline_insert .","title":"Initial import"},{"location":"develop/Indexing/#indexing","text":"The main work horse of the data import is the indexing step, where Nominatim takes every place from the placex and location_property_osmline tables where the indexed_status != 0 and computes the search terms and the address parts of the place. The indexing happens in three major steps: Data preparation - The indexer gets the data for the place to be indexed from the database. Search name processing - The prepared data is given to the tokenizer which computes the search terms from the names and potentially other information. Address processing - The indexer then hands the prepared data and the tokenizer information back to the database via an INSERT statement which also sets the indexed_status to 0 . This triggers the update triggers placex_update / osmline_update which do the work of computing address parts and filling all the search tables. When computing the address terms of a place, Nominatim relies on the processed search names of all the address parts. That is why places are processed in rank order, from smallest rank to largest. To ensure correct handling of linked place nodes, administrative boundaries are processed before all other places. Apart from these restrictions, each place can be indexed independently from the others. This allows a large degree of parallelization during the indexing. It also means that the indexing process can be interrupted at any time and will simply pick up where it left of when restarted.","title":"Indexing"},{"location":"develop/Indexing/#data-preparation","text":"The data preparation step computes and retrieves all data for a place that might be needed for the next step of processing the search name. That includes location information (country code) place classification (class, type, ranks) names (including names of linked places) address information ( addr:* tags) Data preparation is implemented in pl/PgSQL mostly in the functions placex_indexing_prepare() and get_interpolation_address() .","title":"Data preparation"},{"location":"develop/Indexing/#addr-tag-inheritance","text":"Nominatim has limited support for inheriting address tags from a building to POIs inside the building. This only works when the address tags are on the building outline. Any rank 30 object inside such a building or on its outline inherits all address tags when it does not have any address tags of its own. The inheritance is computed in the data preparation step.","title":"addr:* tag inheritance"},{"location":"develop/Indexing/#search-name-processing","text":"The prepared place information is handed to the tokenizer next. This is a Python module responsible for processing the names from both name and address terms and building up the word index from them. The process is explained in more detail in the Tokenizer chapter .","title":"Search name processing"},{"location":"develop/Indexing/#address-processing","text":"Finally, the preprocessed place information and the results of the search name processing are written back to the database. At this point the update trigger of the placex/location_property_osmline tables take over and fill all the dependent tables. This makes up the most work-intensive part of the indexing. Nominatim distinguishes between dependent and independent places. Dependent places are all places on rank 30: house numbers, POIs etc. These places don't have a full address of their own. Instead they are attached to a parent street or place and use the information of the parent for searching and displaying information. Everything else are independent places : streets, parks, water bodies, suburbs, cities, states etc. They receive a full address on their own. The address processing for both types of places is very different.","title":"Address processing"},{"location":"develop/Indexing/#independent-places","text":"To compute the address of an independent place Nominatim searches for all places that cover the place to compute the address for at least partially. For places with an area, that area is used to check for coverage. For place nodes an artificial square area is computed according to the rank of the place. The lower the rank the lager the area. The location_area_large_X tables are there to facilitate the lookup. All places that can function as the address of another place are saved in those tables. addr:* and isin:* tags are taken into account to compute the address, too. Nominatim will give preference to places with the same name as in these tags when looking for places in the vicinity. If there are no matching place names at all, then the tags are at least added to the search index. That means that the names will not be shown in the result as the 'address' of the place, but searching by them still works. Independent places are always added to the global search index search_name .","title":"Independent places"},{"location":"develop/Indexing/#dependent-places","text":"Dependent places skip the full address computation for performance reasons. Instead they just find a parent place to attach themselves to. By default a POI or house number will be attached to the closest street. That can be any major or minor street indexed by Nominatim. In the default configuration that means that it can attach itself to a footway but only when it has a name. When the dependent place has an addr:street tag, then Nominatim will first try to find a street with the same name before falling back to the closest street. There are also addresses in OSM, where the housenumber does not belong to a street at all. These have an addr:place tag. For these places, Nominatim tries to find a place with the given name in the indexed places with an address rank between 16 and 25. If none is found, then the dependent place is attached to the closest place in that category and the addr:place name is added as unlisted place, which indicates to Nominatim that it needs to add it to the address output, no matter what. This special case is necessary to cover addresses that don't really refer to an existing object. When an address has both the addr:street and addr:place tag, then Nominatim assumes that the addr:place tag in fact should be the city part of the address and give the POI the usual street number address. Dependent places are only added to the global search index search_name when they have either a name themselves or when they have address tags that are not covered by the places that make up their address. The latter ensures that addresses are always searchable by those address tags.","title":"Dependent places"},{"location":"develop/Testing/","text":"Nominatim Test Suite \uf0c1 This chapter describes the tests in the /test directory, how they are structured and how to extend them. For a quick introduction on how to run the tests, see the Development setup chapter . Overall structure \uf0c1 There are two kind of tests in this test suite. There are functional tests which test the API interface using a BDD test framework and there are unit tests for specific PHP functions. This test directory is sturctured as follows: -+- bdd Functional API tests | \\ | +- steps Step implementations for test descriptions | +- osm2pgsql Tests for data import via osm2pgsql | +- db Tests for internal data processing on import and update | +- api Tests for API endpoints ( search , reverse , etc . ) | +- php PHP unit tests +- python Python unit tests +- testdb Base data for generating API test database +- testdata Additional test data used by unit tests PHP Unit Tests ( test/php ) \uf0c1 Unit tests for PHP code can be found in the php/ directory. They test selected PHP functions. Very low coverage. To execute the test suite run cd test/php UNIT_TEST_DSN='pgsql:dbname=nominatim_unit_tests' phpunit ../ It will read phpunit.xml which points to the library, test path, bootstrap strip and sets other parameters. It will use (and destroy) a local database 'nominatim_unit_tests'. You can set a different connection string with e.g. UNIT_TEST_DSN='pgsql:dbname=foo_unit_tests'. Python Unit Tests ( test/python ) \uf0c1 Unit tests for Python code can be found in the python/ directory. The goal is to have complete coverage of the Python library in nominatim . To execute the tests run py.test-3 test/python or pytest test/python The name of the pytest binary depends on your installation. BDD Functional Tests ( test/bdd ) \uf0c1 Functional tests are written as BDD instructions. For more information on the philosophy of BDD testing, see the Behave manual . The following explanation assume that the reader is familiar with the BDD notations of features, scenarios and steps. All possible steps can be found in the steps directory and should ideally be documented. General Usage \uf0c1 To run the functional tests, do cd test/bdd behave The tests can be configured with a set of environment variables ( behave -D key=val ): BUILDDIR - build directory of Nominatim installation to test TEMPLATE_DB - name of template database used as a skeleton for the test databases (db tests) TEST_DB - name of test database (db tests) API_TEST_DB - name of the database containing the API test data (api tests) API_TEST_FILE - OSM file to be imported into the API test database (api tests) DB_HOST - (optional) hostname of database host DB_PORT - (optional) port of database on host DB_USER - (optional) username of database login DB_PASS - (optional) password for database login SERVER_MODULE_PATH - (optional) path on the Postgres server to Nominatim module shared library file REMOVE_TEMPLATE - if true, the template and API database will not be reused during the next run. Reusing the base templates speeds up tests considerably but might lead to outdated errors for some changes in the database layout. KEEP_TEST_DB - if true, the test database will not be dropped after a test is finished. Should only be used if one single scenario is run, otherwise the result is undefined. Logging can be defined through command line parameters of behave itself. Check out behave --help for details. Also have a look at the 'work-in-progress' feature of behave which comes in handy when writing new tests. API Tests ( test/bdd/api ) \uf0c1 These tests are meant to test the different API endpoints and their parameters. They require to import several datasets into a test database. This is normally done automatically during setup of the test. The API test database is then kept around and reused in subsequent runs of behave. Use behave -DREMOVE_TEMPLATE to force a reimport of the database. The official test dataset is saved in the file test/testdb/apidb-test-data.pbf and compromises the following data: Geofabrik extract of Liechtenstein extract of Autauga country, Alabama, US (for tests against Tiger data) additional data from test/testdb/additional_api_test.data.osm API tests should only be testing the functionality of the website PHP code. Most tests should be formulated as BDD DB creation tests (see below) instead. Code Coverage \uf0c1 The API tests also support code coverage tests. You need to install PHP_CodeCoverage . On Debian/Ubuntu run: apt-get install php-codecoverage php-xdebug Then run the API tests as follows: behave api -DPHPCOV=<coverage output dir> The output directory must be an absolute path. To generate reports, you can use the phpcov tool: phpcov merge --html=<report output dir> <coverage output dir> DB Creation Tests ( test/bdd/db ) \uf0c1 These tests check the import and update of the Nominatim database. They do not test the correctness of osm2pgsql. Each test will write some data into the place table (and optionally the planet_osm_* tables if required) and then run Nominatim's processing functions on that. These tests need to create their own test databases. By default they will be called test_template_nominatim and test_nominatim . Names can be changed with the environment variables TEMPLATE_DB and TEST_DB . The user running the tests needs superuser rights for postgres. Import Tests ( test/bdd/osm2pgsql ) \uf0c1 These tests check that data is imported correctly into the place table. They use the same template database as the DB Creation tests, so the same remarks apply. Note that most testing of the gazetteer output of osm2pgsql is done in the tests of osm2pgsql itself. The BDD tests are just there to ensure compatibility of the osm2pgsql and Nominatim code.","title":"Testing"},{"location":"develop/Testing/#nominatim-test-suite","text":"This chapter describes the tests in the /test directory, how they are structured and how to extend them. For a quick introduction on how to run the tests, see the Development setup chapter .","title":"Nominatim Test Suite"},{"location":"develop/Testing/#overall-structure","text":"There are two kind of tests in this test suite. There are functional tests which test the API interface using a BDD test framework and there are unit tests for specific PHP functions. This test directory is sturctured as follows: -+- bdd Functional API tests | \\ | +- steps Step implementations for test descriptions | +- osm2pgsql Tests for data import via osm2pgsql | +- db Tests for internal data processing on import and update | +- api Tests for API endpoints ( search , reverse , etc . ) | +- php PHP unit tests +- python Python unit tests +- testdb Base data for generating API test database +- testdata Additional test data used by unit tests","title":"Overall structure"},{"location":"develop/Testing/#php-unit-tests-testphp","text":"Unit tests for PHP code can be found in the php/ directory. They test selected PHP functions. Very low coverage. To execute the test suite run cd test/php UNIT_TEST_DSN='pgsql:dbname=nominatim_unit_tests' phpunit ../ It will read phpunit.xml which points to the library, test path, bootstrap strip and sets other parameters. It will use (and destroy) a local database 'nominatim_unit_tests'. You can set a different connection string with e.g. UNIT_TEST_DSN='pgsql:dbname=foo_unit_tests'.","title":"PHP Unit Tests (test/php)"},{"location":"develop/Testing/#python-unit-tests-testpython","text":"Unit tests for Python code can be found in the python/ directory. The goal is to have complete coverage of the Python library in nominatim . To execute the tests run py.test-3 test/python or pytest test/python The name of the pytest binary depends on your installation.","title":"Python Unit Tests (test/python)"},{"location":"develop/Testing/#bdd-functional-tests-testbdd","text":"Functional tests are written as BDD instructions. For more information on the philosophy of BDD testing, see the Behave manual . The following explanation assume that the reader is familiar with the BDD notations of features, scenarios and steps. All possible steps can be found in the steps directory and should ideally be documented.","title":"BDD Functional Tests (test/bdd)"},{"location":"develop/Testing/#general-usage","text":"To run the functional tests, do cd test/bdd behave The tests can be configured with a set of environment variables ( behave -D key=val ): BUILDDIR - build directory of Nominatim installation to test TEMPLATE_DB - name of template database used as a skeleton for the test databases (db tests) TEST_DB - name of test database (db tests) API_TEST_DB - name of the database containing the API test data (api tests) API_TEST_FILE - OSM file to be imported into the API test database (api tests) DB_HOST - (optional) hostname of database host DB_PORT - (optional) port of database on host DB_USER - (optional) username of database login DB_PASS - (optional) password for database login SERVER_MODULE_PATH - (optional) path on the Postgres server to Nominatim module shared library file REMOVE_TEMPLATE - if true, the template and API database will not be reused during the next run. Reusing the base templates speeds up tests considerably but might lead to outdated errors for some changes in the database layout. KEEP_TEST_DB - if true, the test database will not be dropped after a test is finished. Should only be used if one single scenario is run, otherwise the result is undefined. Logging can be defined through command line parameters of behave itself. Check out behave --help for details. Also have a look at the 'work-in-progress' feature of behave which comes in handy when writing new tests.","title":"General Usage"},{"location":"develop/Testing/#api-tests-testbddapi","text":"These tests are meant to test the different API endpoints and their parameters. They require to import several datasets into a test database. This is normally done automatically during setup of the test. The API test database is then kept around and reused in subsequent runs of behave. Use behave -DREMOVE_TEMPLATE to force a reimport of the database. The official test dataset is saved in the file test/testdb/apidb-test-data.pbf and compromises the following data: Geofabrik extract of Liechtenstein extract of Autauga country, Alabama, US (for tests against Tiger data) additional data from test/testdb/additional_api_test.data.osm API tests should only be testing the functionality of the website PHP code. Most tests should be formulated as BDD DB creation tests (see below) instead.","title":"API Tests (test/bdd/api)"},{"location":"develop/Testing/#code-coverage","text":"The API tests also support code coverage tests. You need to install PHP_CodeCoverage . On Debian/Ubuntu run: apt-get install php-codecoverage php-xdebug Then run the API tests as follows: behave api -DPHPCOV=<coverage output dir> The output directory must be an absolute path. To generate reports, you can use the phpcov tool: phpcov merge --html=<report output dir> <coverage output dir>","title":"Code Coverage"},{"location":"develop/Testing/#db-creation-tests-testbdddb","text":"These tests check the import and update of the Nominatim database. They do not test the correctness of osm2pgsql. Each test will write some data into the place table (and optionally the planet_osm_* tables if required) and then run Nominatim's processing functions on that. These tests need to create their own test databases. By default they will be called test_template_nominatim and test_nominatim . Names can be changed with the environment variables TEMPLATE_DB and TEST_DB . The user running the tests needs superuser rights for postgres.","title":"DB Creation Tests (test/bdd/db)"},{"location":"develop/Testing/#import-tests-testbddosm2pgsql","text":"These tests check that data is imported correctly into the place table. They use the same template database as the DB Creation tests, so the same remarks apply. Note that most testing of the gazetteer output of osm2pgsql is done in the tests of osm2pgsql itself. The BDD tests are just there to ensure compatibility of the osm2pgsql and Nominatim code.","title":"Import Tests (test/bdd/osm2pgsql)"},{"location":"develop/Tokenizers/","text":"Tokenizers \uf0c1 The tokenizer is the component of Nominatim that is responsible for analysing names of OSM objects and queries. Nominatim provides different tokenizers that use different strategies for normalisation. This page describes how tokenizers are expected to work and the public API that needs to be implemented when creating a new tokenizer. For information on how to configure a specific tokenizer for a database see the tokenizer chapter in the Customization Guide . Generic Architecture \uf0c1 About Search Tokens \uf0c1 Search in Nominatim is organised around search tokens. Such a token represents string that can be part of the search query. Tokens are used so that the search index does not need to be organised around strings. Instead the database saves for each place which tokens match this place's name, address, house number etc. To be able to distinguish between these different types of information stored with the place, a search token also always has a certain type: name, house number, postcode etc. During search an incoming query is transformed into a ordered list of such search tokens (or rather many lists, see below) and this list is then converted into a database query to find the right place. It is the core task of the tokenizer to create, manage and assign the search tokens. The tokenizer is involved in two distinct operations: at import time : scanning names of OSM objects, normalizing them and building up the list of search tokens. at query time : scanning the query and returning the appropriate search tokens. Importing \uf0c1 The indexer is responsible to enrich an OSM object (or place) with all data required for geocoding. It is split into two parts: the controller collects the places that require updating, enriches the place information as required and hands the place to Postgresql. The collector is part of the Nominatim library written in Python. Within Postgresql, the placex_update trigger is responsible to fill out all secondary tables with extra geocoding information. This part is written in PL/pgSQL. The tokenizer is involved in both parts. When the indexer prepares a place, it hands it over to the tokenizer to inspect the names and create all the search tokens applicable for the place. This usually involves updating the tokenizer's internal token lists and creating a list of all token IDs for the specific place. This list is later needed in the PL/pgSQL part where the indexer needs to add the token IDs to the appropriate search tables. To be able to communicate the list between the Python part and the pl/pgSQL trigger, the placex table contains a special JSONB column token_info which is there for the exclusive use of the tokenizer. The Python part of the tokenizer returns a structured information about the tokens of a place to the indexer which converts it to JSON and inserts it into the token_info column. The content of the column is then handed to the PL/pqSQL callbacks of the tokenizer which extracts the required information. Usually the tokenizer then removes all information from the token_info structure, so that no information is ever persistently saved in the table. All information that went in should have been processed after all and put into secondary tables. This is however not a hard requirement. If the tokenizer needs to store additional information about a place permanently, it may do so in the token_info column. It just may never execute searches over it and consequently not create any special indexes on it. Querying \uf0c1 At query time, Nominatim builds up multiple interpretations of the search query. Each of these interpretations is tried against the database in order of the likelihood with which they match to the search query. The first interpretation that yields results wins. The interpretations are encapsulated in the SearchDescription class. An instance of this class is created by applying a sequence of search tokens to an initially empty SearchDescription. It is the responsibility of the tokenizer to parse the search query and derive all possible sequences of search tokens. To that end the tokenizer needs to parse the search query and look up matching words in its own data structures. Tokenizer API \uf0c1 The following section describes the functions that need to be implemented for a custom tokenizer implementation. Warning This API is currently in early alpha status. While this API is meant to be a public API on which other tokenizers may be implemented, the API is far away from being stable at the moment. Directory Structure \uf0c1 Nominatim expects two files for a tokenizer: nominatim/tokenizer/<NAME>_tokenizer.py containing the Python part of the implementation lib-php/tokenizer/<NAME>_tokenizer.php with the PHP part of the implementation where <NAME> is a unique name for the tokenizer consisting of only lower-case letters, digits and underscore. A tokenizer also needs to install some SQL functions. By convention, these should be placed in lib-sql/tokenizer . If the tokenizer has a default configuration file, this should be saved in the settings/<NAME>_tokenizer.<SUFFIX> . Configuration and Persistence \uf0c1 Tokenizers may define custom settings for their configuration. All settings must be prefixed with NOMINATIM_TOKENIZER_ . Settings may be transient or persistent. Transient settings are loaded from the configuration file when Nominatim is started and may thus be changed at any time. Persistent settings are tied to a database installation and must only be read during installation time. If they are needed for the runtime then they must be saved into the nominatim_properties table and later loaded from there. The Python module \uf0c1 The Python module is expect to export a single factory function: def create ( dsn : str , data_dir : Path ) -> AbstractTokenizer The dsn parameter contains the DSN of the Nominatim database. The data_dir is a directory in the project directory that the tokenizer may use to save database-specific data. The function must return the instance of the tokenizer class as defined below. Python Tokenizer Class \uf0c1 All tokenizers must inherit from nominatim.tokenizer.base.AbstractTokenizer and implement the abstract functions defined there. The tokenizer instance is the central instance of the tokenizer in the system. There will only be a single instance of the tokenizer active at any time. Source code in nominatim/tokenizer/base.py class AbstractTokenizer ( ABC ): \"\"\" The tokenizer instance is the central instance of the tokenizer in the system. There will only be a single instance of the tokenizer active at any time. \"\"\" @abstractmethod def init_new_db ( self , config : Configuration , init_db : bool = True ) -> None : \"\"\" Set up a new tokenizer for the database. The function should copy all necessary data into the project directory or save it in the property table to make sure that the tokenizer remains stable over updates. Arguments: config: Read-only object with configuration options. init_db: When set to False, then initialisation of database tables should be skipped. This option is only required for migration purposes and can be safely ignored by custom tokenizers. TODO: can we move the init_db parameter somewhere else? \"\"\" @abstractmethod def init_from_project ( self , config : Configuration ) -> None : \"\"\" Initialise the tokenizer from an existing database setup. The function should load all previously saved configuration from the project directory and/or the property table. Arguments: config: Read-only object with configuration options. \"\"\" @abstractmethod def finalize_import ( self , config : Configuration ) -> None : \"\"\" This function is called at the very end of an import when all data has been imported and indexed. The tokenizer may create at this point any additional indexes and data structures needed during query time. Arguments: config: Read-only object with configuration options. \"\"\" @abstractmethod def update_sql_functions ( self , config : Configuration ) -> None : \"\"\" Update the SQL part of the tokenizer. This function is called automatically on migrations or may be called explicitly by the user through the `nominatim refresh --functions` command. The tokenizer must only update the code of the tokenizer. The data structures or data itself must not be changed by this function. Arguments: config: Read-only object with configuration options. \"\"\" @abstractmethod def check_database ( self , config : Configuration ) -> Optional [ str ]: \"\"\" Check that the database is set up correctly and ready for being queried. Arguments: config: Read-only object with configuration options. Returns: If an issue was found, return an error message with the description of the issue as well as hints for the user on how to resolve the issue. If everything is okay, return `None`. \"\"\" @abstractmethod def update_statistics ( self ) -> None : \"\"\" Recompute any tokenizer statistics necessary for efficient lookup. This function is meant to be called from time to time by the user to improve performance. However, the tokenizer must not depend on it to be called in order to work. \"\"\" @abstractmethod def update_word_tokens ( self ) -> None : \"\"\" Do house-keeping on the tokenizers internal data structures. Remove unused word tokens, resort data etc. \"\"\" @abstractmethod def name_analyzer ( self ) -> AbstractAnalyzer : \"\"\" Create a new analyzer for tokenizing names and queries using this tokinzer. Analyzers are context managers and should be used accordingly: ``` with tokenizer.name_analyzer() as analyzer: analyser.tokenize() ``` When used outside the with construct, the caller must ensure to call the close() function before destructing the analyzer. \"\"\" check_database ( self , config ) \uf0c1 Check that the database is set up correctly and ready for being queried. Parameters: config ( Configuration ) \u2013 Read-only object with configuration options. Returns: Optional[str] \u2013 If an issue was found, return an error message with the description of the issue as well as hints for the user on how to resolve the issue. If everything is okay, return None . Source code in nominatim/tokenizer/base.py @abstractmethod def check_database ( self , config : Configuration ) -> Optional [ str ]: \"\"\" Check that the database is set up correctly and ready for being queried. Arguments: config: Read-only object with configuration options. Returns: If an issue was found, return an error message with the description of the issue as well as hints for the user on how to resolve the issue. If everything is okay, return `None`. \"\"\" finalize_import ( self , config ) \uf0c1 This function is called at the very end of an import when all data has been imported and indexed. The tokenizer may create at this point any additional indexes and data structures needed during query time. Parameters: config ( Configuration ) \u2013 Read-only object with configuration options. Source code in nominatim/tokenizer/base.py @abstractmethod def finalize_import ( self , config : Configuration ) -> None : \"\"\" This function is called at the very end of an import when all data has been imported and indexed. The tokenizer may create at this point any additional indexes and data structures needed during query time. Arguments: config: Read-only object with configuration options. \"\"\" init_from_project ( self , config ) \uf0c1 Initialise the tokenizer from an existing database setup. The function should load all previously saved configuration from the project directory and/or the property table. Parameters: config ( Configuration ) \u2013 Read-only object with configuration options. Source code in nominatim/tokenizer/base.py @abstractmethod def init_from_project ( self , config : Configuration ) -> None : \"\"\" Initialise the tokenizer from an existing database setup. The function should load all previously saved configuration from the project directory and/or the property table. Arguments: config: Read-only object with configuration options. \"\"\" init_new_db ( self , config , init_db = True ) \uf0c1 Set up a new tokenizer for the database. The function should copy all necessary data into the project directory or save it in the property table to make sure that the tokenizer remains stable over updates. Parameters: config ( Configuration ) \u2013 Read-only object with configuration options. init_db ( bool ) \u2013 When set to False, then initialisation of database tables should be skipped. This option is only required for migration purposes and can be safely ignored by custom tokenizers. TODO: can we move the init_db parameter somewhere else? Source code in nominatim/tokenizer/base.py @abstractmethod def init_new_db ( self , config : Configuration , init_db : bool = True ) -> None : \"\"\" Set up a new tokenizer for the database. The function should copy all necessary data into the project directory or save it in the property table to make sure that the tokenizer remains stable over updates. Arguments: config: Read-only object with configuration options. init_db: When set to False, then initialisation of database tables should be skipped. This option is only required for migration purposes and can be safely ignored by custom tokenizers. TODO: can we move the init_db parameter somewhere else? \"\"\" name_analyzer ( self ) \uf0c1 Create a new analyzer for tokenizing names and queries using this tokinzer. Analyzers are context managers and should be used accordingly: with tokenizer.name_analyzer() as analyzer: analyser.tokenize() When used outside the with construct, the caller must ensure to call the close() function before destructing the analyzer. Source code in nominatim/tokenizer/base.py @abstractmethod def name_analyzer ( self ) -> AbstractAnalyzer : \"\"\" Create a new analyzer for tokenizing names and queries using this tokinzer. Analyzers are context managers and should be used accordingly: ``` with tokenizer.name_analyzer() as analyzer: analyser.tokenize() ``` When used outside the with construct, the caller must ensure to call the close() function before destructing the analyzer. \"\"\" update_sql_functions ( self , config ) \uf0c1 Update the SQL part of the tokenizer. This function is called automatically on migrations or may be called explicitly by the user through the nominatim refresh --functions command. The tokenizer must only update the code of the tokenizer. The data structures or data itself must not be changed by this function. Parameters: config ( Configuration ) \u2013 Read-only object with configuration options. Source code in nominatim/tokenizer/base.py @abstractmethod def update_sql_functions ( self , config : Configuration ) -> None : \"\"\" Update the SQL part of the tokenizer. This function is called automatically on migrations or may be called explicitly by the user through the `nominatim refresh --functions` command. The tokenizer must only update the code of the tokenizer. The data structures or data itself must not be changed by this function. Arguments: config: Read-only object with configuration options. \"\"\" update_statistics ( self ) \uf0c1 Recompute any tokenizer statistics necessary for efficient lookup. This function is meant to be called from time to time by the user to improve performance. However, the tokenizer must not depend on it to be called in order to work. Source code in nominatim/tokenizer/base.py @abstractmethod def update_statistics ( self ) -> None : \"\"\" Recompute any tokenizer statistics necessary for efficient lookup. This function is meant to be called from time to time by the user to improve performance. However, the tokenizer must not depend on it to be called in order to work. \"\"\" update_word_tokens ( self ) \uf0c1 Do house-keeping on the tokenizers internal data structures. Remove unused word tokens, resort data etc. Source code in nominatim/tokenizer/base.py @abstractmethod def update_word_tokens ( self ) -> None : \"\"\" Do house-keeping on the tokenizers internal data structures. Remove unused word tokens, resort data etc. \"\"\" Python Analyzer Class \uf0c1 The analyzer provides the functions for analysing names and building the token database. Analyzers are instantiated on a per-thread base. Access to global data structures must be synchronised accordingly. Source code in nominatim/tokenizer/base.py class AbstractAnalyzer ( ABC ): \"\"\" The analyzer provides the functions for analysing names and building the token database. Analyzers are instantiated on a per-thread base. Access to global data structures must be synchronised accordingly. \"\"\" def __enter__ ( self ) -> 'AbstractAnalyzer' : return self def __exit__ ( self , exc_type : Any , exc_value : Any , traceback : Any ) -> None : self . close () @abstractmethod def close ( self ) -> None : \"\"\" Free all resources used by the analyzer. \"\"\" @abstractmethod def get_word_token_info ( self , words : List [ str ]) -> List [ Tuple [ str , str , int ]]: \"\"\" Return token information for the given list of words. The function is used for testing and debugging only and does not need to be particularly efficient. Arguments: words: A list of words to look up the tokens for. If a word starts with # it is assumed to be a full name otherwise is a partial term. Returns: The function returns the list of all tuples that could be found for the given words. Each list entry is a tuple of (original word, word token, word id). \"\"\" @abstractmethod def normalize_postcode ( self , postcode : str ) -> str : \"\"\" Convert the postcode to its standardized form. This function must yield exactly the same result as the SQL function `token_normalized_postcode()`. Arguments: postcode: The postcode to be normalized. Returns: The given postcode after normalization. \"\"\" @abstractmethod def update_postcodes_from_db ( self ) -> None : \"\"\" Update the tokenizer's postcode tokens from the current content of the `location_postcode` table. \"\"\" @abstractmethod def update_special_phrases ( self , phrases : Iterable [ Tuple [ str , str , str , str ]], should_replace : bool ) -> None : \"\"\" Update the tokenizer's special phrase tokens from the given list of special phrases. Arguments: phrases: The new list of special phrases. Each entry is a tuple of (phrase, class, type, operator). should_replace: If true, replace the current list of phrases. When false, just add the given phrases to the ones that already exist. \"\"\" @abstractmethod def add_country_names ( self , country_code : str , names : Dict [ str , str ]) -> None : \"\"\" Add the given names to the tokenizer's list of country tokens. Arguments: country_code: two-letter country code for the country the names refer to. names: Dictionary of name type to name. \"\"\" @abstractmethod def process_place ( self , place : PlaceInfo ) -> Any : \"\"\" Extract tokens for the given place and compute the information to be handed to the PL/pgSQL processor for building the search index. Arguments: place: Place information retrieved from the database. Returns: A JSON-serialisable structure that will be handed into the database via the `token_info` field. \"\"\" add_country_names ( self , country_code , names ) \uf0c1 Add the given names to the tokenizer's list of country tokens. Parameters: country_code ( str ) \u2013 two-letter country code for the country the names refer to. names ( Dict[str, str] ) \u2013 Dictionary of name type to name. Source code in nominatim/tokenizer/base.py @abstractmethod def add_country_names ( self , country_code : str , names : Dict [ str , str ]) -> None : \"\"\" Add the given names to the tokenizer's list of country tokens. Arguments: country_code: two-letter country code for the country the names refer to. names: Dictionary of name type to name. \"\"\" close ( self ) \uf0c1 Free all resources used by the analyzer. Source code in nominatim/tokenizer/base.py @abstractmethod def close ( self ) -> None : \"\"\" Free all resources used by the analyzer. \"\"\" get_word_token_info ( self , words ) \uf0c1 Return token information for the given list of words. The function is used for testing and debugging only and does not need to be particularly efficient. Parameters: words ( List[str] ) \u2013 A list of words to look up the tokens for. If a word starts with # it is assumed to be a full name otherwise is a partial term. Returns: List[Tuple[str, str, int]] \u2013 The function returns the list of all tuples that could be found for the given words. Each list entry is a tuple of (original word, word token, word id). Source code in nominatim/tokenizer/base.py @abstractmethod def get_word_token_info ( self , words : List [ str ]) -> List [ Tuple [ str , str , int ]]: \"\"\" Return token information for the given list of words. The function is used for testing and debugging only and does not need to be particularly efficient. Arguments: words: A list of words to look up the tokens for. If a word starts with # it is assumed to be a full name otherwise is a partial term. Returns: The function returns the list of all tuples that could be found for the given words. Each list entry is a tuple of (original word, word token, word id). \"\"\" normalize_postcode ( self , postcode ) \uf0c1 Convert the postcode to its standardized form. This function must yield exactly the same result as the SQL function token_normalized_postcode() . Parameters: postcode ( str ) \u2013 The postcode to be normalized. Returns: str \u2013 The given postcode after normalization. Source code in nominatim/tokenizer/base.py @abstractmethod def normalize_postcode ( self , postcode : str ) -> str : \"\"\" Convert the postcode to its standardized form. This function must yield exactly the same result as the SQL function `token_normalized_postcode()`. Arguments: postcode: The postcode to be normalized. Returns: The given postcode after normalization. \"\"\" process_place ( self , place ) \uf0c1 Extract tokens for the given place and compute the information to be handed to the PL/pgSQL processor for building the search index. Parameters: place ( PlaceInfo ) \u2013 Place information retrieved from the database. Returns: Any \u2013 A JSON-serialisable structure that will be handed into the database via the token_info field. Source code in nominatim/tokenizer/base.py @abstractmethod def process_place ( self , place : PlaceInfo ) -> Any : \"\"\" Extract tokens for the given place and compute the information to be handed to the PL/pgSQL processor for building the search index. Arguments: place: Place information retrieved from the database. Returns: A JSON-serialisable structure that will be handed into the database via the `token_info` field. \"\"\" update_postcodes_from_db ( self ) \uf0c1 Update the tokenizer's postcode tokens from the current content of the location_postcode table. Source code in nominatim/tokenizer/base.py @abstractmethod def update_postcodes_from_db ( self ) -> None : \"\"\" Update the tokenizer's postcode tokens from the current content of the `location_postcode` table. \"\"\" update_special_phrases ( self , phrases , should_replace ) \uf0c1 Update the tokenizer's special phrase tokens from the given list of special phrases. Parameters: phrases ( Iterable[Tuple[str, str, str, str]] ) \u2013 The new list of special phrases. Each entry is a tuple of (phrase, class, type, operator). should_replace ( bool ) \u2013 If true, replace the current list of phrases. When false, just add the given phrases to the ones that already exist. Source code in nominatim/tokenizer/base.py @abstractmethod def update_special_phrases ( self , phrases : Iterable [ Tuple [ str , str , str , str ]], should_replace : bool ) -> None : \"\"\" Update the tokenizer's special phrase tokens from the given list of special phrases. Arguments: phrases: The new list of special phrases. Each entry is a tuple of (phrase, class, type, operator). should_replace: If true, replace the current list of phrases. When false, just add the given phrases to the ones that already exist. \"\"\" PL/pgSQL Functions \uf0c1 The tokenizer must provide access functions for the token_info column to the indexer which extracts the necessary information for the global search tables. If the tokenizer needs additional SQL functions for private use, then these functions must be prefixed with token_ in order to ensure that there are no naming conflicts with the SQL indexer code. The following functions are expected: FUNCTION token_get_name_search_tokens ( info JSONB ) RETURNS INTEGER [] Return an array of token IDs of search terms that should match the name(s) for the given place. These tokens are used to look up the place by name and, where the place functions as part of an address for another place, by address. Must return NULL when the place has no name. FUNCTION token_get_name_match_tokens ( info JSONB ) RETURNS INTEGER [] Return an array of token IDs of full names of the place that should be used to match addresses. The list of match tokens is usually more strict than search tokens as it is used to find a match between two OSM tag values which are expected to contain matching full names. Partial terms should not be used for match tokens. Must return NULL when the place has no name. FUNCTION token_get_housenumber_search_tokens ( info JSONB ) RETURNS INTEGER [] Return an array of token IDs of house number tokens that apply to the place. Note that a place may have multiple house numbers, for example when apartments each have their own number. Must be NULL when the place has no house numbers. FUNCTION token_normalized_housenumber ( info JSONB ) RETURNS TEXT Return the house number(s) in the normalized form that can be matched against a house number token text. If a place has multiple house numbers they must be listed with a semicolon as delimiter. Must be NULL when the place has no house numbers. FUNCTION token_matches_street ( info JSONB , street_tokens INTEGER []) RETURNS BOOLEAN Check if the given tokens (previously saved from token_get_name_match_tokens() ) match against the addr:street tag name. Must return either NULL or FALSE when the place has no addr:street tag. FUNCTION token_matches_place ( info JSONB , place_tokens INTEGER []) RETURNS BOOLEAN Check if the given tokens (previously saved from token_get_name_match_tokens() ) match against the addr:place tag name. Must return either NULL or FALSE when the place has no addr:place tag. FUNCTION token_addr_place_search_tokens ( info JSONB ) RETURNS INTEGER [] Return the search token IDs extracted from the addr:place tag. These tokens are used for searches by address when no matching place can be found in the database. Must be NULL when the place has no addr:place tag. FUNCTION token_get_address_keys ( info JSONB ) RETURNS SETOF TEXT Return the set of keys for which address information is provided. This should correspond to the list of (relevant) addr:* tags with the addr: prefix removed or the keys used in the address dictionary of the place info. FUNCTION token_get_address_search_tokens ( info JSONB , key TEXT ) RETURNS INTEGER [] Return the array of search tokens for the given address part. key can be expected to be one of those returned with token_get_address_keys() . The search tokens are added to the address search vector of the place, when no corresponding OSM object could be found for the given address part from which to copy the name information. FUNCTION token_matches_address ( info JSONB , key TEXT , tokens INTEGER []) Check if the given tokens match against the address part key . Warning: the tokens that are handed in are the lists previously saved from token_get_name_search_tokens() , not from the match token list. This is an historical oddity which will be fixed at some point in the future. Currently, tokenizers are encouraged to make sure that matching works against both the search token list and the match token list. FUNCTION token_get_postcode ( info JSONB ) RETURNS TEXT Return the postcode for the object, if any exists. The postcode must be in the form that should also be presented to the end-user. FUNCTION token_strip_info ( info JSONB ) RETURNS JSONB Return the part of the token_info field that should be stored in the database permanently. The indexer calls this function when all processing is done and replaces the content of the token_info column with the returned value before the trigger stores the information in the database. May return NULL if no information should be stored permanently. PHP Tokenizer class \uf0c1 The PHP tokenizer class is instantiated once per request and responsible for analyzing the incoming query. Multiple requests may be in flight in parallel. The class is expected to be found under the name of \\Nominatim\\Tokenizer . To find the class the PHP code includes the file tokenizer/tokenizer.php in the project directory. This file must be created when the tokenizer is first set up on import. The file should initialize any configuration variables by setting PHP constants and then require the file with the actual implementation of the tokenizer. The tokenizer class must implement the following functions: public function __construct(object &$oDB) The constructor of the class receives a database connection that can be used to query persistent data in the database. public function checkStatus() Check that the tokenizer can access its persistent data structures. If there is an issue, throw an \\Exception . public function normalizeString(string $sTerm) : string Normalize string to a form to be used for comparisons when reordering results. Nominatim reweighs results how well the final display string matches the actual query. Before comparing result and query, names and query are normalised against this function. The tokenizer can thus remove all properties that should not be taken into account for reweighing, e.g. special characters or case. public function tokensForSpecialTerm(string $sTerm) : array Return the list of special term tokens that match the given term. public function extractTokensFromPhrases(array &$aPhrases) : TokenList Parse the given phrases, splitting them into word lists and retrieve the matching tokens. The phrase array may take on two forms. In unstructured searches (using q= parameter) the search query is split at the commas and the elements are put into a sorted list. For structured searches the phrase array is an associative array where the key designates the type of the term (street, city, county etc.) The tokenizer may ignore the phrase type at this stage in parsing. Matching phrase type and appropriate search token type will be done later when the SearchDescription is built. For each phrase in the list of phrases, the function must analyse the phrase string and then call setWordSets() to communicate the result of the analysis. A word set is a list of strings, where each string refers to a search token. A phrase may have multiple interpretations. Therefore a list of word sets is usually attached to the phrase. The search tokens themselves are returned by the function in an associative array, where the key corresponds to the strings given in the word sets. The value is a list of search tokens. Thus a single string in the list of word sets may refer to multiple search tokens.","title":"Tokenizers"},{"location":"develop/Tokenizers/#tokenizers","text":"The tokenizer is the component of Nominatim that is responsible for analysing names of OSM objects and queries. Nominatim provides different tokenizers that use different strategies for normalisation. This page describes how tokenizers are expected to work and the public API that needs to be implemented when creating a new tokenizer. For information on how to configure a specific tokenizer for a database see the tokenizer chapter in the Customization Guide .","title":"Tokenizers"},{"location":"develop/Tokenizers/#generic-architecture","text":"","title":"Generic Architecture"},{"location":"develop/Tokenizers/#about-search-tokens","text":"Search in Nominatim is organised around search tokens. Such a token represents string that can be part of the search query. Tokens are used so that the search index does not need to be organised around strings. Instead the database saves for each place which tokens match this place's name, address, house number etc. To be able to distinguish between these different types of information stored with the place, a search token also always has a certain type: name, house number, postcode etc. During search an incoming query is transformed into a ordered list of such search tokens (or rather many lists, see below) and this list is then converted into a database query to find the right place. It is the core task of the tokenizer to create, manage and assign the search tokens. The tokenizer is involved in two distinct operations: at import time : scanning names of OSM objects, normalizing them and building up the list of search tokens. at query time : scanning the query and returning the appropriate search tokens.","title":"About Search Tokens"},{"location":"develop/Tokenizers/#importing","text":"The indexer is responsible to enrich an OSM object (or place) with all data required for geocoding. It is split into two parts: the controller collects the places that require updating, enriches the place information as required and hands the place to Postgresql. The collector is part of the Nominatim library written in Python. Within Postgresql, the placex_update trigger is responsible to fill out all secondary tables with extra geocoding information. This part is written in PL/pgSQL. The tokenizer is involved in both parts. When the indexer prepares a place, it hands it over to the tokenizer to inspect the names and create all the search tokens applicable for the place. This usually involves updating the tokenizer's internal token lists and creating a list of all token IDs for the specific place. This list is later needed in the PL/pgSQL part where the indexer needs to add the token IDs to the appropriate search tables. To be able to communicate the list between the Python part and the pl/pgSQL trigger, the placex table contains a special JSONB column token_info which is there for the exclusive use of the tokenizer. The Python part of the tokenizer returns a structured information about the tokens of a place to the indexer which converts it to JSON and inserts it into the token_info column. The content of the column is then handed to the PL/pqSQL callbacks of the tokenizer which extracts the required information. Usually the tokenizer then removes all information from the token_info structure, so that no information is ever persistently saved in the table. All information that went in should have been processed after all and put into secondary tables. This is however not a hard requirement. If the tokenizer needs to store additional information about a place permanently, it may do so in the token_info column. It just may never execute searches over it and consequently not create any special indexes on it.","title":"Importing"},{"location":"develop/Tokenizers/#querying","text":"At query time, Nominatim builds up multiple interpretations of the search query. Each of these interpretations is tried against the database in order of the likelihood with which they match to the search query. The first interpretation that yields results wins. The interpretations are encapsulated in the SearchDescription class. An instance of this class is created by applying a sequence of search tokens to an initially empty SearchDescription. It is the responsibility of the tokenizer to parse the search query and derive all possible sequences of search tokens. To that end the tokenizer needs to parse the search query and look up matching words in its own data structures.","title":"Querying"},{"location":"develop/Tokenizers/#tokenizer-api","text":"The following section describes the functions that need to be implemented for a custom tokenizer implementation. Warning This API is currently in early alpha status. While this API is meant to be a public API on which other tokenizers may be implemented, the API is far away from being stable at the moment.","title":"Tokenizer API"},{"location":"develop/Tokenizers/#directory-structure","text":"Nominatim expects two files for a tokenizer: nominatim/tokenizer/<NAME>_tokenizer.py containing the Python part of the implementation lib-php/tokenizer/<NAME>_tokenizer.php with the PHP part of the implementation where <NAME> is a unique name for the tokenizer consisting of only lower-case letters, digits and underscore. A tokenizer also needs to install some SQL functions. By convention, these should be placed in lib-sql/tokenizer . If the tokenizer has a default configuration file, this should be saved in the settings/<NAME>_tokenizer.<SUFFIX> .","title":"Directory Structure"},{"location":"develop/Tokenizers/#configuration-and-persistence","text":"Tokenizers may define custom settings for their configuration. All settings must be prefixed with NOMINATIM_TOKENIZER_ . Settings may be transient or persistent. Transient settings are loaded from the configuration file when Nominatim is started and may thus be changed at any time. Persistent settings are tied to a database installation and must only be read during installation time. If they are needed for the runtime then they must be saved into the nominatim_properties table and later loaded from there.","title":"Configuration and Persistence"},{"location":"develop/Tokenizers/#the-python-module","text":"The Python module is expect to export a single factory function: def create ( dsn : str , data_dir : Path ) -> AbstractTokenizer The dsn parameter contains the DSN of the Nominatim database. The data_dir is a directory in the project directory that the tokenizer may use to save database-specific data. The function must return the instance of the tokenizer class as defined below.","title":"The Python module"},{"location":"develop/Tokenizers/#python-tokenizer-class","text":"All tokenizers must inherit from nominatim.tokenizer.base.AbstractTokenizer and implement the abstract functions defined there. The tokenizer instance is the central instance of the tokenizer in the system. There will only be a single instance of the tokenizer active at any time. Source code in nominatim/tokenizer/base.py class AbstractTokenizer ( ABC ): \"\"\" The tokenizer instance is the central instance of the tokenizer in the system. There will only be a single instance of the tokenizer active at any time. \"\"\" @abstractmethod def init_new_db ( self , config : Configuration , init_db : bool = True ) -> None : \"\"\" Set up a new tokenizer for the database. The function should copy all necessary data into the project directory or save it in the property table to make sure that the tokenizer remains stable over updates. Arguments: config: Read-only object with configuration options. init_db: When set to False, then initialisation of database tables should be skipped. This option is only required for migration purposes and can be safely ignored by custom tokenizers. TODO: can we move the init_db parameter somewhere else? \"\"\" @abstractmethod def init_from_project ( self , config : Configuration ) -> None : \"\"\" Initialise the tokenizer from an existing database setup. The function should load all previously saved configuration from the project directory and/or the property table. Arguments: config: Read-only object with configuration options. \"\"\" @abstractmethod def finalize_import ( self , config : Configuration ) -> None : \"\"\" This function is called at the very end of an import when all data has been imported and indexed. The tokenizer may create at this point any additional indexes and data structures needed during query time. Arguments: config: Read-only object with configuration options. \"\"\" @abstractmethod def update_sql_functions ( self , config : Configuration ) -> None : \"\"\" Update the SQL part of the tokenizer. This function is called automatically on migrations or may be called explicitly by the user through the `nominatim refresh --functions` command. The tokenizer must only update the code of the tokenizer. The data structures or data itself must not be changed by this function. Arguments: config: Read-only object with configuration options. \"\"\" @abstractmethod def check_database ( self , config : Configuration ) -> Optional [ str ]: \"\"\" Check that the database is set up correctly and ready for being queried. Arguments: config: Read-only object with configuration options. Returns: If an issue was found, return an error message with the description of the issue as well as hints for the user on how to resolve the issue. If everything is okay, return `None`. \"\"\" @abstractmethod def update_statistics ( self ) -> None : \"\"\" Recompute any tokenizer statistics necessary for efficient lookup. This function is meant to be called from time to time by the user to improve performance. However, the tokenizer must not depend on it to be called in order to work. \"\"\" @abstractmethod def update_word_tokens ( self ) -> None : \"\"\" Do house-keeping on the tokenizers internal data structures. Remove unused word tokens, resort data etc. \"\"\" @abstractmethod def name_analyzer ( self ) -> AbstractAnalyzer : \"\"\" Create a new analyzer for tokenizing names and queries using this tokinzer. Analyzers are context managers and should be used accordingly: ``` with tokenizer.name_analyzer() as analyzer: analyser.tokenize() ``` When used outside the with construct, the caller must ensure to call the close() function before destructing the analyzer. \"\"\"","title":"Python Tokenizer Class"},{"location":"develop/Tokenizers/#nominatim.tokenizer.base.AbstractTokenizer.check_database","text":"Check that the database is set up correctly and ready for being queried. Parameters: config ( Configuration ) \u2013 Read-only object with configuration options. Returns: Optional[str] \u2013 If an issue was found, return an error message with the description of the issue as well as hints for the user on how to resolve the issue. If everything is okay, return None . Source code in nominatim/tokenizer/base.py @abstractmethod def check_database ( self , config : Configuration ) -> Optional [ str ]: \"\"\" Check that the database is set up correctly and ready for being queried. Arguments: config: Read-only object with configuration options. Returns: If an issue was found, return an error message with the description of the issue as well as hints for the user on how to resolve the issue. If everything is okay, return `None`. \"\"\"","title":"check_database()"},{"location":"develop/Tokenizers/#nominatim.tokenizer.base.AbstractTokenizer.finalize_import","text":"This function is called at the very end of an import when all data has been imported and indexed. The tokenizer may create at this point any additional indexes and data structures needed during query time. Parameters: config ( Configuration ) \u2013 Read-only object with configuration options. Source code in nominatim/tokenizer/base.py @abstractmethod def finalize_import ( self , config : Configuration ) -> None : \"\"\" This function is called at the very end of an import when all data has been imported and indexed. The tokenizer may create at this point any additional indexes and data structures needed during query time. Arguments: config: Read-only object with configuration options. \"\"\"","title":"finalize_import()"},{"location":"develop/Tokenizers/#nominatim.tokenizer.base.AbstractTokenizer.init_from_project","text":"Initialise the tokenizer from an existing database setup. The function should load all previously saved configuration from the project directory and/or the property table. Parameters: config ( Configuration ) \u2013 Read-only object with configuration options. Source code in nominatim/tokenizer/base.py @abstractmethod def init_from_project ( self , config : Configuration ) -> None : \"\"\" Initialise the tokenizer from an existing database setup. The function should load all previously saved configuration from the project directory and/or the property table. Arguments: config: Read-only object with configuration options. \"\"\"","title":"init_from_project()"},{"location":"develop/Tokenizers/#nominatim.tokenizer.base.AbstractTokenizer.init_new_db","text":"Set up a new tokenizer for the database. The function should copy all necessary data into the project directory or save it in the property table to make sure that the tokenizer remains stable over updates. Parameters: config ( Configuration ) \u2013 Read-only object with configuration options. init_db ( bool ) \u2013 When set to False, then initialisation of database tables should be skipped. This option is only required for migration purposes and can be safely ignored by custom tokenizers. TODO: can we move the init_db parameter somewhere else? Source code in nominatim/tokenizer/base.py @abstractmethod def init_new_db ( self , config : Configuration , init_db : bool = True ) -> None : \"\"\" Set up a new tokenizer for the database. The function should copy all necessary data into the project directory or save it in the property table to make sure that the tokenizer remains stable over updates. Arguments: config: Read-only object with configuration options. init_db: When set to False, then initialisation of database tables should be skipped. This option is only required for migration purposes and can be safely ignored by custom tokenizers. TODO: can we move the init_db parameter somewhere else? \"\"\"","title":"init_new_db()"},{"location":"develop/Tokenizers/#nominatim.tokenizer.base.AbstractTokenizer.name_analyzer","text":"Create a new analyzer for tokenizing names and queries using this tokinzer. Analyzers are context managers and should be used accordingly: with tokenizer.name_analyzer() as analyzer: analyser.tokenize() When used outside the with construct, the caller must ensure to call the close() function before destructing the analyzer. Source code in nominatim/tokenizer/base.py @abstractmethod def name_analyzer ( self ) -> AbstractAnalyzer : \"\"\" Create a new analyzer for tokenizing names and queries using this tokinzer. Analyzers are context managers and should be used accordingly: ``` with tokenizer.name_analyzer() as analyzer: analyser.tokenize() ``` When used outside the with construct, the caller must ensure to call the close() function before destructing the analyzer. \"\"\"","title":"name_analyzer()"},{"location":"develop/Tokenizers/#nominatim.tokenizer.base.AbstractTokenizer.update_sql_functions","text":"Update the SQL part of the tokenizer. This function is called automatically on migrations or may be called explicitly by the user through the nominatim refresh --functions command. The tokenizer must only update the code of the tokenizer. The data structures or data itself must not be changed by this function. Parameters: config ( Configuration ) \u2013 Read-only object with configuration options. Source code in nominatim/tokenizer/base.py @abstractmethod def update_sql_functions ( self , config : Configuration ) -> None : \"\"\" Update the SQL part of the tokenizer. This function is called automatically on migrations or may be called explicitly by the user through the `nominatim refresh --functions` command. The tokenizer must only update the code of the tokenizer. The data structures or data itself must not be changed by this function. Arguments: config: Read-only object with configuration options. \"\"\"","title":"update_sql_functions()"},{"location":"develop/Tokenizers/#nominatim.tokenizer.base.AbstractTokenizer.update_statistics","text":"Recompute any tokenizer statistics necessary for efficient lookup. This function is meant to be called from time to time by the user to improve performance. However, the tokenizer must not depend on it to be called in order to work. Source code in nominatim/tokenizer/base.py @abstractmethod def update_statistics ( self ) -> None : \"\"\" Recompute any tokenizer statistics necessary for efficient lookup. This function is meant to be called from time to time by the user to improve performance. However, the tokenizer must not depend on it to be called in order to work. \"\"\"","title":"update_statistics()"},{"location":"develop/Tokenizers/#nominatim.tokenizer.base.AbstractTokenizer.update_word_tokens","text":"Do house-keeping on the tokenizers internal data structures. Remove unused word tokens, resort data etc. Source code in nominatim/tokenizer/base.py @abstractmethod def update_word_tokens ( self ) -> None : \"\"\" Do house-keeping on the tokenizers internal data structures. Remove unused word tokens, resort data etc. \"\"\"","title":"update_word_tokens()"},{"location":"develop/Tokenizers/#python-analyzer-class","text":"The analyzer provides the functions for analysing names and building the token database. Analyzers are instantiated on a per-thread base. Access to global data structures must be synchronised accordingly. Source code in nominatim/tokenizer/base.py class AbstractAnalyzer ( ABC ): \"\"\" The analyzer provides the functions for analysing names and building the token database. Analyzers are instantiated on a per-thread base. Access to global data structures must be synchronised accordingly. \"\"\" def __enter__ ( self ) -> 'AbstractAnalyzer' : return self def __exit__ ( self , exc_type : Any , exc_value : Any , traceback : Any ) -> None : self . close () @abstractmethod def close ( self ) -> None : \"\"\" Free all resources used by the analyzer. \"\"\" @abstractmethod def get_word_token_info ( self , words : List [ str ]) -> List [ Tuple [ str , str , int ]]: \"\"\" Return token information for the given list of words. The function is used for testing and debugging only and does not need to be particularly efficient. Arguments: words: A list of words to look up the tokens for. If a word starts with # it is assumed to be a full name otherwise is a partial term. Returns: The function returns the list of all tuples that could be found for the given words. Each list entry is a tuple of (original word, word token, word id). \"\"\" @abstractmethod def normalize_postcode ( self , postcode : str ) -> str : \"\"\" Convert the postcode to its standardized form. This function must yield exactly the same result as the SQL function `token_normalized_postcode()`. Arguments: postcode: The postcode to be normalized. Returns: The given postcode after normalization. \"\"\" @abstractmethod def update_postcodes_from_db ( self ) -> None : \"\"\" Update the tokenizer's postcode tokens from the current content of the `location_postcode` table. \"\"\" @abstractmethod def update_special_phrases ( self , phrases : Iterable [ Tuple [ str , str , str , str ]], should_replace : bool ) -> None : \"\"\" Update the tokenizer's special phrase tokens from the given list of special phrases. Arguments: phrases: The new list of special phrases. Each entry is a tuple of (phrase, class, type, operator). should_replace: If true, replace the current list of phrases. When false, just add the given phrases to the ones that already exist. \"\"\" @abstractmethod def add_country_names ( self , country_code : str , names : Dict [ str , str ]) -> None : \"\"\" Add the given names to the tokenizer's list of country tokens. Arguments: country_code: two-letter country code for the country the names refer to. names: Dictionary of name type to name. \"\"\" @abstractmethod def process_place ( self , place : PlaceInfo ) -> Any : \"\"\" Extract tokens for the given place and compute the information to be handed to the PL/pgSQL processor for building the search index. Arguments: place: Place information retrieved from the database. Returns: A JSON-serialisable structure that will be handed into the database via the `token_info` field. \"\"\"","title":"Python Analyzer Class"},{"location":"develop/Tokenizers/#nominatim.tokenizer.base.AbstractAnalyzer.add_country_names","text":"Add the given names to the tokenizer's list of country tokens. Parameters: country_code ( str ) \u2013 two-letter country code for the country the names refer to. names ( Dict[str, str] ) \u2013 Dictionary of name type to name. Source code in nominatim/tokenizer/base.py @abstractmethod def add_country_names ( self , country_code : str , names : Dict [ str , str ]) -> None : \"\"\" Add the given names to the tokenizer's list of country tokens. Arguments: country_code: two-letter country code for the country the names refer to. names: Dictionary of name type to name. \"\"\"","title":"add_country_names()"},{"location":"develop/Tokenizers/#nominatim.tokenizer.base.AbstractAnalyzer.close","text":"Free all resources used by the analyzer. Source code in nominatim/tokenizer/base.py @abstractmethod def close ( self ) -> None : \"\"\" Free all resources used by the analyzer. \"\"\"","title":"close()"},{"location":"develop/Tokenizers/#nominatim.tokenizer.base.AbstractAnalyzer.get_word_token_info","text":"Return token information for the given list of words. The function is used for testing and debugging only and does not need to be particularly efficient. Parameters: words ( List[str] ) \u2013 A list of words to look up the tokens for. If a word starts with # it is assumed to be a full name otherwise is a partial term. Returns: List[Tuple[str, str, int]] \u2013 The function returns the list of all tuples that could be found for the given words. Each list entry is a tuple of (original word, word token, word id). Source code in nominatim/tokenizer/base.py @abstractmethod def get_word_token_info ( self , words : List [ str ]) -> List [ Tuple [ str , str , int ]]: \"\"\" Return token information for the given list of words. The function is used for testing and debugging only and does not need to be particularly efficient. Arguments: words: A list of words to look up the tokens for. If a word starts with # it is assumed to be a full name otherwise is a partial term. Returns: The function returns the list of all tuples that could be found for the given words. Each list entry is a tuple of (original word, word token, word id). \"\"\"","title":"get_word_token_info()"},{"location":"develop/Tokenizers/#nominatim.tokenizer.base.AbstractAnalyzer.normalize_postcode","text":"Convert the postcode to its standardized form. This function must yield exactly the same result as the SQL function token_normalized_postcode() . Parameters: postcode ( str ) \u2013 The postcode to be normalized. Returns: str \u2013 The given postcode after normalization. Source code in nominatim/tokenizer/base.py @abstractmethod def normalize_postcode ( self , postcode : str ) -> str : \"\"\" Convert the postcode to its standardized form. This function must yield exactly the same result as the SQL function `token_normalized_postcode()`. Arguments: postcode: The postcode to be normalized. Returns: The given postcode after normalization. \"\"\"","title":"normalize_postcode()"},{"location":"develop/Tokenizers/#nominatim.tokenizer.base.AbstractAnalyzer.process_place","text":"Extract tokens for the given place and compute the information to be handed to the PL/pgSQL processor for building the search index. Parameters: place ( PlaceInfo ) \u2013 Place information retrieved from the database. Returns: Any \u2013 A JSON-serialisable structure that will be handed into the database via the token_info field. Source code in nominatim/tokenizer/base.py @abstractmethod def process_place ( self , place : PlaceInfo ) -> Any : \"\"\" Extract tokens for the given place and compute the information to be handed to the PL/pgSQL processor for building the search index. Arguments: place: Place information retrieved from the database. Returns: A JSON-serialisable structure that will be handed into the database via the `token_info` field. \"\"\"","title":"process_place()"},{"location":"develop/Tokenizers/#nominatim.tokenizer.base.AbstractAnalyzer.update_postcodes_from_db","text":"Update the tokenizer's postcode tokens from the current content of the location_postcode table. Source code in nominatim/tokenizer/base.py @abstractmethod def update_postcodes_from_db ( self ) -> None : \"\"\" Update the tokenizer's postcode tokens from the current content of the `location_postcode` table. \"\"\"","title":"update_postcodes_from_db()"},{"location":"develop/Tokenizers/#nominatim.tokenizer.base.AbstractAnalyzer.update_special_phrases","text":"Update the tokenizer's special phrase tokens from the given list of special phrases. Parameters: phrases ( Iterable[Tuple[str, str, str, str]] ) \u2013 The new list of special phrases. Each entry is a tuple of (phrase, class, type, operator). should_replace ( bool ) \u2013 If true, replace the current list of phrases. When false, just add the given phrases to the ones that already exist. Source code in nominatim/tokenizer/base.py @abstractmethod def update_special_phrases ( self , phrases : Iterable [ Tuple [ str , str , str , str ]], should_replace : bool ) -> None : \"\"\" Update the tokenizer's special phrase tokens from the given list of special phrases. Arguments: phrases: The new list of special phrases. Each entry is a tuple of (phrase, class, type, operator). should_replace: If true, replace the current list of phrases. When false, just add the given phrases to the ones that already exist. \"\"\"","title":"update_special_phrases()"},{"location":"develop/Tokenizers/#plpgsql-functions","text":"The tokenizer must provide access functions for the token_info column to the indexer which extracts the necessary information for the global search tables. If the tokenizer needs additional SQL functions for private use, then these functions must be prefixed with token_ in order to ensure that there are no naming conflicts with the SQL indexer code. The following functions are expected: FUNCTION token_get_name_search_tokens ( info JSONB ) RETURNS INTEGER [] Return an array of token IDs of search terms that should match the name(s) for the given place. These tokens are used to look up the place by name and, where the place functions as part of an address for another place, by address. Must return NULL when the place has no name. FUNCTION token_get_name_match_tokens ( info JSONB ) RETURNS INTEGER [] Return an array of token IDs of full names of the place that should be used to match addresses. The list of match tokens is usually more strict than search tokens as it is used to find a match between two OSM tag values which are expected to contain matching full names. Partial terms should not be used for match tokens. Must return NULL when the place has no name. FUNCTION token_get_housenumber_search_tokens ( info JSONB ) RETURNS INTEGER [] Return an array of token IDs of house number tokens that apply to the place. Note that a place may have multiple house numbers, for example when apartments each have their own number. Must be NULL when the place has no house numbers. FUNCTION token_normalized_housenumber ( info JSONB ) RETURNS TEXT Return the house number(s) in the normalized form that can be matched against a house number token text. If a place has multiple house numbers they must be listed with a semicolon as delimiter. Must be NULL when the place has no house numbers. FUNCTION token_matches_street ( info JSONB , street_tokens INTEGER []) RETURNS BOOLEAN Check if the given tokens (previously saved from token_get_name_match_tokens() ) match against the addr:street tag name. Must return either NULL or FALSE when the place has no addr:street tag. FUNCTION token_matches_place ( info JSONB , place_tokens INTEGER []) RETURNS BOOLEAN Check if the given tokens (previously saved from token_get_name_match_tokens() ) match against the addr:place tag name. Must return either NULL or FALSE when the place has no addr:place tag. FUNCTION token_addr_place_search_tokens ( info JSONB ) RETURNS INTEGER [] Return the search token IDs extracted from the addr:place tag. These tokens are used for searches by address when no matching place can be found in the database. Must be NULL when the place has no addr:place tag. FUNCTION token_get_address_keys ( info JSONB ) RETURNS SETOF TEXT Return the set of keys for which address information is provided. This should correspond to the list of (relevant) addr:* tags with the addr: prefix removed or the keys used in the address dictionary of the place info. FUNCTION token_get_address_search_tokens ( info JSONB , key TEXT ) RETURNS INTEGER [] Return the array of search tokens for the given address part. key can be expected to be one of those returned with token_get_address_keys() . The search tokens are added to the address search vector of the place, when no corresponding OSM object could be found for the given address part from which to copy the name information. FUNCTION token_matches_address ( info JSONB , key TEXT , tokens INTEGER []) Check if the given tokens match against the address part key . Warning: the tokens that are handed in are the lists previously saved from token_get_name_search_tokens() , not from the match token list. This is an historical oddity which will be fixed at some point in the future. Currently, tokenizers are encouraged to make sure that matching works against both the search token list and the match token list. FUNCTION token_get_postcode ( info JSONB ) RETURNS TEXT Return the postcode for the object, if any exists. The postcode must be in the form that should also be presented to the end-user. FUNCTION token_strip_info ( info JSONB ) RETURNS JSONB Return the part of the token_info field that should be stored in the database permanently. The indexer calls this function when all processing is done and replaces the content of the token_info column with the returned value before the trigger stores the information in the database. May return NULL if no information should be stored permanently.","title":"PL/pgSQL Functions"},{"location":"develop/Tokenizers/#php-tokenizer-class","text":"The PHP tokenizer class is instantiated once per request and responsible for analyzing the incoming query. Multiple requests may be in flight in parallel. The class is expected to be found under the name of \\Nominatim\\Tokenizer . To find the class the PHP code includes the file tokenizer/tokenizer.php in the project directory. This file must be created when the tokenizer is first set up on import. The file should initialize any configuration variables by setting PHP constants and then require the file with the actual implementation of the tokenizer. The tokenizer class must implement the following functions: public function __construct(object &$oDB) The constructor of the class receives a database connection that can be used to query persistent data in the database. public function checkStatus() Check that the tokenizer can access its persistent data structures. If there is an issue, throw an \\Exception . public function normalizeString(string $sTerm) : string Normalize string to a form to be used for comparisons when reordering results. Nominatim reweighs results how well the final display string matches the actual query. Before comparing result and query, names and query are normalised against this function. The tokenizer can thus remove all properties that should not be taken into account for reweighing, e.g. special characters or case. public function tokensForSpecialTerm(string $sTerm) : array Return the list of special term tokens that match the given term. public function extractTokensFromPhrases(array &$aPhrases) : TokenList Parse the given phrases, splitting them into word lists and retrieve the matching tokens. The phrase array may take on two forms. In unstructured searches (using q= parameter) the search query is split at the commas and the elements are put into a sorted list. For structured searches the phrase array is an associative array where the key designates the type of the term (street, city, county etc.) The tokenizer may ignore the phrase type at this stage in parsing. Matching phrase type and appropriate search token type will be done later when the SearchDescription is built. For each phrase in the list of phrases, the function must analyse the phrase string and then call setWordSets() to communicate the result of the analysis. A word set is a list of strings, where each string refers to a search token. A phrase may have multiple interpretations. Therefore a list of word sets is usually attached to the phrase. The search tokens themselves are returned by the function in an associative array, where the key corresponds to the strings given in the word sets. The value is a list of search tokens. Thus a single string in the list of word sets may refer to multiple search tokens.","title":"PHP Tokenizer class"},{"location":"develop/data-sources/","text":"Additional Data Sources \uf0c1 This guide explains how data sources other than OpenStreetMap mentioned in the install instructions got obtained and converted. Country grid \uf0c1 Nominatim uses pre-generated country borders data. In case one imports only a subset of a country. And to assign each place a partition. Nominatim database tables are split into partitions for performance. More details in osm-search/country-grid-data . US Census TIGER \uf0c1 For the United States you can choose to import additional street-level data. The data isn't mixed into OSM data but queried as fallback when no OSM result can be found. More details in osm-search/TIGER-data . GB postcodes \uf0c1 For Great Britain you can choose to import Royalmail postcode centroids. More details in osm-search/gb-postcode-data . Wikipedia & Wikidata rankings \uf0c1 Nominatim can import \"importance\" data of place names. This greatly improves ranking of results. More details in osm-search/wikipedia-wikidata .","title":"External Data Sources"},{"location":"develop/data-sources/#additional-data-sources","text":"This guide explains how data sources other than OpenStreetMap mentioned in the install instructions got obtained and converted.","title":"Additional Data Sources"},{"location":"develop/data-sources/#country-grid","text":"Nominatim uses pre-generated country borders data. In case one imports only a subset of a country. And to assign each place a partition. Nominatim database tables are split into partitions for performance. More details in osm-search/country-grid-data .","title":"Country grid"},{"location":"develop/data-sources/#us-census-tiger","text":"For the United States you can choose to import additional street-level data. The data isn't mixed into OSM data but queried as fallback when no OSM result can be found. More details in osm-search/TIGER-data .","title":"US Census TIGER"},{"location":"develop/data-sources/#gb-postcodes","text":"For Great Britain you can choose to import Royalmail postcode centroids. More details in osm-search/gb-postcode-data .","title":"GB postcodes"},{"location":"develop/data-sources/#wikipedia-wikidata-rankings","text":"Nominatim can import \"importance\" data of place names. This greatly improves ranking of results. More details in osm-search/wikipedia-wikidata .","title":"Wikipedia &amp; Wikidata rankings"},{"location":"develop/overview/","text":"Basic Architecture \uf0c1 Nominatim provides geocoding based on OpenStreetMap data. It uses a PostgreSQL database as a backend for storing the data. There are three basic parts to Nominatim's architecture: the data import, the address computation and the search frontend. The data import stage reads the raw OSM data and extracts all information that is useful for geocoding. This part is done by osm2pgsql, the same tool that can also be used to import a rendering database. It uses the special gazetteer output plugin in osm2pgsql/src/output-gazetter.[ch]pp . The result of the import can be found in the database table place . The address computation or indexing stage takes the data from place and adds additional information needed for geocoding. It ranks the places by importance, links objects that belong together and computes addresses and the search index. Most of this work is done in PL/pgSQL via database triggers and can be found in the files in the sql/functions/ directory. The search frontend implements the actual API. It takes search and reverse geocoding queries from the user, looks up the data and returns the results in the requested format. This part is written in PHP and can be found in the lib/ and website/ directories.","title":"Architecture Overview"},{"location":"develop/overview/#basic-architecture","text":"Nominatim provides geocoding based on OpenStreetMap data. It uses a PostgreSQL database as a backend for storing the data. There are three basic parts to Nominatim's architecture: the data import, the address computation and the search frontend. The data import stage reads the raw OSM data and extracts all information that is useful for geocoding. This part is done by osm2pgsql, the same tool that can also be used to import a rendering database. It uses the special gazetteer output plugin in osm2pgsql/src/output-gazetter.[ch]pp . The result of the import can be found in the database table place . The address computation or indexing stage takes the data from place and adds additional information needed for geocoding. It ranks the places by importance, links objects that belong together and computes addresses and the search index. Most of this work is done in PL/pgSQL via database triggers and can be found in the files in the sql/functions/ directory. The search frontend implements the actual API. It takes search and reverse geocoding queries from the user, looks up the data and returns the results in the requested format. This part is written in PHP and can be found in the lib/ and website/ directories.","title":"Basic Architecture"}]}